{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from func.utils import get_numeric_features, get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename, logger_func\n",
    "try:\n",
    "    logger\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b130d0c90f9052e4e79d9a42a33126d326f99e76"
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../../tool/ctrNet-tool/')\n",
    "import ctrNet\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src import misc_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMN_GROUP = 'DT-M'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, COLUMN_GROUP, 'is_train', 'date']\n",
    "\n",
    "def filter_feature(path):\n",
    "    if path.count(''):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "paths_train = glob('../submit/re_sub/*_train.gz')\n",
    "paths_test  = glob('../submit/re_sub/*_test.gz')\n",
    "paths_train += glob('../submit/add_feature/*_train.gz')\n",
    "paths_test  += glob('../submit/add_feature/*_test.gz')\n",
    "paths_train += glob('../feature/valid_use/531*_train.gz')\n",
    "paths_test  += glob('../feature/valid_use/531*_test.gz')\n",
    "paths_train += glob('../feature/valid_use/532*_train.gz')\n",
    "paths_test  += glob('../feature/valid_use/532*_test.gz')\n",
    "paths_train_feature = []\n",
    "paths_test_feature  = []\n",
    "\n",
    "df_train = parallel_load_data(paths_train)\n",
    "df_test  = parallel_load_data(paths_test)\n",
    "Y = df_train[COLUMN_TARGET]\n",
    "df_train.drop(COLUMN_TARGET, axis=1, inplace=True)\n",
    "len_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f24dcd1a223ea1175800f722952980c4a8a4215c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [50:38<00:00, 21.81s/it]\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Loading Dataset & Bucketting\n",
    "#========================================================================\n",
    "def make_bucket(data,num=10):\n",
    "    data.sort()\n",
    "    bins=[]\n",
    "    for i in range(num):\n",
    "        bins.append(data[int(len(data)*(i+1)//num)-1])\n",
    "    return bins\n",
    "\n",
    "df_feat = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "del df_train, df_test\n",
    "gc.collect()\n",
    "\n",
    "cols_num = get_numeric_features(df_feat, ignore_list=COLUMNS_IGNORE)\n",
    "\n",
    "for f in tqdm(cols_num):\n",
    "    mode = df_feat[~df_feat[f].isnull()][f].mode()[0]\n",
    "    df_feat[f].fillna(mode, inplace=True)\n",
    "    data = df_feat[f].tolist()\n",
    "    bins=make_bucket(data,num=50)\n",
    "    df_feat[f] = np.digitize(df_feat[f], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = get_categorical_features(df_feat, ignore_list=COLUMNS_IGNORE)\n",
    "\n",
    "for col in cols_cat:\n",
    "    df_feat[col].fillna(0, inplace=True)\n",
    "\n",
    "train = df_feat.iloc[:len_train, :]\n",
    "test = df_feat.iloc[len_train:, :]\n",
    "use_cols = [col for col in train.columns if col not in COLUMNS_IGNORE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "40b2ecd8536dcac62d426daeeb8c5f79f8f817c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  activation=['relu', 'relu', 'relu']\n",
      "  batch_norm_decay=0.9\n",
      "  batch_size=1024\n",
      "  cross_activation=identity\n",
      "  cross_layer_sizes=[128, 128, 128]\n",
      "  epoch=1\n",
      "  feature_nums=148\n",
      "  hash_ids=200000\n",
      "  hidden_size=[128, 128]\n",
      "  init_method=uniform\n",
      "  init_value=0.1\n",
      "  k=8\n",
      "  kfold=5\n",
      "  learning_rate=0.001\n",
      "  metric=auc\n",
      "  model=xdeepfm\n",
      "  norm=True\n",
      "  num_display_steps=1000\n",
      "  num_eval_steps=1000\n",
      "  optimizer=adam\n"
     ]
    }
   ],
   "source": [
    "hparam=tf.contrib.training.HParams(\n",
    "            model='xdeepfm',\n",
    "            norm=True,\n",
    "            batch_norm_decay=0.9,\n",
    "            hidden_size=[128,128],\n",
    "            cross_layer_sizes=[128,128,128],\n",
    "            k=8,\n",
    "            hash_ids=int(2e5),\n",
    "            batch_size=1024,\n",
    "            optimizer=\"adam\",\n",
    "            learning_rate=0.001,\n",
    "            num_display_steps=1000,\n",
    "            num_eval_steps=1000,\n",
    "            epoch=1,\n",
    "            metric='auc',\n",
    "            activation=['relu','relu','relu'],\n",
    "            cross_activation='identity',\n",
    "            init_method='uniform',\n",
    "            init_value=0.1,\n",
    "            feature_nums=len(use_cols),\n",
    "            kfold=5)\n",
    "misc_utils.print_hparams(hparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66e67bbf4fb72dfb853ca1cb05ce993f670bec35"
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[COLUMN_TARGET] = Y\n",
    "test[COLUMN_TARGET] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=set(range(train.shape[0]))\n",
    "K_fold=[]\n",
    "for i in range(hparam.kfold):\n",
    "    if i == hparam.kfold-1:\n",
    "        tmp=index\n",
    "    else:\n",
    "        tmp=random.sample(index,int(1.0/hparam.kfold*train.shape[0]))\n",
    "    index=index-set(tmp)\n",
    "    print(\"Number:\",len(tmp))\n",
    "    K_fold.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "6c48b409a4e86c09ca395c3a4f75b2b1c372d124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "# Trainable variables\n",
      "  emb_v1:0, (200000, 1), \n",
      "  emb_v2:0, (200000, 8), \n",
      "  Variable:0, (1184, 128), \n",
      "  norm_0/beta:0, (128,), \n",
      "  norm_0/gamma:0, (128,), \n",
      "  Variable_1:0, (128, 128), \n",
      "  norm_1/beta:0, (128,), \n",
      "  norm_1/gamma:0, (128,), \n",
      "  Variable_2:0, (128, 1), \n",
      "  exfm_part/f_0:0, (1, 21904, 128), \n",
      "  exfm_part/f_1:0, (1, 9472, 128), \n",
      "  exfm_part/f_2:0, (1, 9472, 128), \n",
      "  exfm_part/w_nn_output:0, (256, 1), \n",
      "  exfm_part/b_nn_output:0, (1,), \n",
      "  epoch 0 step 1000 lr 0.001 logloss 0.619496 gN 0.30, Tue Mar 12 22:13:13 2019\n",
      "# Epcho-time 223.05s Eval AUC 0.721773. Best AUC 0.721773.\n",
      "  epoch 0 step 2000 lr 0.001 logloss 0.605771 gN 0.24, Tue Mar 12 22:17:28 2019\n",
      "# Epcho-time 477.70s Eval AUC 0.729980. Best AUC 0.729980.\n",
      "  epoch 0 step 3000 lr 0.001 logloss 0.602579 gN 0.23, Tue Mar 12 22:21:42 2019\n",
      "# Epcho-time 732.48s Eval AUC 0.732971. Best AUC 0.732971.\n",
      "  epoch 0 step 4000 lr 0.001 logloss 0.600521 gN 0.22, Tue Mar 12 22:25:58 2019\n",
      "# Epcho-time 988.38s Eval AUC 0.734562. Best AUC 0.734562.\n",
      "  epoch 0 step 5000 lr 0.001 logloss 0.598817 gN 0.21, Tue Mar 12 22:30:18 2019\n",
      "# Epcho-time 1248.18s Eval AUC 0.735656. Best AUC 0.735656.\n",
      "  epoch 0 step 6000 lr 0.001 logloss 0.598064 gN 0.21, Tue Mar 12 22:34:35 2019\n",
      "# Epcho-time 1505.22s Eval AUC 0.737564. Best AUC 0.737564.\n",
      "# Epcho-time 1756.73s Eval AUC 0.738002. Best AUC 0.738002.\n",
      "INFO:tensorflow:Restoring parameters from model_tmp/model\n",
      "# Epcho-time 1789.95s Eval AUC 0.737999. Best AUC 0.738002.\n",
      "Training Done! Inference...\n",
      "Fold 1\n",
      "# Trainable variables\n",
      "  emb_v1:0, (200000, 1), \n",
      "  emb_v2:0, (200000, 8), \n",
      "  Variable:0, (1184, 128), \n",
      "  norm_0/beta:0, (128,), \n",
      "  norm_0/gamma:0, (128,), \n",
      "  Variable_1:0, (128, 128), \n",
      "  norm_1/beta:0, (128,), \n",
      "  norm_1/gamma:0, (128,), \n",
      "  Variable_2:0, (128, 1), \n",
      "  exfm_part/f_0:0, (1, 21904, 128), \n",
      "  exfm_part/f_1:0, (1, 9472, 128), \n",
      "  exfm_part/f_2:0, (1, 9472, 128), \n",
      "  exfm_part/w_nn_output:0, (256, 1), \n",
      "  exfm_part/b_nn_output:0, (1,), \n",
      "  epoch 0 step 1000 lr 0.001 logloss 0.620267 gN 0.29, Tue Mar 12 23:09:01 2019\n",
      "# Epcho-time 226.94s Eval AUC 0.723373. Best AUC 0.723373.\n",
      "  epoch 0 step 2000 lr 0.001 logloss 0.606365 gN 0.24, Tue Mar 12 23:13:17 2019\n",
      "# Epcho-time 483.13s Eval AUC 0.728467. Best AUC 0.728467.\n",
      "  epoch 0 step 3000 lr 0.001 logloss 0.602665 gN 0.23, Tue Mar 12 23:17:36 2019\n",
      "# Epcho-time 741.55s Eval AUC 0.732529. Best AUC 0.732529.\n",
      "  epoch 0 step 4000 lr 0.001 logloss 0.600500 gN 0.22, Tue Mar 12 23:21:55 2019\n",
      "# Epcho-time 1000.99s Eval AUC 0.733633. Best AUC 0.733633.\n",
      "  epoch 0 step 5000 lr 0.001 logloss 0.598733 gN 0.22, Tue Mar 12 23:26:11 2019\n",
      "# Epcho-time 1257.05s Eval AUC 0.733887. Best AUC 0.733887.\n",
      "  epoch 0 step 6000 lr 0.001 logloss 0.598007 gN 0.21, Tue Mar 12 23:30:27 2019\n",
      "# Epcho-time 1512.40s Eval AUC 0.736371. Best AUC 0.736371.\n",
      "# Epcho-time 1760.44s Eval AUC 0.736726. Best AUC 0.736726.\n",
      "INFO:tensorflow:Restoring parameters from model_tmp/model\n",
      "# Epcho-time 1793.93s Eval AUC 0.736723. Best AUC 0.736726.\n",
      "Training Done! Inference...\n",
      "Fold 2\n",
      "# Trainable variables\n",
      "  emb_v1:0, (200000, 1), \n",
      "  emb_v2:0, (200000, 8), \n",
      "  Variable:0, (1184, 128), \n",
      "  norm_0/beta:0, (128,), \n",
      "  norm_0/gamma:0, (128,), \n",
      "  Variable_1:0, (128, 128), \n",
      "  norm_1/beta:0, (128,), \n",
      "  norm_1/gamma:0, (128,), \n",
      "  Variable_2:0, (128, 1), \n",
      "  exfm_part/f_0:0, (1, 21904, 128), \n",
      "  exfm_part/f_1:0, (1, 9472, 128), \n",
      "  exfm_part/f_2:0, (1, 9472, 128), \n",
      "  exfm_part/w_nn_output:0, (256, 1), \n",
      "  exfm_part/b_nn_output:0, (1,), \n",
      "  epoch 0 step 1000 lr 0.001 logloss 0.619777 gN 0.29, Wed Mar 13 00:04:43 2019\n",
      "# Epcho-time 221.72s Eval AUC 0.722431. Best AUC 0.722431.\n",
      "  epoch 0 step 2000 lr 0.001 logloss 0.605597 gN 0.24, Wed Mar 13 00:08:58 2019\n",
      "# Epcho-time 476.88s Eval AUC 0.729562. Best AUC 0.729562.\n",
      "  epoch 0 step 3000 lr 0.001 logloss 0.601705 gN 0.23, Wed Mar 13 00:13:13 2019\n",
      "# Epcho-time 731.96s Eval AUC 0.731918. Best AUC 0.731918.\n",
      "  epoch 0 step 4000 lr 0.001 logloss 0.600295 gN 0.22, Wed Mar 13 00:17:29 2019\n",
      "# Epcho-time 987.62s Eval AUC 0.733650. Best AUC 0.733650.\n",
      "  epoch 0 step 5000 lr 0.001 logloss 0.598752 gN 0.22, Wed Mar 13 00:21:44 2019\n",
      "# Epcho-time 1242.78s Eval AUC 0.734470. Best AUC 0.734470.\n",
      "  epoch 0 step 6000 lr 0.001 logloss 0.597974 gN 0.21, Wed Mar 13 00:26:01 2019\n",
      "# Epcho-time 1499.78s Eval AUC 0.736779. Best AUC 0.736779.\n",
      "# Epcho-time 1749.30s Eval AUC 0.737132. Best AUC 0.737132.\n",
      "INFO:tensorflow:Restoring parameters from model_tmp/model\n",
      "# Epcho-time 1782.29s Eval AUC 0.737133. Best AUC 0.737133.\n",
      "Training Done! Inference...\n",
      "Fold 3\n",
      "# Trainable variables\n",
      "  emb_v1:0, (200000, 1), \n",
      "  emb_v2:0, (200000, 8), \n",
      "  Variable:0, (1184, 128), \n",
      "  norm_0/beta:0, (128,), \n",
      "  norm_0/gamma:0, (128,), \n",
      "  Variable_1:0, (128, 128), \n",
      "  norm_1/beta:0, (128,), \n",
      "  norm_1/gamma:0, (128,), \n",
      "  Variable_2:0, (128, 1), \n",
      "  exfm_part/f_0:0, (1, 21904, 128), \n",
      "  exfm_part/f_1:0, (1, 9472, 128), \n",
      "  exfm_part/f_2:0, (1, 9472, 128), \n",
      "  exfm_part/w_nn_output:0, (256, 1), \n",
      "  exfm_part/b_nn_output:0, (1,), \n",
      "  epoch 0 step 1000 lr 0.001 logloss 0.620135 gN 0.29, Wed Mar 13 01:00:17 2019\n",
      "# Epcho-time 225.54s Eval AUC 0.725166. Best AUC 0.725166.\n",
      "  epoch 0 step 2000 lr 0.001 logloss 0.605617 gN 0.24, Wed Mar 13 01:04:33 2019\n",
      "# Epcho-time 481.01s Eval AUC 0.731947. Best AUC 0.731947.\n",
      "  epoch 0 step 3000 lr 0.001 logloss 0.601622 gN 0.22, Wed Mar 13 01:08:51 2019\n",
      "# Epcho-time 738.80s Eval AUC 0.734148. Best AUC 0.734148.\n",
      "  epoch 0 step 4000 lr 0.001 logloss 0.600444 gN 0.22, Wed Mar 13 01:13:10 2019\n",
      "# Epcho-time 997.78s Eval AUC 0.736700. Best AUC 0.736700.\n",
      "  epoch 0 step 5000 lr 0.001 logloss 0.599325 gN 0.22, Wed Mar 13 01:17:27 2019\n",
      "# Epcho-time 1255.69s Eval AUC 0.737696. Best AUC 0.737696.\n",
      "  epoch 0 step 6000 lr 0.001 logloss 0.597823 gN 0.21, Wed Mar 13 01:21:45 2019\n",
      "# Epcho-time 1512.83s Eval AUC 0.738962. Best AUC 0.738962.\n",
      "# Epcho-time 1760.64s Eval AUC 0.739237. Best AUC 0.739237.\n",
      "INFO:tensorflow:Restoring parameters from model_tmp/model\n",
      "# Epcho-time 1793.44s Eval AUC 0.739236. Best AUC 0.739237.\n",
      "Training Done! Inference...\n",
      "Fold 4\n",
      "# Trainable variables\n",
      "  emb_v1:0, (200000, 1), \n",
      "  emb_v2:0, (200000, 8), \n",
      "  Variable:0, (1184, 128), \n",
      "  norm_0/beta:0, (128,), \n",
      "  norm_0/gamma:0, (128,), \n",
      "  Variable_1:0, (128, 128), \n",
      "  norm_1/beta:0, (128,), \n",
      "  norm_1/gamma:0, (128,), \n",
      "  Variable_2:0, (128, 1), \n",
      "  exfm_part/f_0:0, (1, 21904, 128), \n",
      "  exfm_part/f_1:0, (1, 9472, 128), \n",
      "  exfm_part/f_2:0, (1, 9472, 128), \n",
      "  exfm_part/w_nn_output:0, (256, 1), \n",
      "  exfm_part/b_nn_output:0, (1,), \n",
      "  epoch 0 step 1000 lr 0.001 logloss 0.619439 gN 0.28, Wed Mar 13 01:55:54 2019\n",
      "# Epcho-time 221.57s Eval AUC 0.722588. Best AUC 0.722588.\n",
      "  epoch 0 step 2000 lr 0.001 logloss 0.605522 gN 0.23, Wed Mar 13 02:00:13 2019\n",
      "# Epcho-time 480.59s Eval AUC 0.728662. Best AUC 0.728662.\n",
      "  epoch 0 step 3000 lr 0.001 logloss 0.601542 gN 0.22, Wed Mar 13 02:04:27 2019\n",
      "# Epcho-time 734.85s Eval AUC 0.731093. Best AUC 0.731093.\n",
      "  epoch 0 step 4000 lr 0.001 logloss 0.600454 gN 0.22, Wed Mar 13 02:08:45 2019\n",
      "# Epcho-time 992.46s Eval AUC 0.734103. Best AUC 0.734103.\n",
      "  epoch 0 step 5000 lr 0.001 logloss 0.599247 gN 0.21, Wed Mar 13 02:13:03 2019\n",
      "# Epcho-time 1250.29s Eval AUC 0.735912. Best AUC 0.735912.\n",
      "  epoch 0 step 6000 lr 0.001 logloss 0.597640 gN 0.21, Wed Mar 13 02:17:18 2019\n",
      "# Epcho-time 1506.11s Eval AUC 0.736866. Best AUC 0.736866.\n",
      "# Epcho-time 1754.11s Eval AUC 0.737364. Best AUC 0.737364.\n",
      "INFO:tensorflow:Restoring parameters from model_tmp/model\n",
      "# Epcho-time 1786.93s Eval AUC 0.737365. Best AUC 0.737365.\n",
      "Training Done! Inference...\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros(train.shape[0])\n",
    "for i in range(hparam.kfold):       \n",
    "        \n",
    "    print(\"Fold\",i)\n",
    "    dev_index=K_fold[i]\n",
    "    dev_index=random.sample(dev_index,int(0.1*len(dev_index)))\n",
    "    train_index=[]\n",
    "    for j in range(hparam.kfold):\n",
    "        if j!=i:\n",
    "            train_index+=K_fold[j]\n",
    "            \n",
    "    x_train = train.iloc[train_index][use_cols]\n",
    "    y_train = train.iloc[train_index][COLUMN_TARGET]\n",
    "    x_val = train.iloc[dev_index][use_cols]\n",
    "    y_val = train.iloc[dev_index][COLUMN_TARGET]\n",
    "    \n",
    "    model=ctrNet.build_model(hparam)\n",
    "    model.train(train_data=(x_train, y_train), dev_data=(x_val, y_val))\n",
    "    print(\"Training Done! Inference...\")\n",
    "    if i==0:\n",
    "        y_pred[dev_index] += model.infer(dev_data=(x_val, y_val))/hparam.kfold\n",
    "        y_test = model.infer(dev_data=(test[use_cols], test[COLUMN_TARGET]))/hparam.kfold\n",
    "    else:\n",
    "        y_pred[dev_index] += model.infer(dev_data=(x_val, y_val))/hparam.kfold\n",
    "        y_test += model.infer(dev_data=(test[use_cols],test[COLUMN_TARGET]))/hparam.kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.502331614968106\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['MachineIdentifier'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7669a6f4eb58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pkl_gzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'../stack/0313_stack_XDEEPFM_feat{x_train.shape[1]}_CV{cv}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['MachineIdentifier'] not in index\""
     ]
    }
   ],
   "source": [
    "to_pkl_gzip(obj=y_test, path = f'../output/pred_result/{start_time}_ieee__test_oof_Xdeepfm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "fcd62d5f09ca9d78e96854d84433325fb80f6096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7853253,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
