{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_numeric_features, get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename\n",
    "from func.time_utils import date_add_days, date_add_times\n",
    "from func.ml_utils import save_feature, get_cnt_feature, get_dummie_feature, get_label_feature, get_factorize_feature\n",
    "from func.parallel_utils import get_parallel_arg_list\n",
    "from joblib import delayed, Parallel\n",
    "from itertools import combinations\n",
    "\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "# COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, 'ProductCD']\n",
    "\n",
    "train_paths = glob('../feature/eda_base/*_train.gz')\n",
    "test_paths = glob('../feature/eda_base/*_test.gz')\n",
    "\n",
    "train_paths = [path for path in train_paths \n",
    "               if path.count(COLUMN_DT) \n",
    "               or path.count(COLUMN_ID)\n",
    "               or path.count(COLUMN_TARGET)\n",
    "               or path.count('time_zone')\n",
    "               or path.count('fill__cnt')\n",
    "               or path.count('bin_')\n",
    "               or path.count('ProductCD')\n",
    "              ]\n",
    "test_paths = [path for path in test_paths \n",
    "               if path.count(COLUMN_DT) \n",
    "               or path.count(COLUMN_ID)\n",
    "               or path.count(COLUMN_TARGET)\n",
    "               or path.count('time_zone')\n",
    "               or path.count('fill__cnt')\n",
    "               or path.count('bin_')\n",
    "               or path.count('ProductCD')\n",
    "              ]\n",
    "\n",
    "df_train = parallel_load_data(train_paths)\n",
    "df_test = parallel_load_data(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fill__cnt_V306</th>\n",
       "      <th>bin__C7</th>\n",
       "      <th>fill__P_emaildomain_bin</th>\n",
       "      <th>fill__cnt_V87</th>\n",
       "      <th>fill__cnt_V78</th>\n",
       "      <th>fill__cnt_V165</th>\n",
       "      <th>fill__cnt_C5</th>\n",
       "      <th>fill__cnt_addr2</th>\n",
       "      <th>fill__cnt_V314</th>\n",
       "      <th>fill__cnt_V156</th>\n",
       "      <th>...</th>\n",
       "      <th>fill__cnt_V317</th>\n",
       "      <th>fill__cnt_V281</th>\n",
       "      <th>fill__cnt_C8</th>\n",
       "      <th>fill__cnt_C6</th>\n",
       "      <th>fill__cnt_card2</th>\n",
       "      <th>fill__cnt_V265</th>\n",
       "      <th>fill__cnt_V54</th>\n",
       "      <th>fill__cnt_V37</th>\n",
       "      <th>fill__cnt_V67</th>\n",
       "      <th>ProductCD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>273</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>89</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>273</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>286</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>273</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>273</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>273</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>169</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fill__cnt_V306 bin__C7 fill__P_emaildomain_bin fill__cnt_V87 fill__cnt_V78  \\\n",
       "0            244       1                       1            31            36   \n",
       "1            244       1                       7            31            36   \n",
       "2            244       1                       8            31            36   \n",
       "3            103       1                      11            31            36   \n",
       "4            244       1                       7             3             2   \n",
       "\n",
       "  fill__cnt_V165 fill__cnt_C5 fill__cnt_addr2 fill__cnt_V314 fill__cnt_V156  \\\n",
       "0            110           12              31            273             16   \n",
       "1            110           12              31            273             16   \n",
       "2            110           12              31            273             16   \n",
       "3            110           12              31            273             16   \n",
       "4            106           12              31            273             11   \n",
       "\n",
       "   ... fill__cnt_V317 fill__cnt_V281 fill__cnt_C8 fill__cnt_C6  \\\n",
       "0  ...            113              3            6           12   \n",
       "1  ...            194              3            6           12   \n",
       "2  ...            194              3            6           12   \n",
       "3  ...            139              3            6           10   \n",
       "4  ...            194              3            4           12   \n",
       "\n",
       "  fill__cnt_card2 fill__cnt_V265 fill__cnt_V54 fill__cnt_V37 fill__cnt_V67  \\\n",
       "0              89             98             8            10            11   \n",
       "1             286             98             7            28            11   \n",
       "2             326             98             8            28            11   \n",
       "3              13             98             8            28            11   \n",
       "4             169             25             9            10            10   \n",
       "\n",
       "  ProductCD  \n",
       "0         W  \n",
       "1         W  \n",
       "2         W  \n",
       "3         W  \n",
       "4         H  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [col for col in df_train.columns if col not in COLUMNS_IGNORE]\n",
    "print('Transform all features to category.\\n')\n",
    "for usecol in use_cols:\n",
    "\n",
    "    df_train[usecol] = df_train[usecol].astype('str')\n",
    "    df_test[usecol] = df_test[usecol].astype('str')\n",
    "    \n",
    "    #Fit LabelEncoder\n",
    "    le = LabelEncoder().fit(\n",
    "            np.unique(df_train[usecol].unique().tolist()+\n",
    "                      df_test[usecol].unique().tolist()))\n",
    "\n",
    "    #At the end 0 will be used for dropped values\n",
    "    df_train[usecol] = le.transform(df_train[usecol])+1\n",
    "    df_test[usecol]  = le.transform(df_test[usecol])+1\n",
    "\n",
    "    agg_tr = (df_train\n",
    "              .groupby([usecol])\n",
    "              .aggregate({COLUMN_ID:'count'})\n",
    "              .reset_index()\n",
    "              .rename({COLUMN_ID:'df_train'}, axis=1))\n",
    "    agg_te = (df_test\n",
    "              .groupby([usecol])\n",
    "              .aggregate({COLUMN_ID:'count'})\n",
    "              .reset_index()\n",
    "              .rename({COLUMN_ID:'df_test'}, axis=1))\n",
    "\n",
    "    agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)\n",
    "    #Select values with more than 1000 observations\n",
    "    agg = agg[(agg['df_train'] > 20)].reset_index(drop=True)\n",
    "    agg['Total'] = agg['df_train'] + agg['df_test']\n",
    "    #Drop unbalanced values\n",
    "    agg = agg[(agg['df_train'] / agg['Total'] > 0.05) & (agg['df_train'] / agg['Total'] < 0.95)]\n",
    "    agg[usecol+'Copy'] = agg[usecol]\n",
    "\n",
    "    df_train[usecol] = (pd.merge(df_train[[usecol]], \n",
    "                              agg[[usecol, usecol+'Copy']], \n",
    "                              on=usecol, how='left')[usecol+'Copy']\n",
    "                     .replace(np.nan, 0).astype('int').astype('category'))\n",
    "\n",
    "    df_test[usecol]  = (pd.merge(df_test[[usecol]], \n",
    "                              agg[[usecol, usecol+'Copy']], \n",
    "                              on=usecol, how='left')[usecol+'Copy']\n",
    "                     .replace(np.nan, 0).astype('int').astype('category'))\n",
    "\n",
    "    del le, agg_tr, agg_te, agg, usecol\n",
    "    gc.collect()\n",
    "          \n",
    "y_train = np.array(df_train[COLUMN_TARGET])\n",
    "train_ids = df_train.index\n",
    "test_ids  = df_test.index\n",
    "\n",
    "del df_train[COLUMN_TARGET], df_train[COLUMN_ID], df_test[COLUMN_ID]\n",
    "del df_test[COLUMN_TARGET]\n",
    "gc.collect()\n",
    "\n",
    "print(\"If you don't want use Sparse Matrix choose Kernel Version 2 to get simple solution.\\n\")\n",
    "\n",
    "print('--------------------------------------------------------------------------------------------------------')\n",
    "print('Transform Data to Sparse Matrix.')\n",
    "print('Sparse Matrix can be used to fit a lot of models, eg. XGBoost, LightGBM, Random Forest, K-Means and etc.')\n",
    "print('To concatenate Sparse Matrices by column use hstack()')\n",
    "print('Read more about Sparse Matrix https://docs.scipy.org/doc/scipy/reference/sparse.html')\n",
    "print('Good Luck!')\n",
    "print('--------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# Fit OneHotEncoder\n",
    "data = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "ohe = OneHotEncoder(categories='auto', sparse=True, dtype='uint8').fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform data using small groups to reduce memory usage\n",
    "m = 100000\n",
    "\n",
    "# ohe = OneHotEncoder(categories='auto', sparse=True, dtype='uint8').fit(df_train)\n",
    "# ohe_train = vstack([ohe.transform(df_train[i*m:(i+1)*m]) for i in range(df_train.shape[0] // m + 1)])\n",
    "# ohe_test  = vstack([ohe.transform(df_test[i*m:(i+1)*m])  for i in range(df_test.shape[0] // m +  1)])\n",
    "\n",
    "# data = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "# ohe = OneHotEncoder(categories='auto', sparse=True, dtype='uint8').fit(data)\n",
    "# ohe_all  = vstack([ohe.transform(data[i*m:(i+1)*m])  for i in range(data.shape[0] // m +  1)])\n",
    "ohe_train = ohe_all[:len(df_train)]\n",
    "ohe_test = ohe_all[len(df_train):]\n",
    "save_npz('610_train.npz', ohe_train, compressed=True)\n",
    "save_npz('610_test.npz',  ohe_test,  compressed=True)\n",
    "\n",
    "del ohe, ohe_train, ohe_test, data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(train_ids, y_train)\n",
    "\n",
    "lgb_test_result  = np.zeros(test_ids.shape[0])\n",
    "#lgb_train_result = np.zeros(train_ids.shape[0])\n",
    "#xgb_test_result  = np.zeros(test_ids.shape[0])\n",
    "#xgb_train_result = np.zeros(train_ids.shape[0])\n",
    "counter = 0\n",
    "\n",
    "print('\\nLightGBM\\n')\n",
    "\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    \n",
    "    print('Fold {}\\n'.format(counter + 1))\n",
    "    \n",
    "    train = load_npz('train.npz')\n",
    "    X_fit = vstack([train[train_index[i*m:(i+1)*m]] for i in range(train_index.shape[0] // m + 1)])\n",
    "    X_val = vstack([train[test_index[i*m:(i+1)*m]]  for i in range(test_index.shape[0] //  m + 1)])\n",
    "    X_fit, X_val = csr_matrix(X_fit, dtype='float32'), csr_matrix(X_val, dtype='float32')\n",
    "    y_fit, y_val = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    del train\n",
    "    gc.collect()\n",
    "\n",
    "    lgb_model = lgb.LGBMClassifier(max_depth=-1,\n",
    "                                   n_estimators=30000,\n",
    "                                   learning_rate=0.05,\n",
    "                                   num_leaves=2**12-1,\n",
    "                                   colsample_bytree=0.28,\n",
    "                                   objective='binary', \n",
    "                                   n_jobs=-1)\n",
    "                                   \n",
    "    #xgb_model = xgb.XGBClassifier(max_depth=6,\n",
    "    #                              n_estimators=30000,\n",
    "    #                              colsample_bytree=0.2,\n",
    "    #                              learning_rate=0.1,\n",
    "    #                              objective='binary:logistic', \n",
    "    #                              n_jobs=-1)\n",
    "    \n",
    "                               \n",
    "    lgb_model.fit(X_fit, y_fit, eval_metric='auc', \n",
    "                  eval_set=[(X_val, y_val)], \n",
    "                  verbose=100, early_stopping_rounds=100)\n",
    "                  \n",
    "    #xgb_model.fit(X_fit, y_fit, eval_metric='auc', \n",
    "    #              eval_set=[(X_val, y_val)], \n",
    "    #              verbose=1000, early_stopping_rounds=300)\n",
    "\n",
    "    #lgb_train_result[test_index] += lgb_model.predict_proba(X_val)[:,1]\n",
    "    #xgb_train_result[test_index] += xgb_model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    del X_fit, X_val, y_fit, y_val, train_index, test_index\n",
    "    gc.collect()\n",
    "    \n",
    "    test = load_npz('test.npz')\n",
    "    test = csr_matrix(test, dtype='float32')\n",
    "    lgb_test_result += lgb_model.predict_proba(test)[:,1]\n",
    "    #xgb_test_result += xgb_model.predict_proba(test)[:,1]\n",
    "    counter += 1\n",
    "    \n",
    "    del test\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
