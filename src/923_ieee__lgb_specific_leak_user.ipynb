{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename, logger_func\n",
    "from ieee_train import eval_train, eval_check_feature\n",
    "from kaggle_utils import reduce_mem_usage, move_feature\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "try:\n",
    "    logger\n",
    "except NameError:\n",
    "    logger = logger_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMN_GROUP = 'DT-M'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, COLUMN_GROUP, 'is_train', 'datetime', 'date', 'year', 'month', 'DT-M']\n",
    "\n",
    "def filter_feature(path):\n",
    "    if path.count(''):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "paths_train = glob('../submit/re_sub/Tran*_train.gz')\n",
    "paths_test  = glob('../submit/re_sub/Tran*_test.gz')\n",
    "paths_train += glob('../submit/re_sub/is*_train.gz')\n",
    "paths_test  += glob('../submit/re_sub/is*_test.gz')\n",
    "paths_train += glob('../submit/re_sub/528__ugr_R_emaildomain_C1_C14_ratio_agg_V35_52*_train.gz')\n",
    "paths_test  += glob('../submit/re_sub/528__ugr_R_emaildomain_C1_C14_ratio_agg_V35_52*_test.gz')\n",
    "print(len(paths_train))\n",
    "\n",
    "paths_train_feature = []\n",
    "paths_test_feature  = []\n",
    "\n",
    "# df_train = reduce_mem_usage( parallel_load_data(paths_train) )\n",
    "# df_test  = reduce_mem_usage( parallel_load_data(paths_test) )\n",
    "df_train = parallel_load_data(paths_train)\n",
    "df_test  = parallel_load_data(paths_test)\n",
    "data = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Bear's score\n",
    "#========================================================================\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "bear = pd.read_csv('../input/20190913_ieee__bear_probing.csv').iloc[:, [0, 1, 2, 3, 4, 6]]\n",
    "# bear = bear[bear[COLUMN_TARGET]==-1]\n",
    "bear = bear.iloc[:, [0,1,2,3,5]]\n",
    "bear.columns = [COLUMN_ID, COLUMN_DT, col_bear, 'data_type', 'bear_probing']\n",
    "bear = bear.merge(data[[COLUMN_ID, 'DT-M']], how='inner', on=COLUMN_ID)\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission.columns = [COLUMN_ID, 'pred']\n",
    "\n",
    "\n",
    "def bear_validation(test_pred):\n",
    "    submission['pred'] = test_pred\n",
    "    bear_score = submission.merge(bear, how='inner', on=COLUMN_ID)\n",
    "    public  = bear_score[bear_score['data_type']=='test_public']\n",
    "    private = bear_score[bear_score['data_type']=='test_private']\n",
    "    \n",
    "    public_score = roc_auc_score(public[COLUMN_TARGET].values, public['pred'].values)\n",
    "    private_score = roc_auc_score(private[COLUMN_TARGET].values, private['pred'].values)\n",
    "    all_score = roc_auc_score(bear_score[COLUMN_TARGET].values, bear_score['pred'].values)\n",
    "\n",
    "    return public_score, private_score, all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([df_train, df_test], axis=0)\n",
    "startdate = datetime.datetime(2017,12,1)\n",
    "\n",
    "data['datetime'] = data['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n",
    "data['year'] = data['datetime'].map(lambda x: x.year)\n",
    "data['month'] = data['datetime'].map(lambda x: x.month)\n",
    "data['month'] = data['month'].map(lambda x: 5 if x==6 else x)\n",
    "\n",
    "data['DT-M'] = data[['year', 'month']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)\n",
    "\n",
    "\n",
    "# df_train['datetime'] = df_train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n",
    "# df_train['year'] = df_train['datetime'].map(lambda x: x.year)\n",
    "# df_train['month'] = df_train['datetime'].map(lambda x: x.month)\n",
    "# df_train['month'] = df_train['month'].map(lambda x: 5 if x==6 else x)\n",
    "# df_train['DT-M'] = df_train[['year', 'month']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)\n",
    "\n",
    "# df_test['datetime'] = df_test['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n",
    "# df_test['year'] = df_test['datetime'].map(lambda x: x.year)\n",
    "# df_test['month'] = df_test['datetime'].map(lambda x: x.month)\n",
    "# df_test['month'] = df_test['month'].map(lambda x: 5 if x==6 else x)\n",
    "\n",
    "# df_test['DT-M'] = df_test[['year', 'month']].apply(lambda x: str(x[0]) + '-' + str(x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Bear's ID\n",
    "#========================================================================\n",
    "col_bear = 'predicted_user_id'\n",
    "same_user_path = '../output/same_user_pattern/20190901_user_ids_share.csv'\n",
    "\n",
    "bear = pd.read_csv(same_user_path)\n",
    "bear = bear[[COLUMN_ID, col_bear]]\n",
    "\n",
    "# max_id = bear['predicted_user_id'].max()\n",
    "# bear.loc[bear[bear['predicted_user_id'].isnull()].index, 'predicted_user_id'] = np.arange(\n",
    "#     bear['predicted_user_id'].isnull().sum() ) + 1 + max_id\n",
    "bear['predicted_user_id'] =  bear['predicted_user_id'].fillna(-1).astype('int')\n",
    "\n",
    "data = data.merge(bear[[COLUMN_ID, 'predicted_user_id']], how='inner', on=COLUMN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lb = read_pkl_gzip('../output/pred_result/20190927_0221__CV0-9594791704263358__all_preds.gz')\n",
    "df_bear = read_pkl_gzip('../output/pred_result/20190929_1132__CV0-912702787903791__all_preds_Bear_GROUPK.gz')\n",
    "df_lb.columns = [COLUMN_ID, 'pred_lb']\n",
    "df_bear.columns = [COLUMN_ID, 'pred_bear']\n",
    "\n",
    "data['diff_pred'] = df_lb['pred_lb'] - df_bear['pred_bear']\n",
    "data['diff_pred'] = data['diff_pred'].map(lambda x: np.round(x, 2))\n",
    "data['diff_pred'] = data['diff_pred'].map(np.abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# 0.02未満の差は誤差とする\n",
    "# 予測値で0.02以上の差が開いてるIDはリークの影響を受けてるとする\n",
    "# 恐らく, bear's idとキレイに特定できているユーザーほど差が大きく、そうでないノイズがのったuser_idは差が開きにくい\n",
    "#========================================================================\n",
    "threshold = 0.01\n",
    "df_leak = data[data['diff_pred'] >= threshold]\n",
    "df_solo = data[data['diff_pred'] <  threshold]\n",
    "\n",
    "# やはりpublic/privateに差が開いてるユーザーが多め\n",
    "display(df_leak[COLUMN_TARGET].fillna(-1).value_counts())\n",
    "display(df_solo[COLUMN_TARGET].fillna(-1).value_counts())\n",
    "\n",
    "print('solo ratio leak:' , df_leak.shape, (df_leak[col_bear].value_counts()==1).sum() / df_leak.shape[0])\n",
    "print('solo ratio solo:' , df_solo.shape, (df_solo[col_bear].value_counts()==1).sum() / df_solo.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# ここで保存したそれぞれのIDグループごとに最適化を行う\n",
    "# \n",
    "#========================================================================\n",
    "leak_ids = df_leak[COLUMN_ID].values\n",
    "solo_ids = df_solo[COLUMN_ID].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = data[[col_bear, 'DT-M']].drop_duplicates().groupby(col_bear)['DT-M'].agg({\n",
    "    'count': 'count'\n",
    "})\n",
    "leak_bear = cnt[cnt>1].index\n",
    "\n",
    "all_bear = list(data[col_bear].values)\n",
    "list_solo = cnt[cnt['count']<=1].index.tolist()\n",
    "list_leak = list(set(all_bear) - set(list_solo))\n",
    "\n",
    "print(len(list_solo), len(list_leak))\n",
    "print(len(list_solo) + len(list_leak))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_solo_id = data[data[col_bear].isin(list_solo)][COLUMN_ID].values.tolist()\n",
    "bear_leak_id = data[data[col_bear].isin(list_leak)][COLUMN_ID].values.tolist()\n",
    "\n",
    "print(len(bear_solo_id) , len(bear_leak_id))\n",
    "print(len(bear_solo_id) + len(bear_leak_id))\n",
    "to_pkl_gzip(obj=leak_ids, path='../output/923_ieee__bear_leak_ids')\n",
    "to_pkl_gzip(obj=solo_ids, path='../output/923_ieee__bear_solo_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bear_solo_id))\n",
    "print( len( list(list(set(bear_solo_id) - set(leak_ids))) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = read_pkl_gzip('../output/pred_result/20190927_0221__CV0-9594791704263358__all_preds.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_solo = df_pred[df_pred[COLUMN_ID].isin(bear_solo_id)]\n",
    "df_pred_solo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_leak_ids = list(set(bear_leak_id) - set(solo_ids))\n",
    "result_solo_ids = list(set(list(bear_solo_id) + list(solo_ids)))\n",
    "\n",
    "print(len(result_leak_ids) , len(result_solo_ids))\n",
    "print(len(result_leak_ids) + len(result_solo_ids))\n",
    "\n",
    "to_pkl_gzip(obj=result_leak_ids, path='../output/923_ieee__leak_ids')\n",
    "to_pkl_gzip(obj=result_solo_ids, path='../output/923_ieee__solo_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(result_solo_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Join Prediction\n",
    "#========================================================================\n",
    "# pred = read_pkl_gzip('../output/pred_result/20190925_1450__CV0-9581588018233685__all_preds.gz').iloc[:, 1].values\n",
    "# data['pred_holy'] = pred\n",
    "\n",
    "# oof_haku = pd.read_csv('../output/oof/oof.csv').iloc[:, 1].values\n",
    "# test_haku = pd.read_csv('../output/oof/submission.csv').iloc[:, 1].values\n",
    "# data['pred_haku'] = np.hstack((oof_haku, test_haku))\n",
    "\n",
    "# oof_hmd = pd.read_csv('../output/oof/20190925_hmdhmd_oof.csv').iloc[:, 1].values\n",
    "# test_hmd = pd.read_csv('../output/oof/20190925_hmdhmd_pred.csv').iloc[:, 1].values\n",
    "# data['pred_hmd'] = np.hstack((oof_hmd, test_hmd))\n",
    "\n",
    "# oof_bear = pd.read_csv('../output/oof/20190925_all_uid_agg_stats_lr001_oof_features1381_oof0.95_pub0.984_pri0.989.csv')\n",
    "# test_bear = pd.read_csv('../output/oof/20190925_all_uid_agg_stats_lr001_pred_features1381_oof0.95_pub0.984_pri0.989.csv')\n",
    "# df_bear = pd.concat([oof_bear, test_bear], axis=0)\n",
    "# df_bear.columns = [COLUMN_ID, 'pred_bear']\n",
    "# data = data.merge(df_bear, how='inner', on=COLUMN_ID)\n",
    "\n",
    "\n",
    "pred = read_pkl_gzip('../output/pred_result/20190925_1450__CV0-9581588018233685__all_preds.gz').iloc[:len(df_train), 1].values\n",
    "df_train['pred_holy'] = pred\n",
    "oof_haku = pd.read_csv('../output/oof/oof.csv').iloc[:, 1].values\n",
    "df_train['pred_haku'] = oof_haku\n",
    "\n",
    "oof_hmd = pd.read_csv('../output/oof/20190925_hmdhmd_oof.csv').iloc[:, 1].values\n",
    "df_train['pred_hmd'] = oof_hmd\n",
    "\n",
    "oof_bear = pd.read_csv('../output/oof/20190925_all_uid_agg_stats_lr001_oof_features1381_oof0.95_pub0.984_pri0.989.csv')\n",
    "oof_bear.columns = [COLUMN_ID, 'pred_bear']\n",
    "df_train = df_train.merge(oof_bear, how='inner', on=COLUMN_ID)\n",
    "\n",
    "\n",
    "pred = read_pkl_gzip('../output/pred_result/20190925_1450__CV0-9581588018233685__all_preds.gz').iloc[len(df_train):, 1].values\n",
    "df_test['pred_holy'] = pred\n",
    "\n",
    "test_haku = pd.read_csv('../output/oof/submission.csv').iloc[:, 1].values\n",
    "df_test['pred_haku'] = test_haku\n",
    "\n",
    "test_hmd = pd.read_csv('../output/oof/20190925_hmdhmd_pred.csv').iloc[:, 1].values\n",
    "df_test['pred_hmd'] = test_hmd\n",
    "\n",
    "test_bear = pd.read_csv('../output/oof/20190925_all_uid_agg_stats_lr001_pred_features1381_oof0.95_pub0.984_pri0.989.csv')\n",
    "test_bear.columns = [COLUMN_ID, 'pred_bear']\n",
    "df_test = df_test.merge(test_bear, how='inner', on=COLUMN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# 検証するbear's idでfilter\n",
    "#========================================================================\n",
    "data.sort_values(by=COLUMN_DT, inplace=True)\n",
    "bear_first = data.groupby(col_bear)['DT-M'].first()\n",
    "bear_cnt = data.groupby(col_bear)['DT-M'].count()\n",
    "\n",
    "bear_test_user = bear_first[bear_first>='2018-7'].index\n",
    "bear_multi_cnt_user = bear_cnt[bear_cnt>3].index\n",
    "bear_valid_user = list(set(bear_test_user) & set(bear_multi_cnt_user))\n",
    "print(len(bear_valid_user))\n",
    "\n",
    "df_bear_valid = bear[bear[col_bear].isin(bear_valid_user)]\n",
    "df_bear_valid = df_bear_valid.merge(data[[COLUMN_ID, 'pred_holy', 'pred_haku', 'pred_hmd', 'pred_bear']], how='inner', on=COLUMN_ID)\n",
    "\n",
    "pd.set_option('max_rows', 1400)\n",
    "df_bear_valid.sort_values(by=[col_bear, COLUMN_DT], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_adv = pd.concat([\n",
    "df_train['528__ugr_R_emaildomain_C1_C14_ratio_agg_V35_52_mean_mean'].value_counts().rename('cnt_train'), \n",
    "df_test['528__ugr_R_emaildomain_C1_C14_ratio_agg_V35_52_mean_mean'].value_counts().rename('cnt_test')\n",
    "], axis=1)\n",
    "cnt_adv.sort_values(by='cnt_test', ascending=False, inplace=True)\n",
    "cnt_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "df_train['round_ugr'] = df_train['528__ugr_R_emaildomain_C1_C14_ratio_agg_V35_52_mean_mean'].map(lambda x: np.round(x, 2))\n",
    "list_val = []\n",
    "\n",
    "for val in tqdm(sorted(df_train['round_ugr'].unique().tolist())):\n",
    "    \n",
    "    tmp = df_train[df_train['round_ugr']==val]\n",
    "    \n",
    "    if len(tmp)==0:\n",
    "        continue\n",
    "    \n",
    "    y_train = tmp[COLUMN_TARGET].values\n",
    "    haku = tmp['pred_haku'].values\n",
    "    holy = tmp['pred_holy'].values\n",
    "    hmd = tmp['pred_hmd'].values\n",
    "    bear = tmp['pred_bear'].values\n",
    "    cnt = tmp.shape[0]\n",
    "    \n",
    "    try:\n",
    "        score_haku = roc_auc_score(y_train, haku)\n",
    "        score_hmd = roc_auc_score(y_train, hmd)\n",
    "        score_holy = roc_auc_score(y_train, holy)\n",
    "        score_bear = roc_auc_score(y_train, bear)\n",
    "        mean_haku = np.mean(haku)\n",
    "        mean_hmd  = np.mean(hmd)\n",
    "        mean_holy = np.mean(holy)\n",
    "        mean_bear = np.mean(bear)\n",
    "        max_val = np.max(y_train)\n",
    "#         print(f\" * ugr: {val} cnt: {cnt} haku: {score_haku} hmd: {score_hmd} holy: {score_holy} bear: {score_bear}\")\n",
    "        list_val.append([val, cnt, score_haku, score_hmd, score_holy, score_bear, max_val, mean_haku, mean_hmd, mean_holy, mean_bear])\n",
    "    except ValueError:\n",
    "        mean_haku = np.mean(haku)\n",
    "        mean_hmd  = np.mean(hmd)\n",
    "        mean_holy = np.mean(holy)\n",
    "        mean_bear = np.mean(bear)\n",
    "        max_val = np.max(y_train)\n",
    "#         print(f\" * ugr: {val} cnt: {tmp.shape[0]} y_train: {np.max(y_train)} \")\n",
    "        list_val.append([val, cnt, np.nan, np.nan, np.nan, np.nan, max_val, mean_haku, mean_hmd, mean_holy, mean_bear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 300)\n",
    "# ugr_train = pd.DataFrame(list_val, columns=['ugr', 'cnt', 'score_haku', 'score_hmd', 'score_holy', 'score_bear', 'max_target', 'mean_haku', 'mean_hmd', 'mean_holy', 'mean_bear'])\n",
    "ugr_train.columns = [f\"train_{col}\" if not col.count('ugr') else col  for col in ugr_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['round_ugr'] = df_test['528__ugr_R_emaildomain_C1_C14_ratio_agg_V35_52_mean_mean'].map(lambda x: np.round(x, 2))\n",
    "list_val = []\n",
    "\n",
    "for val in tqdm(sorted(df_test['round_ugr'].unique().tolist())):\n",
    "    \n",
    "    tmp = df_test[df_test['round_ugr']==val]\n",
    "    \n",
    "    if len(tmp)==0:\n",
    "        continue\n",
    "    \n",
    "    y_test = tmp[COLUMN_TARGET].values\n",
    "    haku = tmp['pred_haku'].values\n",
    "    holy = tmp['pred_holy'].values\n",
    "    hmd = tmp['pred_hmd'].values\n",
    "    bear = tmp['pred_bear'].values\n",
    "    cnt = tmp.shape[0]\n",
    "    \n",
    "    try:\n",
    "        mean_haku = np.mean(haku)\n",
    "        mean_hmd  = np.mean(hmd)\n",
    "        mean_holy = np.mean(holy)\n",
    "        mean_bear = np.mean(bear)\n",
    "        max_val = np.max(y_test)\n",
    "        list_val.append([val, cnt, max_val, mean_haku, mean_hmd, mean_holy, mean_bear])\n",
    "    except ValueError:\n",
    "        mean_haku = np.mean(haku)\n",
    "        mean_hmd  = np.mean(hmd)\n",
    "        mean_holy = np.mean(holy)\n",
    "        mean_bear = np.mean(bear)\n",
    "        max_val = np.max(y_test)\n",
    "        list_val.append([val, cnt, max_val, mean_haku, mean_hmd, mean_holy, mean_bear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugr_test = pd.DataFrame(list_val, columns=['ugr', 'cnt', 'max_target', 'mean_haku', 'mean_hmd', 'mean_holy', 'mean_bear'])\n",
    "ugr_test.columns = [f\"test_{col}\" if not col.count('ugr') else col  for col in ugr_test.columns]\n",
    "ugr_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ugr = ugr_train.merge(ugr_test, how='outer', on='ugr')\n",
    "df_ugr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ugr.to_csv('../output/0928_ieee__528__ugr_R_emaildomain_C1_C14_ratio_agg_V35_52_mean_mean__round2__score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_bear = 'predicted_user_id'\n",
    "# cols_pred = [col for col in df_train.columns if col.count('pred')]\n",
    "\n",
    "# if col_bear not in df_train.columns:\n",
    "#     df_train = df_train.merge(df_user_id_bear[[COLUMN_ID, col_bear]], how='left', on=COLUMN_ID)\n",
    "\n",
    "tmp = df_train[(0.959<df_train['round_ugr']) \n",
    "         &\n",
    "         (df_train['round_ugr']<0.961)][[COLUMN_ID, 'DT-M', 'datetime', COLUMN_TARGET] + cols_pred]\n",
    "tmp.sort_values(by=COLUMN_TARGET, ascending=False, inplace=True)\n",
    "tmp = tmp[tmp[COLUMN_TARGET]==1]\n",
    "\n",
    "low_ids = tmp[col_bear].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_low = df_train[df_train[col_bear].isin(low_ids)][[COLUMN_ID, 'DT-M', 'datetime', COLUMN_TARGET] + cols_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_low.sort_values(by=[col_bear, 'datetime'], inplace=True)\n",
    "train_low.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
