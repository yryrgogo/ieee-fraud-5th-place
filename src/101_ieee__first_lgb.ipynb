{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from func.utils import get_categorical_features\n",
    "from func.ml_utils import Classifier\n",
    "from func.BigQuery import BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionDT  TransactionAmt  card1  card2  card3  card5  addr1  addr2  \\\n",
       "0          86400            68.5  13926    NaN  150.0  142.0  315.0   87.0   \n",
       "1          86401            29.0   2755  404.0  150.0  102.0  325.0   87.0   \n",
       "2          86469            59.0   4663  490.0  150.0  166.0  330.0   87.0   \n",
       "3          86499            50.0  18132  567.0  150.0  117.0  476.0   87.0   \n",
       "4          86506            50.0   4497  514.0  150.0  102.0  420.0   87.0   \n",
       "\n",
       "   dist1  dist2  ...  V330  V331  V332  V333  V334  V335  V336  V337  V338  \\\n",
       "0   19.0    NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1    NaN    NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2  287.0    NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3    NaN    NaN  ...   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "4    NaN    NaN  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   V339  \n",
       "0   NaN  \n",
       "1   NaN  \n",
       "2   NaN  \n",
       "3   NaN  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_TARGET]\n",
    "\n",
    "train_df = pd.read_csv('../input/train_transaction.csv')\n",
    "test_df  = pd.read_csv('../input/test_transaction.csv')\n",
    "\n",
    "COLUMNS_CATEGORY = get_categorical_features(train_df, COLUMNS_IGNORE)\n",
    "use_cols = [col for col in train_df.columns if col not in COLUMNS_IGNORE+COLUMNS_CATEGORY]\n",
    "\n",
    "Y = train_df[COLUMN_TARGET]\n",
    "train_df = train_df[use_cols]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.884668\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's auc: 0.888564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.855407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.858865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.918391\n",
      "[400]\tvalid_0's auc: 0.924825\n",
      "[600]\tvalid_0's auc: 0.926378\n",
      "[800]\tvalid_0's auc: 0.928353\n",
      "[1000]\tvalid_0's auc: 0.928763\n",
      "[1200]\tvalid_0's auc: 0.928976\n",
      "Early stopping, best iteration is:\n",
      "[1159]\tvalid_0's auc: 0.929609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/yryrgogo/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:1225: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.894831\n",
      "[400]\tvalid_0's auc: 0.903136\n",
      "[600]\tvalid_0's auc: 0.904273\n",
      "Early stopping, best iteration is:\n",
      "[553]\tvalid_0's auc: 0.904977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())[:13]\n",
    "\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits)\n",
    "kfold = list(kfold.split(train_df, Y))\n",
    "params = {}\n",
    "metric = 'auc'\n",
    "model_type = 'lgb'\n",
    "score_list = []\n",
    "feim_list  = []\n",
    "y_pred = np.zeros(len(train_df))\n",
    "test_preds = []\n",
    "use_cols = [col for col in dataset.columns if col not in COLUMNS_IGNORE+COLUMNS_CATEGORY]\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(kfold):\n",
    "    x_train = train_df.iloc[trn_idx][use_cols]\n",
    "    y_train = Y.iloc[trn_idx]\n",
    "    x_valid = train_df.iloc[val_idx][use_cols]\n",
    "    y_valid = Y.iloc[val_idx]\n",
    "\n",
    "    score, oof_pred, test_pred, feim, _, params = Classifier(\n",
    "        model_type=model_type,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_valid=x_valid,\n",
    "        y_valid=y_valid,\n",
    "        x_test=[],\n",
    "        params=params,\n",
    "    )\n",
    "    score_list.append(score)\n",
    "    y_pred[val_idx] = oof_pred\n",
    "    test_preds.append(test_pred)\n",
    "    \n",
    "    feim.rename(columns={'importance': f'importance_fold{n_fold+1}'}, inplace=True)\n",
    "    feim.set_index('feature', inplace=True)\n",
    "    feim_list.append(feim)\n",
    "    \n",
    "cv_score = np.mean(score_list)\n",
    "feim_df = pd.concat(feim_list, axis=1)\n",
    "feim_df['importance_avg'] = feim_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_fold1</th>\n",
       "      <th>importance_fold2</th>\n",
       "      <th>importance_fold3</th>\n",
       "      <th>importance_fold4</th>\n",
       "      <th>importance_fold5</th>\n",
       "      <th>importance_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V258</th>\n",
       "      <td>54054.152344</td>\n",
       "      <td>65909.859375</td>\n",
       "      <td>66860.671875</td>\n",
       "      <td>63341.277344</td>\n",
       "      <td>67058.414062</td>\n",
       "      <td>63444.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>30741.880859</td>\n",
       "      <td>22999.960938</td>\n",
       "      <td>22135.201172</td>\n",
       "      <td>31540.441406</td>\n",
       "      <td>30142.542969</td>\n",
       "      <td>27512.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C14</th>\n",
       "      <td>17157.562500</td>\n",
       "      <td>16444.818359</td>\n",
       "      <td>18448.966797</td>\n",
       "      <td>22242.355469</td>\n",
       "      <td>23464.916016</td>\n",
       "      <td>19551.722656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionDT</th>\n",
       "      <td>16628.685547</td>\n",
       "      <td>1373.168945</td>\n",
       "      <td>1729.534912</td>\n",
       "      <td>20299.755859</td>\n",
       "      <td>12669.451172</td>\n",
       "      <td>10540.120117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>6561.610352</td>\n",
       "      <td>6513.270996</td>\n",
       "      <td>5934.631836</td>\n",
       "      <td>16000.671875</td>\n",
       "      <td>14143.941406</td>\n",
       "      <td>9830.825195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance_fold1  importance_fold2  importance_fold3  \\\n",
       "feature                                                               \n",
       "V258               54054.152344      65909.859375      66860.671875   \n",
       "C1                 30741.880859      22999.960938      22135.201172   \n",
       "C14                17157.562500      16444.818359      18448.966797   \n",
       "TransactionDT      16628.685547       1373.168945       1729.534912   \n",
       "D2                  6561.610352       6513.270996       5934.631836   \n",
       "\n",
       "               importance_fold4  importance_fold5  importance_avg  \n",
       "feature                                                            \n",
       "V258               63341.277344      67058.414062    63444.875000  \n",
       "C1                 31540.441406      30142.542969    27512.005859  \n",
       "C14                22242.355469      23464.916016    19551.722656  \n",
       "TransactionDT      20299.755859      12669.451172    10540.120117  \n",
       "D2                 16000.671875      14143.941406     9830.825195  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feim_df.sort_values(by='importance_avg', ascending=False, inplace=True)\n",
    "display(feim_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V258', 'C1', 'C14', 'TransactionDT', 'D2', 'V201', 'card1', 'card2',\n",
       "       'V294', 'C13', 'C4', 'TransactionAmt', 'addr1', 'V283', 'D15', 'D10',\n",
       "       'C11', 'V308', 'card5', 'C2', 'C6', 'C10', 'D1', 'dist1', 'C8', 'D4',\n",
       "       'C12', 'D3', 'V156', 'V187', 'V317', 'D8', 'card3', 'V33', 'V315',\n",
       "       'V307', 'C5', 'V34', 'C9', 'V91', 'V313', 'V44', 'V90', 'D11', 'V94',\n",
       "       'V29', 'V130', 'V87', 'V310', 'V62', 'V69', 'D6', 'V49', 'V53', 'V102',\n",
       "       'addr2', 'V45', 'V282', 'V67', 'V312', 'V83', 'V314', 'V76', 'V48',\n",
       "       'D12', 'V61', 'V30', 'V285', 'D13', 'V189', 'V149', 'V209', 'V281',\n",
       "       'dist2', 'V207', 'V322', 'V295', 'V82', 'V131', 'V266', 'V20', 'V70',\n",
       "       'V133', 'V74', 'V54', 'D14', 'V320', 'V257', 'V66', 'V318', 'D9',\n",
       "       'V323', 'V243', 'D5', 'V165', 'V13', 'V225', 'V56', 'V12', 'V36'],\n",
       "      dtype='object', name='feature')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS_TOP100 = feim_df['importance_avg'].head(100).index\n",
    "COLUMNS_TOP100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_avg = np.zeros(test_df.shape[0])\n",
    "all_pred = np.append(y_pred, test_pred_avg)\n",
    "all_ids = np.append(dataset[COLUMN_ID], test_df[COLUMN_ID])\n",
    "result_pred = pd.Series(all_pred, index=all_ids, name='pred_' + start_time)\n",
    "\n",
    "# to_pkl_gzip(obj=result_pred, path=f\"../output/result_pred/{start_time}__CV{str(cv_score).replace('.', '-')}__all_preds\")\n",
    "result_pred = read_pkl_gzip(path=f\"../output/result_pred/20190717_0811__CV0-8874842732034365__all_preds.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-17 09:59:05,351 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,351 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,351 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,351 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,351 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,615 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,615 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,615 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,615 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,615 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,750 func.BigQuery 73 [INFO]    [create_table] Table 0717_0941__ieee__pred_value_log created. \n",
      "2019-07-17 09:59:05,750 func.BigQuery 73 [INFO]    [create_table] Table 0717_0941__ieee__pred_value_log created. \n",
      "2019-07-17 09:59:05,750 func.BigQuery 73 [INFO]    [create_table] Table 0717_0941__ieee__pred_value_log created. \n",
      "2019-07-17 09:59:05,750 func.BigQuery 73 [INFO]    [create_table] Table 0717_0941__ieee__pred_value_log created. \n",
      "2019-07-17 09:59:05,750 func.BigQuery 73 [INFO]    [create_table] Table 0717_0941__ieee__pred_value_log created. \n",
      "2019-07-17 09:59:05,757 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,757 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,757 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,757 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,757 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,757 func.BigQuery 32 [INFO]    [logger_func] start \n",
      "2019-07-17 09:59:05,910 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,910 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,910 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,910 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,910 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n",
      "2019-07-17 09:59:05,910 func.BigQuery 53 [INFO]    [_set_dataset] Setup Dataset dim_ml_dataset. \n"
     ]
    }
   ],
   "source": [
    "from bq_log import pred_table\n",
    "pred_table(result_pred.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-64d41e11ad32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbq_log\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_train_log_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_train_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlb_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from bq_log import create_train_log_table, save_train_log\n",
    "\n",
    "lb_score = np.nan\n",
    "metric = 'auc'\n",
    "\n",
    "create_train_log_table()\n",
    "\n",
    "log_map = {}\n",
    "log_map['exp_date']    = start_time\n",
    "log_map['n_features']  = train_df.shape[1]\n",
    "log_map['n_rows']      = train_df.shape[0]\n",
    "log_map['cv_score']    = cv_score\n",
    "log_map['fold1_score'] = score_list[0]\n",
    "log_map['fold2_score'] = score_list[1]\n",
    "log_map['fold3_score'] = score_list[2]\n",
    "log_map['fold4_score'] = score_list[3]\n",
    "log_map['fold5_score'] = score_list[4]\n",
    "log_map['seed']        = seed\n",
    "log_map['metric']      = metric\n",
    "log_map['model_type']  = model_type\n",
    "save_train_log(log_map, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
