{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename, logger_func, timer\n",
    "from func.ml_utils import Regressor\n",
    "from ieee_train import eval_train, eval_check_feature\n",
    "from kaggle_utils import reduce_mem_usage, move_feature\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, GroupKFold\n",
    "try:\n",
    "    logger\n",
    "except NameError:\n",
    "    logger = logger_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "COLUMN_TARGET = sys.argv[1]\n",
    "\n",
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_GROUP = 'DT-M'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, COLUMN_GROUP, 'isFraud', 'is_train', 'date', 'DT-M', 'predicted_user_id']\n",
    "\n",
    "def filter_feature(path):\n",
    "    if path.count(''):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "paths_train = glob('../submit/re_sub/70*_train.gz')\n",
    "paths_test  = glob('../submit/re_sub/70*_test.gz')\n",
    "paths_train += glob('../submit/re_sub/is*_train.gz')\n",
    "paths_test  += glob('../submit/re_sub/is*_test.gz')\n",
    "paths_train += glob('../submit/re_sub/Tran*_train.gz')\n",
    "paths_test  += glob('../submit/re_sub/Tran*_test.gz')\n",
    "\n",
    "print(len(paths_train))\n",
    "\n",
    "df_train = parallel_load_data(paths_train)\n",
    "df_test  = parallel_load_data(paths_test)\n",
    "\n",
    "Y = df_train[COLUMN_TARGET]\n",
    "df_train.drop(COLUMN_TARGET, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Diff Features: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-30 00:35:52,643 func.utils 58 [INFO]    [<module>] * EXP: dataset new_set (590540, 10) lr 1.0  \n"
     ]
    }
   ],
   "source": [
    "is_submit = [True, False][0]\n",
    "n_splits = 6\n",
    "set_type = 'new_set'\n",
    "\n",
    "tmp_train = df_train\n",
    "tmp_test = df_test\n",
    "\n",
    "#========================================================================\n",
    "# Train Test で片方に存在しないFeatureを除外\n",
    "#========================================================================\n",
    "diff_cols = list(set(tmp_train.columns) - set(tmp_test.columns))\n",
    "\n",
    "for col in list(set(diff_cols)):\n",
    "    from_dir = 'valid'\n",
    "    to_dir = 'valid_trush'\n",
    "    move_feature([col], from_dir, to_dir)\n",
    "tmp_train.drop(diff_cols, axis=1, inplace=True)\n",
    "print(f\"  * Diff Features: {len(diff_cols)}\")\n",
    "\n",
    "### DT-M\n",
    "group_kfold_path = '../input/0908_ieee__DT-M_GroupKFold.gz'\n",
    "group = read_pkl_gzip(group_kfold_path)\n",
    "tmp_train[COLUMN_GROUP] = group\n",
    "\n",
    "\n",
    "model_type = \"lgb\"\n",
    "params = {\n",
    "#     'n_jobs': 60,\n",
    "    'n_jobs': 96,\n",
    "#     'n_jobs': 84,\n",
    "#     'n_jobs': 48,\n",
    "#     'n_jobs': 36,\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 2**8-1,\n",
    "    'max_depth': -1,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'colsample_bytree' : 0.10,\n",
    "    'lambda_l1' : 0.1,\n",
    "    'lambda_l2' : 1.0,\n",
    "    'learning_rate' : 0.1,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"seed\": 1208,\n",
    "    \"bagging_seed\": 1208,\n",
    "    \"feature_fraction_seed\": 1208,\n",
    "    \"drop_seed\": 1208,\n",
    "    'n_splits': n_splits,\n",
    "    'metric': 'auc',\n",
    "    'model_type': model_type,\n",
    "    'fold': ['stratified', 'group'][1],\n",
    "}\n",
    "if is_submit:\n",
    "    params['learning_rate'] = 0.01\n",
    "    params['learning_rate'] = 0.05\n",
    "    params['learning_rate'] = 1.0\n",
    "    params[\"early_stopping_rounds\"] = 1\n",
    "\n",
    "logger.info(f\"* EXP: dataset {set_type} {tmp_train.shape} lr {params['learning_rate']} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l2: 0.0252483\n",
      "[  * Fold0 Validation-DT-M 2017-12: 134339] done in 2 s\n",
      "====================\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l2: 0.0364717\n",
      "[  * Fold1 Validation-DT-M 2018-3: 101968] done in 1 s\n",
      "====================\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's l2: 0.0345487\n",
      "[  * Fold2 Validation-DT-M 2018-1: 92510] done in 1 s\n",
      "====================\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's l2: 0.0313687\n",
      "[  * Fold3 Validation-DT-M 2018-5: 92427] done in 1 s\n",
      "====================\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's l2: 0.0345455\n",
      "[  * Fold4 Validation-DT-M 2018-2: 85725] done in 1 s\n",
      "====================\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l2: 0.0319243\n",
      "[  * Fold5 Validation-DT-M 2018-4: 83571] done in 0 s\n",
      "[  * Make Prediction Result File.] done in 50 s\n"
     ]
    }
   ],
   "source": [
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())[:13]\n",
    "seed       = params['seed']\n",
    "model_type = params['model_type']\n",
    "n_splits = params['n_splits']\n",
    "validation = params['fold']\n",
    "early_stopping_rounds = params['early_stopping_rounds']\n",
    "\n",
    "use_cols = [col for col in tmp_train.columns if col not in COLUMNS_IGNORE]\n",
    "\n",
    "kfold = list(GroupKFold(n_splits=n_splits).split(tmp_train, Y, tmp_train[COLUMN_GROUP]))\n",
    "\n",
    "score_list = []\n",
    "feim_list = []\n",
    "y_pred = np.zeros(len(tmp_train))\n",
    "test_preds = []\n",
    "\n",
    "x_test = df_test[use_cols]\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(kfold):\n",
    "    x_train = tmp_train.iloc[trn_idx][use_cols]\n",
    "    y_train = Y.iloc[trn_idx]\n",
    "    x_valid = tmp_train.iloc[val_idx][use_cols]\n",
    "    y_valid = Y.iloc[val_idx]\n",
    "\n",
    "    val_gr = tmp_train.iloc[val_idx][COLUMN_GROUP].value_counts()\n",
    "    dtm = val_gr.index.tolist()[0]\n",
    "    print(\"=\"*20)\n",
    "    with timer(f\"  * Fold{n_fold} Validation-{COLUMN_GROUP} {dtm}: {val_gr.values[0]}\"):\n",
    "        score, oof_pred, test_pred, feim, _ = Regressor(\n",
    "            model_type=model_type,\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            x_valid=x_valid,\n",
    "            y_valid=y_valid,\n",
    "            x_test=x_test,\n",
    "            params=params,\n",
    "            early_stopping_rounds = early_stopping_rounds,\n",
    "        )\n",
    "\n",
    "    score_list.append(score)\n",
    "    y_pred[val_idx] = oof_pred\n",
    "    test_preds.append(test_pred)\n",
    "\n",
    "    feim.rename(columns={'importance': f'imp_fold{n_fold+1}'}, inplace=True)\n",
    "    feim.set_index('feature', inplace=True)\n",
    "    feim_list.append(feim)\n",
    "\n",
    "cv_score = np.mean(score_list)\n",
    "cvs = str(cv_score).replace('.', '-')\n",
    "df_feim = pd.concat(feim_list, axis=1)\n",
    "df_feim['imp_avg'] = df_feim.mean(axis=1)\n",
    "df_feim.sort_values(by='imp_avg', ascending=False, inplace=True)\n",
    "\n",
    "## Save\n",
    "# Feature Importance\n",
    "to_pkl_gzip(obj=df_feim, path=f\"../output/feature_importances/{start_time}__CV{cvs}__{COLUMN_TARGET}__feature{len(use_cols)}\")\n",
    "\n",
    "\n",
    "with timer(\"  * Make Prediction Result File.\"):\n",
    "    test_pred_avg = np.mean(test_preds, axis=0)\n",
    "    all_pred = np.append(y_pred, test_pred_avg)\n",
    "    all_ids = np.append(tmp_train[COLUMN_ID].values, df_test[COLUMN_ID].values)\n",
    "    pred_result = pd.DataFrame([all_ids, all_pred], index=[COLUMN_ID, 'pred_' + start_time]).T\n",
    "    pred_result[COLUMN_ID] = pred_result[COLUMN_ID].astype('int')\n",
    "\n",
    "    #========================================================================\n",
    "    # Save\n",
    "    #========================================================================\n",
    "    # Prediction\n",
    "    to_pkl_gzip(obj=pred_result, path=f\"../output/pred_result/{start_time}__CV{cvs}__all_preds\")\n",
    "    # Submit File\n",
    "    pred_result.columns = [COLUMN_ID, COLUMN_TARGET]\n",
    "    pred_result.iloc[len(tmp_train):].to_csv(f\"../submit/tmp/{start_time}__CV{cvs}__feature{len(use_cols)}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-27f56e0846b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "estimator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
