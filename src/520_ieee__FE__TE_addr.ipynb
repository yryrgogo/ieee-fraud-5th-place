{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename\n",
    "from func.ml_utils import save_feature, get_cnt_feature, get_dummie_feature, get_label_feature\n",
    "from ieee_train import eval_train, eval_check_feature\n",
    "from kaggle_utils import reduce_mem_usage, move_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, 'is_train', 'date']\n",
    "\n",
    "def filter_feature(path):\n",
    "    if path.count('') :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "paths_train = glob('../feature/eda_base/*_train.gz')\n",
    "paths_train = [path for path in paths_train if filter_feature(path) ]\n",
    "df_train = parallel_load_data(paths_train)\n",
    "\n",
    "paths_test = glob('../feature/eda_base/*_test.gz')\n",
    "paths_test = [path for path in paths_test if filter_feature(path) ]\n",
    "df_test = parallel_load_data(paths_test)\n",
    "\n",
    "group_kfold_path = '../input/0908_ieee__DT-M_GroupKFold.gz'\n",
    "group = read_pkl_gzip(group_kfold_path)\n",
    "COLUMN_GROUP = 'DT-M'\n",
    "df_train[COLUMN_GROUP] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['addr2', 'addr1']\n",
      "(590540,) | addr2_fraud_all_mean\n",
      "(590540,) | addr2_no_fraud_sum\n",
      "(590540,) | addr2_monthly_fraud_prob_max_min_diff\n",
      "(590540,) | addr2_monthly_fraud_prob_max_min_ratio\n",
      "(590540,) | addr2_monthly_fraud_prob_std\n",
      "(590540,) | addr2_monthly_fraud_ratio_max_min_diff\n",
      "(590540,) | addr2_monthly_fraud_ratio_max_min_ratio\n",
      "(590540,) | addr2_monthly_fraud_ratio_std\n",
      "(590540,) | addr2_fraud_prob_weighted_mean\n",
      "(590540,) | addr2_fraud_prob_trend\n",
      "(590540,) | addr2_fraud_ratio_weighted_mean\n",
      "(506691,) | addr2_fraud_all_mean\n",
      "(506691,) | addr2_no_fraud_sum\n",
      "(506691,) | addr2_monthly_fraud_prob_max_min_diff\n",
      "(506691,) | addr2_monthly_fraud_prob_max_min_ratio\n",
      "(506691,) | addr2_monthly_fraud_prob_std\n",
      "(506691,) | addr2_monthly_fraud_ratio_max_min_diff\n",
      "(506691,) | addr2_monthly_fraud_ratio_max_min_ratio\n",
      "(506691,) | addr2_monthly_fraud_ratio_std\n",
      "(506691,) | addr2_fraud_prob_weighted_mean\n",
      "(506691,) | addr2_fraud_prob_trend\n",
      "(506691,) | addr2_fraud_ratio_weighted_mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:13<00:13, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540,) | addr1_fraud_all_mean\n",
      "(590540,) | addr1_no_fraud_sum\n",
      "(590540,) | addr1_monthly_fraud_prob_max_min_diff\n",
      "(590540,) | addr1_monthly_fraud_prob_max_min_ratio\n",
      "(590540,) | addr1_monthly_fraud_prob_std\n",
      "(590540,) | addr1_monthly_fraud_ratio_max_min_diff\n",
      "(590540,) | addr1_monthly_fraud_ratio_max_min_ratio\n",
      "(590540,) | addr1_monthly_fraud_ratio_std\n",
      "(590540,) | addr1_fraud_prob_weighted_mean\n",
      "(590540,) | addr1_fraud_prob_trend\n",
      "(590540,) | addr1_fraud_ratio_weighted_mean\n",
      "(506691,) | addr1_fraud_all_mean\n",
      "(506691,) | addr1_no_fraud_sum\n",
      "(506691,) | addr1_monthly_fraud_prob_max_min_diff\n",
      "(506691,) | addr1_monthly_fraud_prob_max_min_ratio\n",
      "(506691,) | addr1_monthly_fraud_prob_std\n",
      "(506691,) | addr1_monthly_fraud_ratio_max_min_diff\n",
      "(506691,) | addr1_monthly_fraud_ratio_max_min_ratio\n",
      "(506691,) | addr1_monthly_fraud_ratio_std\n",
      "(506691,) | addr1_fraud_prob_weighted_mean\n",
      "(506691,) | addr1_fraud_prob_trend\n",
      "(506691,) | addr1_fraud_ratio_weighted_mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:30<00:00, 14.59s/it]\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Target Encoding\n",
    "# 当月のTargetはNullとして計算する\n",
    "#========================================================================\n",
    "dir_save = 'valid'\n",
    "\n",
    "weight_map = {\n",
    "    '2017-12': 0.25,\n",
    "    '2018-1' : 0.40,\n",
    "    '2018-2' : 0.55,\n",
    "    '2018-3' : 0.70,\n",
    "    '2018-4' : 0.85,\n",
    "    '2018-5' : 1.0,\n",
    "}\n",
    "\n",
    "cols_addr = [col for col in df_train.columns if col.startswith('addr')]\n",
    "cols_DTM = df_train['DT-M'].unique().tolist()\n",
    "print(cols_addr)\n",
    "\n",
    "for col in tqdm(cols_addr):\n",
    "    base_train = df_train[[col, 'DT-M']]\n",
    "    base_test = df_test[[col]]\n",
    "    list_dtm = []\n",
    "        \n",
    "    for dtm in cols_DTM + ['test']:\n",
    "        \n",
    "        if dtm==\"2017-12\":\n",
    "            weight_map = {\n",
    "                '2018-1' : 1.0,\n",
    "                '2018-2' : 0.8,\n",
    "                '2018-3' : 0.6,\n",
    "                '2018-4' : 0.4,\n",
    "                '2018-5' : 0.2,\n",
    "            }\n",
    "        elif dtm==\"2018-1\":\n",
    "            weight_map = {\n",
    "                '2017-12' : 1.0,\n",
    "                '2018-2' : 0.8,\n",
    "                '2018-3' : 0.6,\n",
    "                '2018-4' : 0.4,\n",
    "                '2018-5' : 0.2,\n",
    "            }\n",
    "        elif dtm==\"2018-2\":\n",
    "            weight_map = {\n",
    "                '2017-12' : 0.8,\n",
    "                '2018-1' : 1.0,\n",
    "                '2018-3' : 0.6,\n",
    "                '2018-4' : 0.4,\n",
    "                '2018-5' : 0.2,\n",
    "            }\n",
    "        elif dtm==\"2018-3\":\n",
    "            weight_map = {\n",
    "                '2017-12' : 0.6,\n",
    "                '2018-1' : 0.8,\n",
    "                '2018-2' : 1.0,\n",
    "                '2018-4' : 0.4,\n",
    "                '2018-5' : 0.2,\n",
    "            }\n",
    "        elif dtm==\"2018-4\":\n",
    "            weight_map = {\n",
    "                '2017-12' : 0.4,\n",
    "                '2018-1' : 0.6,\n",
    "                '2018-2' : 0.8,\n",
    "                '2018-3' : 1.0,\n",
    "                '2018-5' : 0.2,\n",
    "            }\n",
    "        elif dtm==\"2018-5\":\n",
    "            weight_map = {\n",
    "                '2017-12' : 0.2,\n",
    "                '2018-1' : 0.4,\n",
    "                '2018-2' : 0.6,\n",
    "                '2018-3' : 0.8,\n",
    "                '2018-4' : 1.0,\n",
    "            }\n",
    "        else:\n",
    "            weight_map = {\n",
    "                '2017-12' : 0.25,\n",
    "                '2018-1' : 0.40,\n",
    "                '2018-2' : 0.55,\n",
    "                '2018-3' : 0.70,\n",
    "                '2018-4' : 0.85,\n",
    "                '2018-5' : 1.0,\n",
    "            }\n",
    "        \n",
    "        if dtm != 'test':\n",
    "            df = df_train[df_train['DT-M']!=dtm].copy()\n",
    "        else:\n",
    "            df = df_train.copy()\n",
    "        \n",
    "        tmp = df.groupby([COLUMN_GROUP,col], as_index=False)[COLUMN_TARGET].agg({\n",
    "            f'{col}_mean': 'mean'\n",
    "        })\n",
    "        tmp_all = df.groupby([col], as_index=False)[COLUMN_TARGET].agg({\n",
    "            f'{col}_fraud_all_mean': 'mean'\n",
    "        })\n",
    "        merge = tmp_all.merge(tmp, how='left', on=col)\n",
    "    \n",
    "        # pd.set_option('max_rows', 100)\n",
    "        merge['ratio'] = merge[f'{col}_mean'] / (merge[f'{col}_fraud_all_mean'] + 1)\n",
    "        \n",
    "        merge.reset_index(inplace=True)\n",
    "        tmp_base = merge[[col, f'{col}_fraud_all_mean']].drop_duplicates()\n",
    "        merge.set_index(col, inplace=True)\n",
    "        tmp_base.set_index(col, inplace=True)\n",
    "        \n",
    "        merge['no_fraud'] = (merge[f'{col}_mean']==0)\n",
    "        tmp_base[f'{col}_no_fraud_sum'] = merge.groupby(col)['no_fraud'].sum()\n",
    "        \n",
    "        tmp_base[f'{col}_monthly_fraud_prob_max_min_diff'] = merge.groupby(col)[f'{col}_mean'].max() - merge.groupby(col)[f'{col}_mean'].min()\n",
    "        tmp_base[f'{col}_monthly_fraud_prob_max_min_ratio'] = merge.groupby(col)[f'{col}_mean'].max() / (merge.groupby(col)[f'{col}_mean'].min()+ 1)\n",
    "        tmp_base[f'{col}_monthly_fraud_prob_std'] = merge.groupby(col)[f'{col}_mean'].std()\n",
    "        \n",
    "        tmp_base[f'{col}_monthly_fraud_ratio_max_min_diff'] = merge.groupby(col)['ratio'].max() - merge.groupby(col)['ratio'].min()\n",
    "        tmp_base[f'{col}_monthly_fraud_ratio_max_min_diff'] = merge.groupby(col)['ratio'].max() - merge.groupby(col)['ratio'].min()\n",
    "        tmp_base[f'{col}_monthly_fraud_ratio_max_min_ratio'] = merge.groupby(col)['ratio'].max() / (merge.groupby(col)['ratio'].min() + 1)\n",
    "        tmp_base[f'{col}_monthly_fraud_ratio_std'] = merge.groupby(col)['ratio'].std()\n",
    "        \n",
    "        # Weighted Mean\n",
    "        merge['weight'] = merge['DT-M'].map(weight_map)\n",
    "        merge[f'{col}_weight'] = merge['weight'] * merge[f'{col}_mean']\n",
    "        merge[f'ratio_weight'] = merge['weight'] * merge[f'ratio']\n",
    "        \n",
    "        tmp_base[f'{col}_fraud_prob_weighted_mean'] = merge.groupby(col)[f'{col}_weight'].sum() / merge.groupby(col)['weight'].sum()\n",
    "        tmp_base[f'{col}_fraud_prob_trend'] = tmp_base[f'{col}_fraud_prob_weighted_mean'] / (tmp_base[f'{col}_fraud_all_mean'] + 1)\n",
    "        \n",
    "        tmp_base[f'{col}_fraud_ratio_weighted_mean'] = merge.groupby(col)[f'ratio_weight'].sum() / merge.groupby(col)['weight'].sum()\n",
    "        \n",
    "        tmp_base.fillna(0, inplace=True)\n",
    "        \n",
    "        if dtm != 'test':\n",
    "            tmp_base['DT-M'] = dtm\n",
    "            list_dtm.append(tmp_base)\n",
    "        else:\n",
    "            test_TE = tmp_base\n",
    "        \n",
    "    train_TE = pd.concat(list_dtm, axis=0)\n",
    "    result_train = base_train.merge(train_TE, how='left', on=[col, 'DT-M'])\n",
    "    result_test = base_test.merge(test_TE, how='left', on=[col])\n",
    "    \n",
    "    cols_save = [col for col in result_train.columns if col.count(f'_fraud_')]\n",
    "    \n",
    "    save_feature(result_train[cols_save], '519', dir_save, is_train=True, auto_type=True, list_ignore=COLUMNS_IGNORE)\n",
    "    save_feature(result_test[cols_save],  '519', dir_save, is_train=False, auto_type=True, list_ignore=COLUMNS_IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
