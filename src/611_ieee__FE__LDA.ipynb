{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_numeric_features, get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename\n",
    "from func.time_utils import date_add_days, date_add_times\n",
    "from func.ml_utils import save_feature, get_cnt_feature, get_dummie_feature, get_label_feature\n",
    "from func.parallel_utils import get_parallel_arg_list\n",
    "from kaggle_utils import reduce_mem_usage, move_feature\n",
    "from joblib import delayed, Parallel\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from itertools import combinations, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 785.85 MB\n",
      "Memory usage after optimization is: 380.89 MB\n",
      "Decreased by 51.5%\n"
     ]
    }
   ],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, 'ProductCD']\n",
    "\n",
    "train_paths = glob('../feature/eda_base/*_train.gz')\n",
    "test_paths = glob('../feature/eda_base/*_test.gz')\n",
    "\n",
    "train_paths = [path for path in train_paths \n",
    "               if path.count(COLUMN_DT) \n",
    "               or path.count(COLUMN_ID)\n",
    "               or path.count(COLUMN_TARGET)\n",
    "               or path.count('fill__cnt')\n",
    "               or path.count('bin_')\n",
    "              ]\n",
    "test_paths = [path for path in test_paths \n",
    "               if path.count(COLUMN_DT) \n",
    "               or path.count(COLUMN_ID)\n",
    "               or path.count(COLUMN_TARGET)\n",
    "               or path.count('fill__cnt')\n",
    "               or path.count('bin_')\n",
    "              ]\n",
    "\n",
    "df_train = parallel_load_data(train_paths)\n",
    "df_test = parallel_load_data(test_paths)\n",
    "data = pd.concat([df_train, df_test], axis=0)\n",
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = sorted([col for col in  df_train.columns if col not in COLUMNS_IGNORE])\n",
    "cols_cnt_card   = sorted([col for col in use_cols if col.count('card') and col.count('cnt') and not col.count('4') and not col.count('6')])\n",
    "cols_cnt_addr   = sorted([col for col in use_cols if col.count('addr') and col.count('cnt')])\n",
    "cols_cnt_C      = sorted([col for col in use_cols if col.count('C') and col.count('cnt')])\n",
    "cols_cnt_V      = sorted([col for col in use_cols if col.count('V') and col.count('cnt')])\n",
    "cols_cnt_Amt    = sorted([col for col in use_cols if (col.count('TransactionAmt') or col.count('cents')) and col.count('cnt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_combi = list(\n",
    "    list(combinations(cols_cnt_card   + ['fill__cnt_addr1', 'fill__cnt_C1', 'fill__cnt_C13', 'fill__cnt_V283'], 3))\n",
    "    + list(combinations(cols_cnt_card + ['fill__cnt_addr1', 'fill__cnt_C1', 'fill__cnt_C13', 'fill__cnt_V283'], 4))\n",
    "    + list(combinations(cols_cnt_card + ['fill__cnt_addr1', 'fill__cnt_C1', 'fill__cnt_C13', 'fill__cnt_V283'], 5))\n",
    "    + list(combinations(cols_cnt_card + ['fill__cnt_addr1', 'fill__cnt_C1', 'fill__cnt_C13', 'fill__cnt_V283'], 6))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Presetting\n",
    "#========================================================================\n",
    "num_topics = 5\n",
    "n_jobs = 24\n",
    "prefix = '611'\n",
    "trn_len = len(df_train)\n",
    "\n",
    "#========================================================================\n",
    "# Make Corpus\n",
    "#========================================================================\n",
    "def make_text(df, cols_lda):\n",
    "\n",
    "    list_token = []\n",
    "    for val in df[cols_lda].values:\n",
    "        elems = [str(v) for v in val]\n",
    "        list_token.append(elems)\n",
    "    return list_token\n",
    "\n",
    "\n",
    "def parallel_lda(df, combis):\n",
    "    \n",
    "\n",
    "    for cols_lda in tqdm(combis):\n",
    "        \n",
    "\n",
    "        cols_lda = list(cols_lda)\n",
    "        cols = [c.replace('fill__', 'f_').replace('cnt_', 'c_') for c in cols_lda]\n",
    "        fname = '-'.join(cols)\n",
    "\n",
    "        texts = make_text(df, cols_lda)\n",
    "        dictionary = corpora.Dictionary(texts)\n",
    "        corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "        #========================================================================\n",
    "        # LDA\n",
    "        #========================================================================\n",
    "\n",
    "        lda = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "        def get_lda_topic(num_topics, model, corpus):\n",
    "            tmp_mx = np.zeros((len(corpus), num_topics))\n",
    "            for idx, sample in tqdm(enumerate(corpus)):\n",
    "                topic = model[sample]\n",
    "                for t_no, val in topic:\n",
    "                    tmp_mx[idx, t_no] = val\n",
    "\n",
    "            return tmp_mx\n",
    "\n",
    "\n",
    "        topic_mx = get_lda_topic(num_topics, lda, corpus)\n",
    "\n",
    "        for col_no in tqdm(range(num_topics)):\n",
    "            train_feature = topic_mx[:trn_len, col_no]\n",
    "            test_feature = topic_mx[trn_len:, col_no]\n",
    "            to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{num_topics}_no{col_no}_{fname}_train', obj=train_feature)\n",
    "            to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{num_topics}_no{col_no}_{fname}_test', obj=test_feature)\n",
    "            \n",
    "            \n",
    "for no in range(4, 9, 1):\n",
    "    arg_list = get_parallel_arg_list(48, list_combi[48*no:48*(no+1)])\n",
    "    print(len(arg_list[0]))\n",
    "\n",
    "    Parallel(n_jobs)([delayed(parallel_lda)(data[list(set(list(chain(*arg))))], arg) for arg in arg_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f_c_card1-f_c_card2-f_c_card3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
