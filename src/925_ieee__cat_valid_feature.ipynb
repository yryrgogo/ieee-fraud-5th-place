{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-01 22:38:46,342 func.utils 347 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename, logger_func\n",
    "from func.ml_utils import get_factorize_feature\n",
    "from ieee_train import eval_train, eval_check_feature\n",
    "from kaggle_utils import reduce_mem_usage, move_feature\n",
    "logger = logger_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMN_GROUP = 'DT-M'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, COLUMN_GROUP, 'is_train', 'date']\n",
    "\n",
    "def filter_feature(path):\n",
    "    if path.count(''):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# paths_train = glob('../submit/re_sub/50*_train.gz')\n",
    "# paths_test  = glob('../submit/re_sub/50*_test.gz')\n",
    "# paths_train += glob('../submit/re_sub/Tran*_train.gz')\n",
    "# paths_test  += glob('../submit/re_sub/Tran*_test.gz')\n",
    "# paths_train += glob('../submit/re_sub/is*_train.gz')\n",
    "# paths_test  += glob('../submit/re_sub/is*_test.gz')\n",
    "\n",
    "paths_train = glob('../submit/re_sub/*_train.gz')\n",
    "paths_test  = glob('../submit/re_sub/*_test.gz')\n",
    "# paths_train += glob('../submit/add_feature/*_train.gz')\n",
    "# paths_test  += glob('../submit/add_feature/*_test.gz')\n",
    "\n",
    "print(len(paths_train))\n",
    "# sys.exit()\n",
    "# paths_train += glob('../feature/valid_trush/528*uid2*_train.gz')\n",
    "# paths_test  += glob('../feature/valid_trush/528*uid2*_test.gz')\n",
    "\n",
    "# for path in paths_train:\n",
    "#     if path.count('C14_ratio'):\n",
    "#         paths_train.remove(path)\n",
    "        \n",
    "# for path in paths_test:\n",
    "#     if path.count('C14_ratio'):\n",
    "#         paths_test.remove(path)\n",
    "    \n",
    "# paths_train = glob('../feature/raw_use/*_train.gz')\n",
    "# paths_test = glob('../feature/raw_use/*_test.gz')\n",
    "# paths_train = [path for path in paths_train if filter_feature(path) ]\n",
    "# paths_test = [path for path in paths_test if filter_feature(path) ]\n",
    "\n",
    "# paths_train_feature = sorted(glob('../feature/org_use/*_train.gz'))\n",
    "# paths_test_feature  = sorted(glob('../feature/org_use/*_test.gz'))\n",
    "\n",
    "# paths_train_feature += sorted(glob('../feature/valid/*_train.gz'))\n",
    "# paths_test_feature  += sorted(glob('../feature/valid/*_test.gz'))\n",
    "\n",
    "# paths_train_feature += sorted(glob('../feature/kernel/*_train.gz'))\n",
    "# paths_test_feature  += sorted(glob('../feature/kernel/*_test.gz'))\n",
    "\n",
    "# paths_train_feature = sorted(glob('../feature/valid_use/*_train.gz'))\n",
    "# paths_test_feature  = sorted(glob('../feature/valid_use/*_test.gz'))\n",
    "paths_train_feature = []\n",
    "paths_test_feature  = []\n",
    "\n",
    "# df_train = reduce_mem_usage( parallel_load_data(paths_train) )\n",
    "# df_test  = reduce_mem_usage( parallel_load_data(paths_test) )\n",
    "df_train = parallel_load_data(paths_train)\n",
    "df_test  = parallel_load_data(paths_test)\n",
    "Y = df_train[COLUMN_TARGET]\n",
    "df_train.drop(COLUMN_TARGET, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [00:06<00:00, 149.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "cols_categorical = [col for col in df_train.columns \n",
    "                    if not col in COLUMNS_IGNORE\n",
    "                    and \n",
    "                    (\n",
    "                    col.count('uid')\n",
    "                    or col.count('ugr')\n",
    "                    or col.count('60')\n",
    "                    )\n",
    "                   ]\n",
    "\n",
    "list_drop = []\n",
    "for col in tqdm(cols_categorical):\n",
    "    cnt = df_train[col].head(2000).value_counts().shape[0]\n",
    "    if cnt > 100:\n",
    "        list_drop.append(col)\n",
    "        continue\n",
    "    cnt = data[col].value_counts().shape[0]\n",
    "    if cnt > 200:\n",
    "        list_drop.append(col)\n",
    "    else:\n",
    "        data[col].fillna(-99999, inplace=True)\n",
    "            \n",
    "cols_categorical = list(set(cols_categorical) -set(list_drop))\n",
    "print(len(cols_categorical))\n",
    "data = get_factorize_feature(data, cols_categorical)\n",
    "df_train = data.iloc[:len(df_train)]\n",
    "df_test  = data.iloc[len(df_train):]\n",
    "\n",
    "# same_user_path = '../output/same_user_pattern/20190901_user_ids_share.csv'\n",
    "# same_user_path = '../output/same_user_pattern/20190901_user_ids_share.csv'\n",
    "# bear = pd.read_csv(same_user_path)\n",
    "# bear = bear[[COLUMN_ID, 'predicted_user_id']]\n",
    "# max_id = bear['predicted_user_id'].max()\n",
    "# bear.loc[bear[bear['predicted_user_id'].isnull()].index, 'predicted_user_id'] = np.arange(\n",
    "#     bear['predicted_user_id'].isnull().sum() ) + 1 + max_id\n",
    "# bear['predicted_user_id'] =  bear['predicted_user_id'].astype('int')\n",
    "# bear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Diff Features: 0\n"
     ]
    }
   ],
   "source": [
    "is_submit = [True, False][0]\n",
    "n_splits = 6\n",
    "set_type = 'new_set'\n",
    "\n",
    "valid_paths_train = paths_train_feature[:]\n",
    "valid_paths_test  = paths_test_feature[:]\n",
    "\n",
    "#========================================================================\n",
    "# pathの存在チェック。なぜかたびたびFileNotFoundErrorが起きるので,,,\n",
    "#========================================================================\n",
    "remove_paths = []\n",
    "for trn_path, tes_path in zip(valid_paths_train, valid_paths_test):\n",
    "    if os.path.exists(trn_path) and os.path.exists(tes_path):\n",
    "        pass\n",
    "    else:\n",
    "        remove_paths.append(trn_path)\n",
    "        remove_paths.append(tes_path)\n",
    "for path in remove_paths:\n",
    "    if path.count('train'):\n",
    "        valid_paths_train.remove(path)\n",
    "        print(f'remove {path}')\n",
    "    elif path.count('test'):\n",
    "        valid_paths_test.remove(path)\n",
    "        print(f'remove {path}')\n",
    "\n",
    "if len(valid_paths_train):\n",
    "    df_feat_train = parallel_load_data(valid_paths_train)\n",
    "    df_feat_test  = parallel_load_data(valid_paths_test)\n",
    "    \n",
    "    col_drops = eval_check_feature(df_feat_train, df_feat_test)\n",
    "    \n",
    "    tmp_train = df_train.join(df_feat_train)\n",
    "    tmp_test = df_test.join(df_feat_test)\n",
    "else:\n",
    "    tmp_train = df_train\n",
    "    tmp_test = df_test\n",
    "\n",
    "#========================================================================\n",
    "# Train Test で片方に存在しないFeatureを除外\n",
    "#========================================================================\n",
    "diff_cols = list(set(tmp_train.columns) - set(tmp_test.columns))\n",
    "\n",
    "for col in list(set(diff_cols)):\n",
    "    from_dir = 'valid'\n",
    "    to_dir = 'valid_trush'\n",
    "    move_feature([col], from_dir, to_dir)\n",
    "tmp_train.drop(diff_cols, axis=1, inplace=True)\n",
    "print(f\"  * Diff Features: {len(diff_cols)}\")\n",
    "\n",
    "# same_user_path = '../output/same_user_pattern/0902__same_user_id__card_addr_pemail_M.csv'\n",
    "# tmp_train = tmp_train.merge(bear[[COLUMN_ID, 'predicted_user_id']], how='inner', on=COLUMN_ID)\n",
    "# COLUMN_GROUP = 'predicted_user_id'\n",
    "# COLUMNS_IGNORE.append('predicted_user_id')\n",
    "\n",
    "### DT-M\n",
    "group_kfold_path = '../input/0908_ieee__DT-M_GroupKFold.gz'\n",
    "group = read_pkl_gzip(group_kfold_path)\n",
    "tmp_train[COLUMN_GROUP] = group\n",
    "\n",
    "# tmp_train[COLUMN_GROUP] = tmp_train['528__ugr_uid3_Regist_date_agg_V95_137_mean_mean'].fillna(0)\n",
    "\n",
    "#========================================================================\n",
    "# Features elimination \n",
    "#==============================================================\n",
    "# from scipy.stats import ks_2samp\n",
    "# features_check = []\n",
    "# columns_to_check = set(list(tmp_train)).difference(COLUMNS_IGNORE)\n",
    "# for i in columns_to_check:\n",
    "#     features_check.append(ks_2samp(tmp_test[i], tmp_train[i])[1])\n",
    "\n",
    "# features_check = pd.Series(features_check, index=columns_to_check).sort_values() \n",
    "# features_discard = list(features_check[features_check==0].index)\n",
    "# print(features_discard)\n",
    "# tmp_train.drop(features_discard, axis=1, inplace=True)\n",
    "# tmp_test.drop(features_discard, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "model_type = \"cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-01 22:44:43,288 func.utils 26 [INFO]    [<module>] * EXP: dataset new_set (590540, 1807) lr 0.07  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "0:\tlearn: 0.5776118\ttotal: 3.46s\tremaining: 9h 36m 41s\n",
      "1:\tlearn: 0.4823880\ttotal: 6.03s\tremaining: 8h 22m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Exception ignored in: <function _before_at_fork_weak_calls at 0x7f0f07655ea0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/logging/__init__.py\", line 265, in _before_at_fork_weak_calls\n",
      "    _at_fork_weak_calls('acquire')\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/logging/__init__.py\", line 254, in _at_fork_weak_calls\n",
      "    for instance in _at_fork_acquire_release_weakset:\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iterationIgnoring exception from logging atfork <StreamHandler stderr (INFO)> release method: cannot release un-acquired lock\n",
      "    _at_fork_weak_calls('acquire')\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/logging/__init__.py\", line 254, in _at_fork_weak_calls\n",
      "    for instance in _at_fork_acquire_release_weakset:\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "Ignoring exception from logging atfork <StreamHandler stderr (INFO)> release method: Ignoring exception from logging atfork <StreamHandler <stderr> (NOTSET)> release method: cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <StreamHandler stderr (NOTSET)> release method: cannot release un-acquired lock\n",
      "cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <StreamHandler <stderr> (NOTSET)> release method: cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <StreamHandler stderr (NOTSET)> release method: cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <StreamHandler stderr (NOTSET)> release method: cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <StreamHandler <stderr> (NOTSET)> release method: cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <FileHandler /home/yryrgogo/github/ieee-fraud/output/py_train.py.log (DEBUG)> release method: cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <StreamHandler stderr (NOTSET)> release method: cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <StreamHandler <stderr> (NOTSET)> release method: cannot release un-acquired lock\n",
      "Ignoring exception from logging atfork <FileHandler /home/yryrgogo/github/ieee-fraud/output/py_train.py.log (DEBUG)> release method: cannot release un-acquired lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/catboost/core.py\", line 1612, in _fit\n",
      "    train_params[\"init_model\"]\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/catboost/core.py\", line 1171, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 3573, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 3619, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-6b7672fd5a5a>\", line 48, in <module>\n",
      "    cols_categorical=cols_categorical\n",
      "  File \"/home/yryrgogo/github/ieee-fraud/src/ieee_train.py\", line 379, in eval_train\n",
      "    cols_categorical=cols_categorical,\n",
      "  File \"/home/yryrgogo/github/ieee-fraud/src/ieee_train.py\", line 189, in ieee_cv\n",
      "    cols_categorical = cols_categorical\n",
      "  File \"/home/yryrgogo/github/ieee-fraud/src/func/ml_utils.py\", line 218, in Classifier\n",
      "    cat_features=cols_categorical,\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/catboost/core.py\", line 3689, in fit\n",
      "    silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/catboost/core.py\", line 1612, in _fit\n",
      "    train_params[\"init_model\"]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/yryrgogo/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1611\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2960\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6b7672fd5a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mis_viz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mcols_categorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m )\n",
      "\u001b[0;32m~/github/ieee-fraud/src/ieee_train.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(logger, df_train, Y, df_test, COLUMN_GROUP, model_type, params, cols_categorical, is_adv, is_viz, is_valid)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mis_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mcols_categorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         )\n",
      "\u001b[0;32m~/github/ieee-fraud/src/ieee_train.py\u001b[0m in \u001b[0;36mieee_cv\u001b[0;34m(logger, df_train, Y, df_test, COLUMN_GROUP, use_cols, params, cols_categorical, is_adv, is_valid)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mcols_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             )\n",
      "\u001b[0;32m~/github/ieee-fraud/src/func/ml_utils.py\u001b[0m in \u001b[0;36mClassifier\u001b[0;34m(model_type, x_train, x_valid, y_train, y_valid, x_test, params, seed, get_model, get_feim, early_stopping_rounds, num_boost_round, weight_list, cols_categorical)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   3688\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   3690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1611\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m             )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1862\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2978\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2979\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1864\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1866\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1373\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1281\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m             )\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m             \u001b[0mformatted_exceptions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m             \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "#     'n_jobs': 96,\n",
    "    'seed': 1208,\n",
    "#     'subsample': 0.9,\n",
    "    'num_boost_round':10000,\n",
    "    'random_seed': 1208,\n",
    "    'has_time': True,\n",
    "    'max_depth': 10,\n",
    "    'loss_function': 'Logloss',\n",
    "    'custom_loss':['AUC'],\n",
    "#     'logging_level':'Silent',\n",
    "    'task_type' : 'CPU',\n",
    "    'early_stopping_rounds' : 100,\n",
    "    'n_splits': n_splits,\n",
    "    'model_type': model_type,\n",
    "    'fold': ['stratified', 'group'][1],\n",
    "}\n",
    "\n",
    "if is_submit:\n",
    "    params['learning_rate'] = 0.07\n",
    "#     params['learning_rate'] = 0.05\n",
    "#     params['learning_rate'] = 0.1\n",
    "    params[\"early_stopping_rounds\"] = 100\n",
    "\n",
    "use_cols = [col for col in df_train.columns if col not in COLUMNS_IGNORE]\n",
    "logger.info(f\"* EXP: dataset {set_type} {tmp_train.shape} lr {params['learning_rate']} \")\n",
    "            \n",
    "if False:\n",
    "#     sample = tmp_train.sample(10000)\n",
    "#     sample[COLUMN_GROUP].value_counts()\n",
    "    use_cols = [col for col in df_train.columns if col not in COLUMNS_IGNORE][:10]\n",
    "    params['early_stopping_rounds'] = 1\n",
    "    params['num_boost_round'] = 1\n",
    "\n",
    "feim, _ = eval_train(\n",
    "    logger,\n",
    "    tmp_train,\n",
    "    Y,\n",
    "    tmp_test,\n",
    "#     sample,\n",
    "#     Y.head(10000),\n",
    "#     tmp_test.head(1000),\n",
    "    COLUMN_GROUP,\n",
    "    model_type,\n",
    "    params,\n",
    "    is_adv=[True, False][1],\n",
    "    is_viz=[True, False][1],\n",
    "    cols_categorical=cols_categorical\n",
    ")\n",
    "feim = list_result_feim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
