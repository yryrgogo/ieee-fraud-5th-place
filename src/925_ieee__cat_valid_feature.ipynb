{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-02 23:33:35,339 func.utils 347 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename, logger_func\n",
    "from func.ml_utils import get_factorize_feature\n",
    "from ieee_train import eval_train, eval_check_feature\n",
    "from kaggle_utils import reduce_mem_usage, move_feature\n",
    "logger = logger_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234\n"
     ]
    }
   ],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMN_GROUP = 'DT-M'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, COLUMN_GROUP, 'is_train', 'date']\n",
    "\n",
    "def filter_feature(path):\n",
    "    if path.count(''):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# paths_train = glob('../submit/re_sub/50*_train.gz')\n",
    "# paths_test  = glob('../submit/re_sub/50*_test.gz')\n",
    "# paths_train += glob('../submit/re_sub/Tran*_train.gz')\n",
    "# paths_test  += glob('../submit/re_sub/Tran*_test.gz')\n",
    "# paths_train += glob('../submit/re_sub/is*_train.gz')\n",
    "# paths_test  += glob('../submit/re_sub/is*_test.gz')\n",
    "\n",
    "paths_train = glob('../submit/re_sub/*_train.gz')\n",
    "paths_test  = glob('../submit/re_sub/*_test.gz')\n",
    "# paths_train += glob('../submit/add_feature/*_train.gz')\n",
    "# paths_test  += glob('../submit/add_feature/*_test.gz')\n",
    "\n",
    "print(len(paths_train))\n",
    "# sys.exit()\n",
    "# paths_train += glob('../feature/valid_trush/528*uid2*_train.gz')\n",
    "# paths_test  += glob('../feature/valid_trush/528*uid2*_test.gz')\n",
    "\n",
    "# for path in paths_train:\n",
    "#     if path.count('C14_ratio'):\n",
    "#         paths_train.remove(path)\n",
    "        \n",
    "# for path in paths_test:\n",
    "#     if path.count('C14_ratio'):\n",
    "#         paths_test.remove(path)\n",
    "    \n",
    "# paths_train = glob('../feature/raw_use/*_train.gz')\n",
    "# paths_test = glob('../feature/raw_use/*_test.gz')\n",
    "# paths_train = [path for path in paths_train if filter_feature(path) ]\n",
    "# paths_test = [path for path in paths_test if filter_feature(path) ]\n",
    "\n",
    "# paths_train_feature = sorted(glob('../feature/org_use/*_train.gz'))\n",
    "# paths_test_feature  = sorted(glob('../feature/org_use/*_test.gz'))\n",
    "\n",
    "# paths_train_feature += sorted(glob('../feature/valid/*_train.gz'))\n",
    "# paths_test_feature  += sorted(glob('../feature/valid/*_test.gz'))\n",
    "\n",
    "# paths_train_feature += sorted(glob('../feature/kernel/*_train.gz'))\n",
    "# paths_test_feature  += sorted(glob('../feature/kernel/*_test.gz'))\n",
    "\n",
    "# paths_train_feature = sorted(glob('../feature/valid_use/*_train.gz'))\n",
    "# paths_test_feature  = sorted(glob('../feature/valid_use/*_test.gz'))\n",
    "paths_train_feature = []\n",
    "paths_test_feature  = []\n",
    "\n",
    "# df_train = reduce_mem_usage( parallel_load_data(paths_train) )\n",
    "# df_test  = reduce_mem_usage( parallel_load_data(paths_test) )\n",
    "df_train = parallel_load_data(paths_train)\n",
    "df_test  = parallel_load_data(paths_test)\n",
    "Y = df_train[COLUMN_TARGET]\n",
    "df_train.drop(COLUMN_TARGET, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# cols_categorical = [col for col in df_train.columns \n",
    "#                     if not col in COLUMNS_IGNORE\n",
    "#                     and \n",
    "#                     (\n",
    "#                     col.count('uid')\n",
    "#                     or col.count('ugr')\n",
    "#                     or col.count('60')\n",
    "#                     )\n",
    "#                    ]\n",
    "\n",
    "# list_drop = []\n",
    "# for col in tqdm(cols_categorical):\n",
    "#     cnt = df_train[col].head(2000).value_counts().shape[0]\n",
    "#     if cnt > 100:\n",
    "#         list_drop.append(col)\n",
    "#         continue\n",
    "#     cnt = data[col].value_counts().shape[0]\n",
    "#     if cnt > 200:\n",
    "#         list_drop.append(col)\n",
    "#     else:\n",
    "#         data[col].fillna(-99999, inplace=True)\n",
    "            \n",
    "# cols_categorical = list(set(cols_categorical) -set(list_drop))\n",
    "# print(len(cols_categorical))\n",
    "\n",
    "# data = get_factorize_feature(data, cols_categorical)\n",
    "# df_train = data.iloc[:len(df_train)]\n",
    "# df_test  = data.iloc[len(df_train):]\n",
    "\n",
    "\n",
    "# same_user_path = '../output/same_user_pattern/20190901_user_ids_share.csv'\n",
    "# same_user_path = '../output/same_user_pattern/20190901_user_ids_share.csv'\n",
    "# bear = pd.read_csv(same_user_path)\n",
    "# bear = bear[[COLUMN_ID, 'predicted_user_id']]\n",
    "# max_id = bear['predicted_user_id'].max()\n",
    "# bear.loc[bear[bear['predicted_user_id'].isnull()].index, 'predicted_user_id'] = np.arange(\n",
    "#     bear['predicted_user_id'].isnull().sum() ) + 1 + max_id\n",
    "# bear['predicted_user_id'] =  bear['predicted_user_id'].astype('int')\n",
    "# bear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Diff Features: 0\n"
     ]
    }
   ],
   "source": [
    "is_submit = [True, False][0]\n",
    "n_splits = 5\n",
    "set_type = 'new_set'\n",
    "\n",
    "valid_paths_train = paths_train_feature[:]\n",
    "valid_paths_test  = paths_test_feature[:]\n",
    "\n",
    "#========================================================================\n",
    "# pathの存在チェック。なぜかたびたびFileNotFoundErrorが起きるので,,,\n",
    "#========================================================================\n",
    "remove_paths = []\n",
    "for trn_path, tes_path in zip(valid_paths_train, valid_paths_test):\n",
    "    if os.path.exists(trn_path) and os.path.exists(tes_path):\n",
    "        pass\n",
    "    else:\n",
    "        remove_paths.append(trn_path)\n",
    "        remove_paths.append(tes_path)\n",
    "for path in remove_paths:\n",
    "    if path.count('train'):\n",
    "        valid_paths_train.remove(path)\n",
    "        print(f'remove {path}')\n",
    "    elif path.count('test'):\n",
    "        valid_paths_test.remove(path)\n",
    "        print(f'remove {path}')\n",
    "\n",
    "if len(valid_paths_train):\n",
    "    df_feat_train = parallel_load_data(valid_paths_train)\n",
    "    df_feat_test  = parallel_load_data(valid_paths_test)\n",
    "    \n",
    "    col_drops = eval_check_feature(df_feat_train, df_feat_test)\n",
    "    \n",
    "    tmp_train = df_train.join(df_feat_train)\n",
    "    tmp_test = df_test.join(df_feat_test)\n",
    "else:\n",
    "    tmp_train = df_train\n",
    "    tmp_test = df_test\n",
    "\n",
    "#========================================================================\n",
    "# Train Test で片方に存在しないFeatureを除外\n",
    "#========================================================================\n",
    "diff_cols = list(set(tmp_train.columns) - set(tmp_test.columns))\n",
    "\n",
    "for col in list(set(diff_cols)):\n",
    "    from_dir = 'valid'\n",
    "    to_dir = 'valid_trush'\n",
    "    move_feature([col], from_dir, to_dir)\n",
    "tmp_train.drop(diff_cols, axis=1, inplace=True)\n",
    "print(f\"  * Diff Features: {len(diff_cols)}\")\n",
    "\n",
    "# same_user_path = '../output/same_user_pattern/0902__same_user_id__card_addr_pemail_M.csv'\n",
    "# tmp_train = tmp_train.merge(bear[[COLUMN_ID, 'predicted_user_id']], how='inner', on=COLUMN_ID)\n",
    "# COLUMN_GROUP = 'predicted_user_id'\n",
    "# COLUMNS_IGNORE.append('predicted_user_id')\n",
    "\n",
    "### DT-M\n",
    "group_kfold_path = '../input/0908_ieee__DT-M_GroupKFold.gz'\n",
    "group = read_pkl_gzip(group_kfold_path)\n",
    "tmp_train[COLUMN_GROUP] = group\n",
    "\n",
    "# tmp_train[COLUMN_GROUP] = tmp_train['528__ugr_uid3_Regist_date_agg_V95_137_mean_mean'].fillna(0)\n",
    "\n",
    "#========================================================================\n",
    "# Features elimination \n",
    "#==============================================================\n",
    "# from scipy.stats import ks_2samp\n",
    "# features_check = []\n",
    "# columns_to_check = set(list(tmp_train)).difference(COLUMNS_IGNORE)\n",
    "# for i in columns_to_check:\n",
    "#     features_check.append(ks_2samp(tmp_test[i], tmp_train[i])[1])\n",
    "\n",
    "# features_check = pd.Series(features_check, index=columns_to_check).sort_values() \n",
    "# features_discard = list(features_check[features_check==0].index)\n",
    "# print(features_discard)\n",
    "# tmp_train.drop(features_discard, axis=1, inplace=True)\n",
    "# tmp_test.drop(features_discard, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-02 23:34:44,394 func.utils 33 [INFO]    [<module>] * EXP: dataset new_set (590540, 1234) lr 0.01  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "0:\tlearn: 0.6756240\ttest: 0.6764498\tbest: 0.6764498 (0)\ttotal: 1.77s\tremaining: 4h 55m 31s\n",
      "50:\tlearn: 0.2313863\ttest: 0.2380128\tbest: 0.2380128 (50)\ttotal: 1m 10s\tremaining: 3h 49m 13s\n",
      "100:\tlearn: 0.1371518\ttest: 0.1368381\tbest: 0.1368381 (100)\ttotal: 2m 17s\tremaining: 3h 44m 15s\n",
      "150:\tlearn: 0.1101899\ttest: 0.1068106\tbest: 0.1068106 (150)\ttotal: 3m 24s\tremaining: 3h 42m 11s\n",
      "200:\tlearn: 0.0993151\ttest: 0.0949655\tbest: 0.0949655 (200)\ttotal: 4m 32s\tremaining: 3h 41m 10s\n",
      "250:\tlearn: 0.0934283\ttest: 0.0892683\tbest: 0.0892683 (250)\ttotal: 5m 41s\tremaining: 3h 40m 46s\n",
      "300:\tlearn: 0.0893930\ttest: 0.0863313\tbest: 0.0863313 (300)\ttotal: 6m 48s\tremaining: 3h 39m 31s\n",
      "350:\tlearn: 0.0865129\ttest: 0.0840395\tbest: 0.0840395 (350)\ttotal: 7m 56s\tremaining: 3h 38m 13s\n",
      "400:\tlearn: 0.0839848\ttest: 0.0822417\tbest: 0.0822417 (400)\ttotal: 9m 3s\tremaining: 3h 36m 59s\n",
      "450:\tlearn: 0.0818648\ttest: 0.0812439\tbest: 0.0812430 (449)\ttotal: 10m 11s\tremaining: 3h 35m 47s\n",
      "500:\tlearn: 0.0800398\ttest: 0.0804629\tbest: 0.0804629 (500)\ttotal: 11m 18s\tremaining: 3h 34m 32s\n",
      "550:\tlearn: 0.0784463\ttest: 0.0795067\tbest: 0.0795067 (550)\ttotal: 12m 26s\tremaining: 3h 33m 18s\n",
      "600:\tlearn: 0.0770509\ttest: 0.0788206\tbest: 0.0788206 (600)\ttotal: 13m 33s\tremaining: 3h 32m 2s\n",
      "650:\tlearn: 0.0757121\ttest: 0.0782627\tbest: 0.0782627 (650)\ttotal: 14m 41s\tremaining: 3h 31m 1s\n",
      "700:\tlearn: 0.0745299\ttest: 0.0777944\tbest: 0.0777944 (700)\ttotal: 15m 48s\tremaining: 3h 29m 45s\n",
      "750:\tlearn: 0.0734458\ttest: 0.0773660\tbest: 0.0773643 (749)\ttotal: 16m 55s\tremaining: 3h 28m 31s\n",
      "800:\tlearn: 0.0723582\ttest: 0.0767729\tbest: 0.0767729 (800)\ttotal: 18m 3s\tremaining: 3h 27m 19s\n",
      "850:\tlearn: 0.0713663\ttest: 0.0762931\tbest: 0.0762931 (850)\ttotal: 19m 10s\tremaining: 3h 26m 14s\n",
      "900:\tlearn: 0.0703706\ttest: 0.0758547\tbest: 0.0758508 (898)\ttotal: 20m 18s\tremaining: 3h 25m 7s\n",
      "950:\tlearn: 0.0694348\ttest: 0.0753827\tbest: 0.0753827 (950)\ttotal: 21m 27s\tremaining: 3h 24m 12s\n",
      "1000:\tlearn: 0.0685042\ttest: 0.0748927\tbest: 0.0748927 (1000)\ttotal: 22m 35s\tremaining: 3h 23m 8s\n",
      "1050:\tlearn: 0.0676191\ttest: 0.0744290\tbest: 0.0744290 (1050)\ttotal: 23m 42s\tremaining: 3h 21m 55s\n",
      "1100:\tlearn: 0.0668399\ttest: 0.0740236\tbest: 0.0740236 (1100)\ttotal: 24m 50s\tremaining: 3h 20m 45s\n",
      "1150:\tlearn: 0.0660431\ttest: 0.0737653\tbest: 0.0737653 (1150)\ttotal: 25m 57s\tremaining: 3h 19m 32s\n",
      "1200:\tlearn: 0.0653010\ttest: 0.0735159\tbest: 0.0735159 (1200)\ttotal: 27m 5s\tremaining: 3h 18m 25s\n",
      "1250:\tlearn: 0.0645591\ttest: 0.0732246\tbest: 0.0732207 (1248)\ttotal: 28m 11s\tremaining: 3h 17m 13s\n",
      "1300:\tlearn: 0.0639020\ttest: 0.0730006\tbest: 0.0730006 (1300)\ttotal: 29m 18s\tremaining: 3h 16m\n",
      "1350:\tlearn: 0.0632541\ttest: 0.0726988\tbest: 0.0726988 (1350)\ttotal: 30m 25s\tremaining: 3h 14m 47s\n",
      "1400:\tlearn: 0.0625552\ttest: 0.0724567\tbest: 0.0724567 (1400)\ttotal: 31m 33s\tremaining: 3h 13m 39s\n",
      "1450:\tlearn: 0.0618637\ttest: 0.0720986\tbest: 0.0720986 (1450)\ttotal: 32m 40s\tremaining: 3h 12m 29s\n",
      "1500:\tlearn: 0.0612554\ttest: 0.0718592\tbest: 0.0718467 (1499)\ttotal: 33m 47s\tremaining: 3h 11m 19s\n",
      "1550:\tlearn: 0.0606846\ttest: 0.0716462\tbest: 0.0716462 (1550)\ttotal: 34m 54s\tremaining: 3h 10m 10s\n",
      "1600:\tlearn: 0.0601175\ttest: 0.0713872\tbest: 0.0713872 (1600)\ttotal: 36m 2s\tremaining: 3h 9m 4s\n",
      "1650:\tlearn: 0.0595229\ttest: 0.0711712\tbest: 0.0711712 (1650)\ttotal: 37m 9s\tremaining: 3h 7m 56s\n",
      "1700:\tlearn: 0.0589102\ttest: 0.0709585\tbest: 0.0709565 (1698)\ttotal: 38m 19s\tremaining: 3h 6m 58s\n",
      "1750:\tlearn: 0.0583890\ttest: 0.0707452\tbest: 0.0707378 (1748)\ttotal: 39m 26s\tremaining: 3h 5m 46s\n",
      "1800:\tlearn: 0.0577791\ttest: 0.0704734\tbest: 0.0704730 (1799)\ttotal: 40m 33s\tremaining: 3h 4m 39s\n",
      "1850:\tlearn: 0.0572576\ttest: 0.0703237\tbest: 0.0703237 (1850)\ttotal: 41m 40s\tremaining: 3h 3m 27s\n",
      "1900:\tlearn: 0.0566929\ttest: 0.0701370\tbest: 0.0701370 (1900)\ttotal: 42m 46s\tremaining: 3h 2m 14s\n",
      "1950:\tlearn: 0.0561485\ttest: 0.0699552\tbest: 0.0699550 (1949)\ttotal: 43m 53s\tremaining: 3h 1m 5s\n",
      "2000:\tlearn: 0.0556454\ttest: 0.0697763\tbest: 0.0697763 (2000)\ttotal: 45m 1s\tremaining: 3h\n",
      "2050:\tlearn: 0.0551548\ttest: 0.0695916\tbest: 0.0695916 (2050)\ttotal: 46m 8s\tremaining: 2h 58m 50s\n",
      "2100:\tlearn: 0.0546761\ttest: 0.0693738\tbest: 0.0693738 (2100)\ttotal: 47m 15s\tremaining: 2h 57m 39s\n",
      "2150:\tlearn: 0.0541450\ttest: 0.0692128\tbest: 0.0692128 (2150)\ttotal: 48m 21s\tremaining: 2h 56m 27s\n",
      "2200:\tlearn: 0.0536887\ttest: 0.0690595\tbest: 0.0690595 (2200)\ttotal: 49m 28s\tremaining: 2h 55m 18s\n",
      "2250:\tlearn: 0.0532658\ttest: 0.0689651\tbest: 0.0689651 (2250)\ttotal: 50m 35s\tremaining: 2h 54m 7s\n",
      "2300:\tlearn: 0.0528660\ttest: 0.0688150\tbest: 0.0688150 (2300)\ttotal: 51m 41s\tremaining: 2h 52m 56s\n",
      "2350:\tlearn: 0.0524069\ttest: 0.0686748\tbest: 0.0686743 (2349)\ttotal: 52m 48s\tremaining: 2h 51m 47s\n",
      "2400:\tlearn: 0.0519444\ttest: 0.0685502\tbest: 0.0685502 (2400)\ttotal: 53m 56s\tremaining: 2h 50m 43s\n",
      "2450:\tlearn: 0.0515649\ttest: 0.0684091\tbest: 0.0684091 (2450)\ttotal: 55m 4s\tremaining: 2h 49m 38s\n",
      "2500:\tlearn: 0.0511870\ttest: 0.0682674\tbest: 0.0682674 (2500)\ttotal: 56m 12s\tremaining: 2h 48m 30s\n",
      "2550:\tlearn: 0.0507652\ttest: 0.0681144\tbest: 0.0681144 (2550)\ttotal: 57m 19s\tremaining: 2h 47m 22s\n",
      "2600:\tlearn: 0.0504234\ttest: 0.0680134\tbest: 0.0680115 (2599)\ttotal: 58m 26s\tremaining: 2h 46m 15s\n",
      "2650:\tlearn: 0.0500457\ttest: 0.0679376\tbest: 0.0679376 (2650)\ttotal: 59m 34s\tremaining: 2h 45m 8s\n",
      "2700:\tlearn: 0.0496726\ttest: 0.0678258\tbest: 0.0678247 (2694)\ttotal: 1h 41s\tremaining: 2h 44m\n",
      "2750:\tlearn: 0.0493000\ttest: 0.0677293\tbest: 0.0677277 (2738)\ttotal: 1h 1m 48s\tremaining: 2h 42m 52s\n",
      "2800:\tlearn: 0.0489758\ttest: 0.0675712\tbest: 0.0675712 (2800)\ttotal: 1h 2m 56s\tremaining: 2h 41m 46s\n",
      "2850:\tlearn: 0.0486177\ttest: 0.0673987\tbest: 0.0673976 (2849)\ttotal: 1h 4m 3s\tremaining: 2h 40m 37s\n",
      "2900:\tlearn: 0.0483408\ttest: 0.0673200\tbest: 0.0673200 (2900)\ttotal: 1h 5m 9s\tremaining: 2h 39m 27s\n",
      "2950:\tlearn: 0.0479951\ttest: 0.0671697\tbest: 0.0671687 (2949)\ttotal: 1h 6m 16s\tremaining: 2h 38m 17s\n",
      "3000:\tlearn: 0.0476658\ttest: 0.0671131\tbest: 0.0671131 (2998)\ttotal: 1h 7m 22s\tremaining: 2h 37m 9s\n",
      "3050:\tlearn: 0.0473612\ttest: 0.0670043\tbest: 0.0670043 (3050)\ttotal: 1h 8m 29s\tremaining: 2h 35m 59s\n",
      "3100:\tlearn: 0.0470632\ttest: 0.0668820\tbest: 0.0668820 (3100)\ttotal: 1h 9m 35s\tremaining: 2h 34m 50s\n",
      "3150:\tlearn: 0.0467717\ttest: 0.0668040\tbest: 0.0668040 (3150)\ttotal: 1h 10m 43s\tremaining: 2h 33m 43s\n",
      "3200:\tlearn: 0.0464798\ttest: 0.0666418\tbest: 0.0666418 (3200)\ttotal: 1h 11m 51s\tremaining: 2h 32m 37s\n",
      "3250:\tlearn: 0.0461658\ttest: 0.0665513\tbest: 0.0665513 (3250)\ttotal: 1h 12m 58s\tremaining: 2h 31m 29s\n",
      "3300:\tlearn: 0.0458665\ttest: 0.0664541\tbest: 0.0664541 (3300)\ttotal: 1h 14m 5s\tremaining: 2h 30m 21s\n",
      "3350:\tlearn: 0.0455813\ttest: 0.0663797\tbest: 0.0663797 (3350)\ttotal: 1h 15m 12s\tremaining: 2h 29m 12s\n",
      "3400:\tlearn: 0.0452868\ttest: 0.0662856\tbest: 0.0662856 (3400)\ttotal: 1h 16m 19s\tremaining: 2h 28m 6s\n",
      "3450:\tlearn: 0.0449771\ttest: 0.0661753\tbest: 0.0661737 (3449)\ttotal: 1h 17m 27s\tremaining: 2h 26m 58s\n",
      "3500:\tlearn: 0.0446647\ttest: 0.0661118\tbest: 0.0661118 (3500)\ttotal: 1h 18m 34s\tremaining: 2h 25m 51s\n",
      "3550:\tlearn: 0.0443905\ttest: 0.0660361\tbest: 0.0660361 (3550)\ttotal: 1h 19m 41s\tremaining: 2h 24m 43s\n",
      "3600:\tlearn: 0.0441025\ttest: 0.0659826\tbest: 0.0659826 (3600)\ttotal: 1h 20m 49s\tremaining: 2h 23m 37s\n",
      "3650:\tlearn: 0.0438464\ttest: 0.0659501\tbest: 0.0659501 (3650)\ttotal: 1h 21m 56s\tremaining: 2h 22m 29s\n",
      "3700:\tlearn: 0.0435802\ttest: 0.0658966\tbest: 0.0658947 (3699)\ttotal: 1h 23m 3s\tremaining: 2h 21m 21s\n",
      "3750:\tlearn: 0.0433009\ttest: 0.0658315\tbest: 0.0658315 (3750)\ttotal: 1h 24m 10s\tremaining: 2h 20m 13s\n",
      "3800:\tlearn: 0.0429937\ttest: 0.0657578\tbest: 0.0657573 (3798)\ttotal: 1h 25m 17s\tremaining: 2h 19m 6s\n",
      "3850:\tlearn: 0.0427597\ttest: 0.0656753\tbest: 0.0656753 (3850)\ttotal: 1h 26m 24s\tremaining: 2h 17m 58s\n",
      "3900:\tlearn: 0.0425018\ttest: 0.0656239\tbest: 0.0656239 (3900)\ttotal: 1h 27m 31s\tremaining: 2h 16m 50s\n",
      "3950:\tlearn: 0.0422494\ttest: 0.0655395\tbest: 0.0655389 (3949)\ttotal: 1h 28m 38s\tremaining: 2h 15m 42s\n",
      "4000:\tlearn: 0.0419670\ttest: 0.0654722\tbest: 0.0654722 (4000)\ttotal: 1h 29m 45s\tremaining: 2h 14m 35s\n",
      "4050:\tlearn: 0.0417423\ttest: 0.0654244\tbest: 0.0654226 (4049)\ttotal: 1h 30m 52s\tremaining: 2h 13m 27s\n",
      "4100:\tlearn: 0.0415109\ttest: 0.0653221\tbest: 0.0653216 (4098)\ttotal: 1h 31m 59s\tremaining: 2h 12m 18s\n",
      "4150:\tlearn: 0.0412672\ttest: 0.0652608\tbest: 0.0652549 (4142)\ttotal: 1h 33m 6s\tremaining: 2h 11m 11s\n",
      "4200:\tlearn: 0.0410104\ttest: 0.0652124\tbest: 0.0652100 (4197)\ttotal: 1h 34m 13s\tremaining: 2h 10m 3s\n",
      "4250:\tlearn: 0.0407993\ttest: 0.0651486\tbest: 0.0651486 (4250)\ttotal: 1h 35m 20s\tremaining: 2h 8m 55s\n",
      "4300:\tlearn: 0.0405739\ttest: 0.0650995\tbest: 0.0650965 (4297)\ttotal: 1h 36m 27s\tremaining: 2h 7m 48s\n",
      "4350:\tlearn: 0.0403409\ttest: 0.0650279\tbest: 0.0650277 (4348)\ttotal: 1h 37m 34s\tremaining: 2h 6m 40s\n",
      "4400:\tlearn: 0.0401402\ttest: 0.0649772\tbest: 0.0649772 (4400)\ttotal: 1h 38m 41s\tremaining: 2h 5m 33s\n",
      "4450:\tlearn: 0.0399323\ttest: 0.0649273\tbest: 0.0649259 (4449)\ttotal: 1h 39m 47s\tremaining: 2h 4m 24s\n",
      "4500:\tlearn: 0.0397151\ttest: 0.0648500\tbest: 0.0648500 (4500)\ttotal: 1h 40m 54s\tremaining: 2h 3m 16s\n",
      "4550:\tlearn: 0.0395064\ttest: 0.0648266\tbest: 0.0648253 (4545)\ttotal: 1h 42m 1s\tremaining: 2h 2m 9s\n",
      "4600:\tlearn: 0.0392980\ttest: 0.0648112\tbest: 0.0647975 (4593)\ttotal: 1h 43m 8s\tremaining: 2h 1m 1s\n",
      "4650:\tlearn: 0.0390995\ttest: 0.0647384\tbest: 0.0647384 (4650)\ttotal: 1h 44m 14s\tremaining: 1h 59m 53s\n",
      "4700:\tlearn: 0.0388848\ttest: 0.0646929\tbest: 0.0646929 (4700)\ttotal: 1h 45m 21s\tremaining: 1h 58m 45s\n",
      "4750:\tlearn: 0.0386761\ttest: 0.0646504\tbest: 0.0646504 (4750)\ttotal: 1h 46m 28s\tremaining: 1h 57m 37s\n",
      "4800:\tlearn: 0.0384687\ttest: 0.0645687\tbest: 0.0645682 (4799)\ttotal: 1h 47m 34s\tremaining: 1h 56m 29s\n",
      "4850:\tlearn: 0.0382933\ttest: 0.0645346\tbest: 0.0645346 (4850)\ttotal: 1h 48m 41s\tremaining: 1h 55m 21s\n",
      "4900:\tlearn: 0.0381228\ttest: 0.0645110\tbest: 0.0645110 (4900)\ttotal: 1h 49m 47s\tremaining: 1h 54m 13s\n",
      "4950:\tlearn: 0.0379452\ttest: 0.0644747\tbest: 0.0644743 (4948)\ttotal: 1h 50m 53s\tremaining: 1h 53m 5s\n",
      "5000:\tlearn: 0.0377518\ttest: 0.0644502\tbest: 0.0644498 (4996)\ttotal: 1h 51m 59s\tremaining: 1h 51m 57s\n",
      "5050:\tlearn: 0.0375971\ttest: 0.0644150\tbest: 0.0644150 (5050)\ttotal: 1h 53m 6s\tremaining: 1h 50m 49s\n",
      "5100:\tlearn: 0.0374027\ttest: 0.0643830\tbest: 0.0643830 (5100)\ttotal: 1h 54m 12s\tremaining: 1h 49m 40s\n",
      "5150:\tlearn: 0.0372343\ttest: 0.0643419\tbest: 0.0643419 (5150)\ttotal: 1h 55m 17s\tremaining: 1h 48m 32s\n",
      "5200:\tlearn: 0.0370345\ttest: 0.0643011\tbest: 0.0643011 (5200)\ttotal: 1h 56m 24s\tremaining: 1h 47m 24s\n",
      "5250:\tlearn: 0.0368255\ttest: 0.0642364\tbest: 0.0642364 (5250)\ttotal: 1h 57m 30s\tremaining: 1h 46m 16s\n",
      "5300:\tlearn: 0.0366342\ttest: 0.0641918\tbest: 0.0641917 (5299)\ttotal: 1h 58m 37s\tremaining: 1h 45m 9s\n",
      "5350:\tlearn: 0.0364402\ttest: 0.0641492\tbest: 0.0641492 (5350)\ttotal: 1h 59m 44s\tremaining: 1h 44m 1s\n",
      "5400:\tlearn: 0.0362609\ttest: 0.0641184\tbest: 0.0641184 (5400)\ttotal: 2h 51s\tremaining: 1h 42m 54s\n",
      "5450:\tlearn: 0.0360815\ttest: 0.0640316\tbest: 0.0640315 (5446)\ttotal: 2h 1m 57s\tremaining: 1h 41m 46s\n",
      "5500:\tlearn: 0.0358886\ttest: 0.0640184\tbest: 0.0640097 (5493)\ttotal: 2h 3m 3s\tremaining: 1h 40m 38s\n",
      "5550:\tlearn: 0.0357213\ttest: 0.0639777\tbest: 0.0639777 (5550)\ttotal: 2h 4m 10s\tremaining: 1h 39m 31s\n",
      "5600:\tlearn: 0.0355575\ttest: 0.0639393\tbest: 0.0639380 (5599)\ttotal: 2h 5m 16s\tremaining: 1h 38m 23s\n",
      "5650:\tlearn: 0.0353841\ttest: 0.0639210\tbest: 0.0639169 (5646)\ttotal: 2h 6m 22s\tremaining: 1h 37m 15s\n",
      "5700:\tlearn: 0.0352257\ttest: 0.0638896\tbest: 0.0638896 (5700)\ttotal: 2h 7m 28s\tremaining: 1h 36m 7s\n",
      "5750:\tlearn: 0.0350683\ttest: 0.0638638\tbest: 0.0638638 (5750)\ttotal: 2h 8m 35s\tremaining: 1h 35m\n",
      "5800:\tlearn: 0.0348790\ttest: 0.0638145\tbest: 0.0638137 (5797)\ttotal: 2h 9m 41s\tremaining: 1h 33m 52s\n",
      "5850:\tlearn: 0.0347095\ttest: 0.0637960\tbest: 0.0637933 (5840)\ttotal: 2h 10m 48s\tremaining: 1h 32m 45s\n",
      "5900:\tlearn: 0.0345421\ttest: 0.0637679\tbest: 0.0637679 (5900)\ttotal: 2h 11m 54s\tremaining: 1h 31m 37s\n",
      "5950:\tlearn: 0.0343758\ttest: 0.0637354\tbest: 0.0637354 (5950)\ttotal: 2h 13m\tremaining: 1h 30m 29s\n",
      "6000:\tlearn: 0.0342056\ttest: 0.0637035\tbest: 0.0637035 (6000)\ttotal: 2h 14m 7s\tremaining: 1h 29m 22s\n",
      "6050:\tlearn: 0.0340291\ttest: 0.0637154\tbest: 0.0637028 (6001)\ttotal: 2h 15m 13s\tremaining: 1h 28m 15s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.06370281725\n",
      "bestIteration = 6001\n",
      "\n",
      "Shrink model to first 6002 iterations.\n",
      "[  * Fold0 Validation-DT-M 2017-12: 134339] done in 8145 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-03 01:50:38,088 func.utils 168 [INFO]    [ieee_cv]   * Fold0 2017-12: 0.9318368508185453 | Bear's...PB:0.9165662153383537 PV:0.9153257212423997 All:0.9157662805569584 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "====================\n",
      "0:\tlearn: 0.6745950\ttest: 0.6745815\tbest: 0.6745815 (0)\ttotal: 1.57s\tremaining: 4h 22m 1s\n",
      "50:\tlearn: 0.2251395\ttest: 0.2316345\tbest: 0.2316345 (50)\ttotal: 1m 8s\tremaining: 3h 42m 37s\n",
      "100:\tlearn: 0.1307960\ttest: 0.1415756\tbest: 0.1415756 (100)\ttotal: 2m 14s\tremaining: 3h 40m 28s\n",
      "150:\tlearn: 0.1042225\ttest: 0.1182586\tbest: 0.1182586 (150)\ttotal: 3m 21s\tremaining: 3h 39m 9s\n",
      "200:\tlearn: 0.0934345\ttest: 0.1099121\tbest: 0.1099121 (200)\ttotal: 4m 27s\tremaining: 3h 37m 42s\n",
      "250:\tlearn: 0.0880127\ttest: 0.1060539\tbest: 0.1060539 (250)\ttotal: 5m 34s\tremaining: 3h 36m 18s\n",
      "300:\tlearn: 0.0842831\ttest: 0.1035542\tbest: 0.1035542 (300)\ttotal: 6m 41s\tremaining: 3h 35m 29s\n",
      "350:\tlearn: 0.0813941\ttest: 0.1015636\tbest: 0.1015636 (350)\ttotal: 7m 47s\tremaining: 3h 34m 19s\n",
      "400:\tlearn: 0.0790828\ttest: 0.0999609\tbest: 0.0999609 (400)\ttotal: 8m 54s\tremaining: 3h 33m 17s\n",
      "450:\tlearn: 0.0771875\ttest: 0.0986292\tbest: 0.0986292 (450)\ttotal: 10m 1s\tremaining: 3h 32m 7s\n",
      "500:\tlearn: 0.0755148\ttest: 0.0975373\tbest: 0.0975373 (500)\ttotal: 11m 8s\tremaining: 3h 31m 6s\n",
      "550:\tlearn: 0.0740278\ttest: 0.0965819\tbest: 0.0965819 (550)\ttotal: 12m 16s\tremaining: 3h 30m 27s\n",
      "600:\tlearn: 0.0726675\ttest: 0.0957249\tbest: 0.0957249 (600)\ttotal: 13m 23s\tremaining: 3h 29m 19s\n",
      "650:\tlearn: 0.0714747\ttest: 0.0949639\tbest: 0.0949639 (650)\ttotal: 14m 29s\tremaining: 3h 28m 7s\n",
      "700:\tlearn: 0.0703111\ttest: 0.0942473\tbest: 0.0942473 (700)\ttotal: 15m 35s\tremaining: 3h 26m 55s\n",
      "750:\tlearn: 0.0693085\ttest: 0.0936877\tbest: 0.0936877 (750)\ttotal: 16m 42s\tremaining: 3h 25m 46s\n",
      "800:\tlearn: 0.0682317\ttest: 0.0930289\tbest: 0.0930289 (800)\ttotal: 17m 48s\tremaining: 3h 24m 35s\n",
      "850:\tlearn: 0.0672497\ttest: 0.0925199\tbest: 0.0925199 (850)\ttotal: 18m 54s\tremaining: 3h 23m 21s\n",
      "900:\tlearn: 0.0663408\ttest: 0.0920389\tbest: 0.0920389 (900)\ttotal: 20m\tremaining: 3h 22m 8s\n",
      "950:\tlearn: 0.0654764\ttest: 0.0915497\tbest: 0.0915497 (950)\ttotal: 21m 6s\tremaining: 3h 20m 53s\n",
      "1000:\tlearn: 0.0646524\ttest: 0.0911240\tbest: 0.0911240 (1000)\ttotal: 22m 13s\tremaining: 3h 19m 44s\n",
      "1050:\tlearn: 0.0638604\ttest: 0.0906930\tbest: 0.0906930 (1050)\ttotal: 23m 19s\tremaining: 3h 18m 34s\n",
      "1100:\tlearn: 0.0631251\ttest: 0.0903154\tbest: 0.0903154 (1100)\ttotal: 24m 26s\tremaining: 3h 17m 30s\n",
      "1150:\tlearn: 0.0623327\ttest: 0.0899171\tbest: 0.0899171 (1150)\ttotal: 25m 32s\tremaining: 3h 16m 22s\n",
      "1200:\tlearn: 0.0615762\ttest: 0.0895181\tbest: 0.0895181 (1200)\ttotal: 26m 38s\tremaining: 3h 15m 13s\n",
      "1250:\tlearn: 0.0609101\ttest: 0.0891735\tbest: 0.0891735 (1250)\ttotal: 27m 44s\tremaining: 3h 14m 3s\n",
      "1300:\tlearn: 0.0602185\ttest: 0.0888379\tbest: 0.0888379 (1300)\ttotal: 28m 51s\tremaining: 3h 12m 57s\n",
      "1350:\tlearn: 0.0596122\ttest: 0.0885467\tbest: 0.0885467 (1350)\ttotal: 29m 57s\tremaining: 3h 11m 49s\n",
      "1400:\tlearn: 0.0589990\ttest: 0.0882931\tbest: 0.0882931 (1400)\ttotal: 31m 3s\tremaining: 3h 10m 39s\n",
      "1450:\tlearn: 0.0584437\ttest: 0.0880324\tbest: 0.0880324 (1450)\ttotal: 32m 9s\tremaining: 3h 9m 27s\n",
      "1500:\tlearn: 0.0578387\ttest: 0.0877281\tbest: 0.0877281 (1500)\ttotal: 33m 15s\tremaining: 3h 8m 19s\n",
      "1550:\tlearn: 0.0573114\ttest: 0.0874773\tbest: 0.0874773 (1550)\ttotal: 34m 21s\tremaining: 3h 7m 11s\n",
      "1600:\tlearn: 0.0567990\ttest: 0.0872476\tbest: 0.0872476 (1600)\ttotal: 35m 27s\tremaining: 3h 6m\n",
      "1650:\tlearn: 0.0562986\ttest: 0.0870464\tbest: 0.0870445 (1649)\ttotal: 36m 33s\tremaining: 3h 4m 50s\n",
      "1700:\tlearn: 0.0558112\ttest: 0.0868243\tbest: 0.0868243 (1700)\ttotal: 37m 39s\tremaining: 3h 3m 41s\n",
      "1750:\tlearn: 0.0552602\ttest: 0.0866113\tbest: 0.0866113 (1750)\ttotal: 38m 45s\tremaining: 3h 2m 33s\n",
      "1800:\tlearn: 0.0547937\ttest: 0.0864022\tbest: 0.0864022 (1800)\ttotal: 39m 51s\tremaining: 3h 1m 25s\n",
      "1850:\tlearn: 0.0542901\ttest: 0.0861334\tbest: 0.0861334 (1850)\ttotal: 40m 56s\tremaining: 3h 16s\n",
      "1900:\tlearn: 0.0538307\ttest: 0.0858996\tbest: 0.0858996 (1900)\ttotal: 42m 2s\tremaining: 2h 59m 8s\n",
      "1950:\tlearn: 0.0533509\ttest: 0.0857465\tbest: 0.0857465 (1950)\ttotal: 43m 8s\tremaining: 2h 57m 59s\n",
      "2000:\tlearn: 0.0528844\ttest: 0.0855550\tbest: 0.0855550 (2000)\ttotal: 44m 14s\tremaining: 2h 56m 51s\n",
      "2050:\tlearn: 0.0524212\ttest: 0.0853497\tbest: 0.0853497 (2050)\ttotal: 45m 20s\tremaining: 2h 55m 44s\n",
      "2100:\tlearn: 0.0519699\ttest: 0.0851471\tbest: 0.0851471 (2100)\ttotal: 46m 26s\tremaining: 2h 54m 34s\n",
      "2150:\tlearn: 0.0515830\ttest: 0.0849939\tbest: 0.0849939 (2150)\ttotal: 47m 31s\tremaining: 2h 53m 26s\n",
      "2200:\tlearn: 0.0511469\ttest: 0.0847784\tbest: 0.0847784 (2200)\ttotal: 48m 37s\tremaining: 2h 52m 18s\n",
      "2250:\tlearn: 0.0507468\ttest: 0.0845633\tbest: 0.0845633 (2250)\ttotal: 49m 43s\tremaining: 2h 51m 11s\n",
      "2300:\tlearn: 0.0504017\ttest: 0.0844230\tbest: 0.0844228 (2299)\ttotal: 50m 49s\tremaining: 2h 50m 4s\n",
      "2350:\tlearn: 0.0500047\ttest: 0.0842712\tbest: 0.0842712 (2350)\ttotal: 51m 55s\tremaining: 2h 48m 56s\n",
      "2400:\tlearn: 0.0496448\ttest: 0.0841156\tbest: 0.0841156 (2400)\ttotal: 53m 1s\tremaining: 2h 47m 48s\n",
      "2450:\tlearn: 0.0493077\ttest: 0.0839888\tbest: 0.0839884 (2449)\ttotal: 54m 7s\tremaining: 2h 46m 42s\n",
      "2500:\tlearn: 0.0489243\ttest: 0.0837851\tbest: 0.0837851 (2500)\ttotal: 55m 13s\tremaining: 2h 45m 34s\n",
      "2550:\tlearn: 0.0486069\ttest: 0.0836755\tbest: 0.0836755 (2550)\ttotal: 56m 18s\tremaining: 2h 44m 25s\n",
      "2600:\tlearn: 0.0483001\ttest: 0.0835496\tbest: 0.0835483 (2598)\ttotal: 57m 23s\tremaining: 2h 43m 16s\n",
      "2650:\tlearn: 0.0479758\ttest: 0.0834050\tbest: 0.0834050 (2650)\ttotal: 58m 29s\tremaining: 2h 42m 9s\n",
      "2700:\tlearn: 0.0476375\ttest: 0.0832608\tbest: 0.0832608 (2700)\ttotal: 59m 35s\tremaining: 2h 41m 1s\n",
      "2750:\tlearn: 0.0473441\ttest: 0.0831243\tbest: 0.0831243 (2750)\ttotal: 1h 41s\tremaining: 2h 39m 54s\n",
      "2800:\tlearn: 0.0470563\ttest: 0.0830085\tbest: 0.0830085 (2800)\ttotal: 1h 1m 46s\tremaining: 2h 38m 46s\n",
      "2850:\tlearn: 0.0467554\ttest: 0.0828621\tbest: 0.0828621 (2850)\ttotal: 1h 2m 52s\tremaining: 2h 37m 39s\n",
      "2900:\tlearn: 0.0464506\ttest: 0.0827359\tbest: 0.0827359 (2900)\ttotal: 1h 3m 58s\tremaining: 2h 36m 31s\n",
      "2950:\tlearn: 0.0461918\ttest: 0.0826386\tbest: 0.0826386 (2950)\ttotal: 1h 5m 3s\tremaining: 2h 35m 24s\n",
      "3000:\tlearn: 0.0459062\ttest: 0.0825254\tbest: 0.0825254 (3000)\ttotal: 1h 6m 9s\tremaining: 2h 34m 16s\n",
      "3050:\tlearn: 0.0456038\ttest: 0.0824309\tbest: 0.0824309 (3050)\ttotal: 1h 7m 15s\tremaining: 2h 33m 10s\n",
      "3100:\tlearn: 0.0453319\ttest: 0.0823270\tbest: 0.0823270 (3100)\ttotal: 1h 8m 20s\tremaining: 2h 32m 3s\n",
      "3150:\tlearn: 0.0450400\ttest: 0.0822318\tbest: 0.0822294 (3148)\ttotal: 1h 9m 26s\tremaining: 2h 30m 56s\n",
      "3200:\tlearn: 0.0447640\ttest: 0.0821282\tbest: 0.0821282 (3200)\ttotal: 1h 10m 32s\tremaining: 2h 29m 49s\n",
      "3250:\tlearn: 0.0444970\ttest: 0.0820233\tbest: 0.0820233 (3250)\ttotal: 1h 11m 37s\tremaining: 2h 28m 42s\n",
      "3300:\tlearn: 0.0442380\ttest: 0.0819458\tbest: 0.0819458 (3300)\ttotal: 1h 12m 43s\tremaining: 2h 27m 34s\n",
      "3350:\tlearn: 0.0439298\ttest: 0.0818478\tbest: 0.0818469 (3349)\ttotal: 1h 13m 48s\tremaining: 2h 26m 27s\n",
      "3400:\tlearn: 0.0437235\ttest: 0.0817697\tbest: 0.0817697 (3400)\ttotal: 1h 14m 54s\tremaining: 2h 25m 20s\n",
      "3450:\tlearn: 0.0434653\ttest: 0.0816902\tbest: 0.0816902 (3450)\ttotal: 1h 15m 59s\tremaining: 2h 24m 13s\n",
      "3500:\tlearn: 0.0431869\ttest: 0.0815854\tbest: 0.0815845 (3499)\ttotal: 1h 17m 5s\tremaining: 2h 23m 6s\n",
      "3550:\tlearn: 0.0429155\ttest: 0.0814804\tbest: 0.0814804 (3550)\ttotal: 1h 18m 11s\tremaining: 2h 21m 59s\n",
      "3600:\tlearn: 0.0426768\ttest: 0.0814037\tbest: 0.0814029 (3599)\ttotal: 1h 19m 16s\tremaining: 2h 20m 52s\n",
      "3650:\tlearn: 0.0424376\ttest: 0.0813232\tbest: 0.0813232 (3650)\ttotal: 1h 20m 21s\tremaining: 2h 19m 44s\n",
      "3700:\tlearn: 0.0421571\ttest: 0.0812500\tbest: 0.0812500 (3700)\ttotal: 1h 21m 27s\tremaining: 2h 18m 38s\n",
      "3750:\tlearn: 0.0419123\ttest: 0.0811641\tbest: 0.0811641 (3750)\ttotal: 1h 22m 33s\tremaining: 2h 17m 32s\n",
      "3800:\tlearn: 0.0416848\ttest: 0.0810967\tbest: 0.0810967 (3800)\ttotal: 1h 23m 39s\tremaining: 2h 16m 25s\n",
      "3850:\tlearn: 0.0414721\ttest: 0.0810039\tbest: 0.0810039 (3850)\ttotal: 1h 24m 44s\tremaining: 2h 15m 19s\n",
      "3900:\tlearn: 0.0412560\ttest: 0.0809384\tbest: 0.0809384 (3900)\ttotal: 1h 25m 50s\tremaining: 2h 14m 12s\n",
      "3950:\tlearn: 0.0410111\ttest: 0.0808683\tbest: 0.0808683 (3950)\ttotal: 1h 26m 55s\tremaining: 2h 13m 5s\n",
      "4000:\tlearn: 0.0408149\ttest: 0.0807945\tbest: 0.0807945 (4000)\ttotal: 1h 28m\tremaining: 2h 11m 58s\n",
      "4050:\tlearn: 0.0405890\ttest: 0.0807078\tbest: 0.0807078 (4050)\ttotal: 1h 29m 6s\tremaining: 2h 10m 51s\n",
      "4100:\tlearn: 0.0403666\ttest: 0.0806358\tbest: 0.0806354 (4093)\ttotal: 1h 30m 11s\tremaining: 2h 9m 44s\n",
      "4150:\tlearn: 0.0401511\ttest: 0.0805529\tbest: 0.0805529 (4150)\ttotal: 1h 31m 17s\tremaining: 2h 8m 38s\n",
      "4200:\tlearn: 0.0399616\ttest: 0.0804893\tbest: 0.0804893 (4200)\ttotal: 1h 32m 23s\tremaining: 2h 7m 31s\n",
      "4250:\tlearn: 0.0397332\ttest: 0.0804335\tbest: 0.0804320 (4249)\ttotal: 1h 33m 28s\tremaining: 2h 6m 25s\n",
      "4300:\tlearn: 0.0395086\ttest: 0.0803551\tbest: 0.0803551 (4300)\ttotal: 1h 34m 34s\tremaining: 2h 5m 19s\n",
      "4350:\tlearn: 0.0393013\ttest: 0.0802721\tbest: 0.0802713 (4345)\ttotal: 1h 35m 40s\tremaining: 2h 4m 13s\n",
      "4400:\tlearn: 0.0390676\ttest: 0.0802071\tbest: 0.0802071 (4400)\ttotal: 1h 36m 46s\tremaining: 2h 3m 7s\n",
      "4450:\tlearn: 0.0388573\ttest: 0.0801443\tbest: 0.0801443 (4450)\ttotal: 1h 37m 52s\tremaining: 2h 2m 1s\n",
      "4500:\tlearn: 0.0386452\ttest: 0.0800847\tbest: 0.0800847 (4500)\ttotal: 1h 38m 58s\tremaining: 2h 55s\n",
      "4550:\tlearn: 0.0384547\ttest: 0.0800246\tbest: 0.0800234 (4549)\ttotal: 1h 40m 4s\tremaining: 1h 59m 49s\n",
      "4600:\tlearn: 0.0382654\ttest: 0.0799665\tbest: 0.0799665 (4600)\ttotal: 1h 41m 10s\tremaining: 1h 58m 42s\n",
      "4650:\tlearn: 0.0380738\ttest: 0.0799083\tbest: 0.0799083 (4650)\ttotal: 1h 42m 16s\tremaining: 1h 57m 37s\n",
      "4700:\tlearn: 0.0378925\ttest: 0.0798647\tbest: 0.0798640 (4698)\ttotal: 1h 43m 21s\tremaining: 1h 56m 30s\n",
      "4750:\tlearn: 0.0376995\ttest: 0.0798230\tbest: 0.0798198 (4744)\ttotal: 1h 44m 27s\tremaining: 1h 55m 24s\n",
      "4800:\tlearn: 0.0375272\ttest: 0.0797625\tbest: 0.0797617 (4798)\ttotal: 1h 45m 33s\tremaining: 1h 54m 18s\n",
      "4850:\tlearn: 0.0373603\ttest: 0.0797087\tbest: 0.0797087 (4850)\ttotal: 1h 46m 38s\tremaining: 1h 53m 11s\n",
      "4900:\tlearn: 0.0371788\ttest: 0.0796452\tbest: 0.0796447 (4898)\ttotal: 1h 47m 43s\tremaining: 1h 52m 4s\n",
      "4950:\tlearn: 0.0369981\ttest: 0.0795895\tbest: 0.0795876 (4948)\ttotal: 1h 48m 49s\tremaining: 1h 50m 58s\n",
      "5000:\tlearn: 0.0368219\ttest: 0.0795344\tbest: 0.0795344 (5000)\ttotal: 1h 49m 55s\tremaining: 1h 49m 53s\n",
      "5050:\tlearn: 0.0366562\ttest: 0.0794809\tbest: 0.0794809 (5050)\ttotal: 1h 51m 1s\tremaining: 1h 48m 46s\n",
      "5100:\tlearn: 0.0364894\ttest: 0.0794519\tbest: 0.0794517 (5098)\ttotal: 1h 52m 7s\tremaining: 1h 47m 40s\n",
      "5150:\tlearn: 0.0362870\ttest: 0.0794008\tbest: 0.0794008 (5150)\ttotal: 1h 53m 13s\tremaining: 1h 46m 34s\n",
      "5200:\tlearn: 0.0361277\ttest: 0.0793299\tbest: 0.0793299 (5200)\ttotal: 1h 54m 18s\tremaining: 1h 45m 28s\n",
      "5250:\tlearn: 0.0359622\ttest: 0.0792967\tbest: 0.0792965 (5249)\ttotal: 1h 55m 24s\tremaining: 1h 44m 22s\n",
      "5300:\tlearn: 0.0357962\ttest: 0.0792566\tbest: 0.0792566 (5300)\ttotal: 1h 56m 29s\tremaining: 1h 43m 15s\n",
      "5350:\tlearn: 0.0356240\ttest: 0.0792053\tbest: 0.0792036 (5346)\ttotal: 1h 57m 35s\tremaining: 1h 42m 9s\n",
      "5400:\tlearn: 0.0354462\ttest: 0.0791568\tbest: 0.0791559 (5395)\ttotal: 1h 58m 41s\tremaining: 1h 41m 3s\n",
      "5450:\tlearn: 0.0352850\ttest: 0.0791063\tbest: 0.0791058 (5449)\ttotal: 1h 59m 46s\tremaining: 1h 39m 57s\n",
      "5500:\tlearn: 0.0351152\ttest: 0.0790624\tbest: 0.0790623 (5498)\ttotal: 2h 52s\tremaining: 1h 38m 51s\n",
      "5550:\tlearn: 0.0349623\ttest: 0.0790270\tbest: 0.0790270 (5550)\ttotal: 2h 1m 58s\tremaining: 1h 37m 45s\n",
      "5600:\tlearn: 0.0348097\ttest: 0.0789960\tbest: 0.0789960 (5600)\ttotal: 2h 3m 4s\tremaining: 1h 36m 39s\n",
      "5650:\tlearn: 0.0346520\ttest: 0.0789445\tbest: 0.0789445 (5650)\ttotal: 2h 4m 11s\tremaining: 1h 35m 34s\n",
      "5700:\tlearn: 0.0344937\ttest: 0.0788903\tbest: 0.0788903 (5700)\ttotal: 2h 5m 16s\tremaining: 1h 34m 28s\n",
      "5750:\tlearn: 0.0343344\ttest: 0.0788438\tbest: 0.0788438 (5750)\ttotal: 2h 6m 22s\tremaining: 1h 33m 22s\n",
      "5800:\tlearn: 0.0341776\ttest: 0.0788123\tbest: 0.0788116 (5798)\ttotal: 2h 7m 27s\tremaining: 1h 32m 15s\n",
      "5850:\tlearn: 0.0340251\ttest: 0.0787758\tbest: 0.0787758 (5850)\ttotal: 2h 8m 33s\tremaining: 1h 31m 9s\n",
      "5900:\tlearn: 0.0338571\ttest: 0.0787345\tbest: 0.0787345 (5898)\ttotal: 2h 9m 38s\tremaining: 1h 30m 3s\n",
      "5950:\tlearn: 0.0337165\ttest: 0.0787102\tbest: 0.0787102 (5950)\ttotal: 2h 10m 44s\tremaining: 1h 28m 57s\n",
      "6000:\tlearn: 0.0335389\ttest: 0.0786678\tbest: 0.0786678 (6000)\ttotal: 2h 11m 49s\tremaining: 1h 27m 51s\n",
      "6050:\tlearn: 0.0333858\ttest: 0.0786310\tbest: 0.0786274 (6045)\ttotal: 2h 12m 55s\tremaining: 1h 26m 45s\n",
      "6100:\tlearn: 0.0332305\ttest: 0.0785956\tbest: 0.0785952 (6099)\ttotal: 2h 14m 1s\tremaining: 1h 25m 39s\n",
      "6150:\tlearn: 0.0330908\ttest: 0.0785686\tbest: 0.0785686 (6150)\ttotal: 2h 15m 6s\tremaining: 1h 24m 32s\n",
      "6200:\tlearn: 0.0329419\ttest: 0.0785209\tbest: 0.0785209 (6200)\ttotal: 2h 16m 12s\tremaining: 1h 23m 26s\n",
      "6250:\tlearn: 0.0327873\ttest: 0.0784887\tbest: 0.0784887 (6250)\ttotal: 2h 17m 18s\tremaining: 1h 22m 20s\n",
      "6300:\tlearn: 0.0326326\ttest: 0.0784491\tbest: 0.0784491 (6300)\ttotal: 2h 18m 23s\tremaining: 1h 21m 14s\n",
      "6350:\tlearn: 0.0324919\ttest: 0.0784080\tbest: 0.0784080 (6350)\ttotal: 2h 19m 29s\tremaining: 1h 20m 8s\n",
      "6400:\tlearn: 0.0323627\ttest: 0.0783876\tbest: 0.0783863 (6398)\ttotal: 2h 20m 35s\tremaining: 1h 19m 2s\n",
      "6450:\tlearn: 0.0322311\ttest: 0.0783766\tbest: 0.0783721 (6446)\ttotal: 2h 21m 40s\tremaining: 1h 17m 56s\n",
      "6500:\tlearn: 0.0321156\ttest: 0.0783455\tbest: 0.0783455 (6500)\ttotal: 2h 22m 45s\tremaining: 1h 16m 50s\n",
      "6550:\tlearn: 0.0319815\ttest: 0.0783383\tbest: 0.0783345 (6547)\ttotal: 2h 23m 52s\tremaining: 1h 15m 44s\n",
      "6600:\tlearn: 0.0318472\ttest: 0.0783224\tbest: 0.0783195 (6592)\ttotal: 2h 24m 57s\tremaining: 1h 14m 38s\n",
      "6650:\tlearn: 0.0317027\ttest: 0.0782968\tbest: 0.0782965 (6649)\ttotal: 2h 26m 3s\tremaining: 1h 13m 32s\n",
      "6700:\tlearn: 0.0315726\ttest: 0.0782451\tbest: 0.0782451 (6700)\ttotal: 2h 27m 9s\tremaining: 1h 12m 26s\n",
      "6750:\tlearn: 0.0314317\ttest: 0.0782113\tbest: 0.0782087 (6749)\ttotal: 2h 28m 14s\tremaining: 1h 11m 20s\n",
      "6800:\tlearn: 0.0312783\ttest: 0.0781785\tbest: 0.0781775 (6799)\ttotal: 2h 29m 20s\tremaining: 1h 10m 14s\n",
      "6850:\tlearn: 0.0311492\ttest: 0.0781605\tbest: 0.0781604 (6845)\ttotal: 2h 30m 26s\tremaining: 1h 9m 8s\n",
      "6900:\tlearn: 0.0310260\ttest: 0.0781364\tbest: 0.0781364 (6900)\ttotal: 2h 31m 31s\tremaining: 1h 8m 2s\n",
      "6950:\tlearn: 0.0308933\ttest: 0.0781172\tbest: 0.0781163 (6947)\ttotal: 2h 32m 37s\tremaining: 1h 6m 56s\n",
      "7000:\tlearn: 0.0307433\ttest: 0.0780867\tbest: 0.0780842 (6998)\ttotal: 2h 33m 43s\tremaining: 1h 5m 50s\n",
      "7050:\tlearn: 0.0306114\ttest: 0.0780613\tbest: 0.0780613 (7050)\ttotal: 2h 34m 48s\tremaining: 1h 4m 44s\n",
      "7100:\tlearn: 0.0304814\ttest: 0.0780464\tbest: 0.0780464 (7100)\ttotal: 2h 35m 54s\tremaining: 1h 3m 38s\n",
      "7150:\tlearn: 0.0303582\ttest: 0.0780360\tbest: 0.0780357 (7148)\ttotal: 2h 37m\tremaining: 1h 2m 33s\n",
      "7200:\tlearn: 0.0302404\ttest: 0.0780238\tbest: 0.0780196 (7184)\ttotal: 2h 38m 5s\tremaining: 1h 1m 27s\n",
      "7250:\tlearn: 0.0301148\ttest: 0.0779897\tbest: 0.0779882 (7242)\ttotal: 2h 39m 11s\tremaining: 1h 21s\n",
      "7300:\tlearn: 0.0299815\ttest: 0.0779723\tbest: 0.0779709 (7295)\ttotal: 2h 40m 16s\tremaining: 59m 15s\n",
      "7350:\tlearn: 0.0298522\ttest: 0.0779569\tbest: 0.0779542 (7335)\ttotal: 2h 41m 22s\tremaining: 58m 9s\n",
      "7400:\tlearn: 0.0297343\ttest: 0.0779379\tbest: 0.0779332 (7395)\ttotal: 2h 42m 27s\tremaining: 57m 3s\n",
      "7450:\tlearn: 0.0295926\ttest: 0.0778983\tbest: 0.0778983 (7450)\ttotal: 2h 43m 33s\tremaining: 55m 57s\n",
      "7500:\tlearn: 0.0294723\ttest: 0.0778868\tbest: 0.0778866 (7499)\ttotal: 2h 44m 39s\tremaining: 54m 51s\n",
      "7550:\tlearn: 0.0293381\ttest: 0.0778778\tbest: 0.0778761 (7548)\ttotal: 2h 45m 45s\tremaining: 53m 45s\n",
      "7600:\tlearn: 0.0292198\ttest: 0.0778463\tbest: 0.0778438 (7591)\ttotal: 2h 46m 51s\tremaining: 52m 39s\n",
      "7650:\tlearn: 0.0291113\ttest: 0.0778252\tbest: 0.0778252 (7650)\ttotal: 2h 47m 56s\tremaining: 51m 33s\n",
      "7700:\tlearn: 0.0289981\ttest: 0.0778110\tbest: 0.0778101 (7693)\ttotal: 2h 49m 1s\tremaining: 50m 27s\n",
      "7750:\tlearn: 0.0288653\ttest: 0.0777935\tbest: 0.0777935 (7750)\ttotal: 2h 50m 8s\tremaining: 49m 21s\n",
      "7800:\tlearn: 0.0287371\ttest: 0.0777788\tbest: 0.0777726 (7784)\ttotal: 2h 51m 13s\tremaining: 48m 16s\n",
      "7850:\tlearn: 0.0286142\ttest: 0.0777731\tbest: 0.0777721 (7843)\ttotal: 2h 52m 19s\tremaining: 47m 10s\n",
      "7900:\tlearn: 0.0284978\ttest: 0.0777448\tbest: 0.0777448 (7900)\ttotal: 2h 53m 24s\tremaining: 46m 4s\n",
      "7950:\tlearn: 0.0283732\ttest: 0.0777265\tbest: 0.0777265 (7950)\ttotal: 2h 54m 30s\tremaining: 44m 58s\n",
      "8000:\tlearn: 0.0282648\ttest: 0.0777275\tbest: 0.0777241 (7987)\ttotal: 2h 55m 35s\tremaining: 43m 52s\n",
      "8050:\tlearn: 0.0281527\ttest: 0.0777143\tbest: 0.0777139 (8049)\ttotal: 2h 56m 41s\tremaining: 42m 46s\n",
      "8100:\tlearn: 0.0280352\ttest: 0.0777014\tbest: 0.0776989 (8083)\ttotal: 2h 57m 47s\tremaining: 41m 40s\n",
      "8150:\tlearn: 0.0279202\ttest: 0.0776882\tbest: 0.0776882 (8150)\ttotal: 2h 58m 52s\tremaining: 40m 34s\n",
      "8200:\tlearn: 0.0278069\ttest: 0.0776804\tbest: 0.0776731 (8192)\ttotal: 2h 59m 58s\tremaining: 39m 28s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.07767305736\n",
      "bestIteration = 8192\n",
      "\n",
      "Shrink model to first 8193 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-03 04:52:15,036 func.utils 168 [INFO]    [ieee_cv]   * Fold1 2018-3: 0.9483098336330369 | Bear's...PB:0.9216978431961692 PV:0.9235016436923962 All:0.9234222452041446 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  * Fold1 Validation-DT-M 2018-3: 101968] done in 10889 s\n",
      "====================\n",
      "====================\n",
      "0:\tlearn: 0.6749340\ttest: 0.6751861\tbest: 0.6751861 (0)\ttotal: 2.07s\tremaining: 5h 45m\n",
      "50:\tlearn: 0.2255372\ttest: 0.2315652\tbest: 0.2315652 (50)\ttotal: 1m 11s\tremaining: 3h 54m 3s\n",
      "100:\tlearn: 0.1312113\ttest: 0.1402716\tbest: 0.1402716 (100)\ttotal: 2m 20s\tremaining: 3h 49m 7s\n",
      "150:\tlearn: 0.1049741\ttest: 0.1160752\tbest: 0.1160752 (150)\ttotal: 3m 28s\tremaining: 3h 46m 43s\n",
      "200:\tlearn: 0.0945616\ttest: 0.1070435\tbest: 0.1070435 (200)\ttotal: 4m 37s\tremaining: 3h 45m 8s\n",
      "250:\tlearn: 0.0889802\ttest: 0.1025887\tbest: 0.1025887 (250)\ttotal: 5m 46s\tremaining: 3h 44m 17s\n",
      "300:\tlearn: 0.0852284\ttest: 0.0998341\tbest: 0.0998341 (300)\ttotal: 6m 55s\tremaining: 3h 43m 13s\n",
      "350:\tlearn: 0.0823183\ttest: 0.0978386\tbest: 0.0978386 (350)\ttotal: 8m 4s\tremaining: 3h 42m 9s\n",
      "400:\tlearn: 0.0799851\ttest: 0.0961961\tbest: 0.0961961 (400)\ttotal: 9m 13s\tremaining: 3h 40m 51s\n",
      "450:\tlearn: 0.0781961\ttest: 0.0949474\tbest: 0.0949474 (450)\ttotal: 10m 21s\tremaining: 3h 39m 25s\n",
      "500:\tlearn: 0.0764617\ttest: 0.0936985\tbest: 0.0936985 (500)\ttotal: 11m 30s\tremaining: 3h 38m 6s\n",
      "550:\tlearn: 0.0749920\ttest: 0.0926335\tbest: 0.0926335 (550)\ttotal: 12m 38s\tremaining: 3h 36m 45s\n",
      "600:\tlearn: 0.0736895\ttest: 0.0918000\tbest: 0.0918000 (600)\ttotal: 13m 46s\tremaining: 3h 35m 19s\n",
      "650:\tlearn: 0.0725115\ttest: 0.0910904\tbest: 0.0910904 (650)\ttotal: 14m 54s\tremaining: 3h 34m 1s\n",
      "700:\tlearn: 0.0714467\ttest: 0.0903812\tbest: 0.0903812 (700)\ttotal: 16m 1s\tremaining: 3h 32m 40s\n",
      "750:\tlearn: 0.0703373\ttest: 0.0897016\tbest: 0.0897016 (750)\ttotal: 17m 10s\tremaining: 3h 31m 28s\n",
      "800:\tlearn: 0.0694364\ttest: 0.0891861\tbest: 0.0891861 (800)\ttotal: 18m 18s\tremaining: 3h 30m 11s\n",
      "850:\tlearn: 0.0685616\ttest: 0.0887155\tbest: 0.0887155 (850)\ttotal: 19m 26s\tremaining: 3h 28m 56s\n",
      "900:\tlearn: 0.0676916\ttest: 0.0882058\tbest: 0.0882058 (900)\ttotal: 20m 34s\tremaining: 3h 27m 42s\n",
      "950:\tlearn: 0.0668070\ttest: 0.0876973\tbest: 0.0876973 (950)\ttotal: 21m 42s\tremaining: 3h 26m 28s\n",
      "1000:\tlearn: 0.0659740\ttest: 0.0872104\tbest: 0.0872104 (1000)\ttotal: 22m 49s\tremaining: 3h 25m 14s\n",
      "1050:\tlearn: 0.0651842\ttest: 0.0868331\tbest: 0.0868331 (1050)\ttotal: 23m 57s\tremaining: 3h 23m 59s\n",
      "1100:\tlearn: 0.0643765\ttest: 0.0863818\tbest: 0.0863818 (1100)\ttotal: 25m 5s\tremaining: 3h 22m 46s\n",
      "1150:\tlearn: 0.0636552\ttest: 0.0860552\tbest: 0.0860552 (1150)\ttotal: 26m 13s\tremaining: 3h 21m 34s\n",
      "1200:\tlearn: 0.0629240\ttest: 0.0857379\tbest: 0.0857379 (1200)\ttotal: 27m 21s\tremaining: 3h 20m 23s\n",
      "1250:\tlearn: 0.0622314\ttest: 0.0853729\tbest: 0.0853729 (1250)\ttotal: 28m 28s\tremaining: 3h 19m 11s\n",
      "1300:\tlearn: 0.0616492\ttest: 0.0850535\tbest: 0.0850535 (1300)\ttotal: 29m 36s\tremaining: 3h 17m 57s\n",
      "1350:\tlearn: 0.0610214\ttest: 0.0847596\tbest: 0.0847596 (1350)\ttotal: 30m 44s\tremaining: 3h 16m 45s\n",
      "1400:\tlearn: 0.0603768\ttest: 0.0844512\tbest: 0.0844512 (1400)\ttotal: 31m 52s\tremaining: 3h 15m 35s\n",
      "1450:\tlearn: 0.0597518\ttest: 0.0841593\tbest: 0.0841593 (1450)\ttotal: 33m\tremaining: 3h 14m 28s\n",
      "1500:\tlearn: 0.0591127\ttest: 0.0838677\tbest: 0.0838677 (1500)\ttotal: 34m 8s\tremaining: 3h 13m 17s\n",
      "1550:\tlearn: 0.0585079\ttest: 0.0836286\tbest: 0.0836286 (1550)\ttotal: 35m 16s\tremaining: 3h 12m 8s\n",
      "1600:\tlearn: 0.0580089\ttest: 0.0833779\tbest: 0.0833779 (1600)\ttotal: 36m 23s\tremaining: 3h 10m 57s\n",
      "1650:\tlearn: 0.0574440\ttest: 0.0831227\tbest: 0.0831227 (1650)\ttotal: 37m 31s\tremaining: 3h 9m 46s\n",
      "1700:\tlearn: 0.0569239\ttest: 0.0829051\tbest: 0.0829051 (1700)\ttotal: 38m 39s\tremaining: 3h 8m 34s\n",
      "1750:\tlearn: 0.0564081\ttest: 0.0826643\tbest: 0.0826642 (1749)\ttotal: 39m 47s\tremaining: 3h 7m 28s\n",
      "1800:\tlearn: 0.0559152\ttest: 0.0824381\tbest: 0.0824381 (1800)\ttotal: 40m 55s\tremaining: 3h 6m 18s\n",
      "1850:\tlearn: 0.0553845\ttest: 0.0822073\tbest: 0.0822073 (1850)\ttotal: 42m 3s\tremaining: 3h 5m 8s\n",
      "1900:\tlearn: 0.0548919\ttest: 0.0819575\tbest: 0.0819575 (1900)\ttotal: 43m 11s\tremaining: 3h 3m 59s\n",
      "1950:\tlearn: 0.0544193\ttest: 0.0817462\tbest: 0.0817462 (1950)\ttotal: 44m 19s\tremaining: 3h 2m 50s\n",
      "2000:\tlearn: 0.0539529\ttest: 0.0815717\tbest: 0.0815717 (2000)\ttotal: 45m 26s\tremaining: 3h 1m 41s\n",
      "2050:\tlearn: 0.0535269\ttest: 0.0813837\tbest: 0.0813837 (2050)\ttotal: 46m 34s\tremaining: 3h 31s\n",
      "2100:\tlearn: 0.0530968\ttest: 0.0812148\tbest: 0.0812148 (2100)\ttotal: 47m 42s\tremaining: 2h 59m 21s\n",
      "2150:\tlearn: 0.0527030\ttest: 0.0810396\tbest: 0.0810396 (2150)\ttotal: 48m 49s\tremaining: 2h 58m 11s\n",
      "2200:\tlearn: 0.0522898\ttest: 0.0808800\tbest: 0.0808800 (2200)\ttotal: 49m 57s\tremaining: 2h 57m 1s\n",
      "2250:\tlearn: 0.0518897\ttest: 0.0807447\tbest: 0.0807447 (2250)\ttotal: 51m 5s\tremaining: 2h 55m 52s\n",
      "2300:\tlearn: 0.0515238\ttest: 0.0805953\tbest: 0.0805953 (2300)\ttotal: 52m 13s\tremaining: 2h 54m 43s\n",
      "2350:\tlearn: 0.0511126\ttest: 0.0804169\tbest: 0.0804169 (2350)\ttotal: 53m 21s\tremaining: 2h 53m 35s\n",
      "2400:\tlearn: 0.0507750\ttest: 0.0802809\tbest: 0.0802809 (2400)\ttotal: 54m 29s\tremaining: 2h 52m 27s\n",
      "2450:\tlearn: 0.0504316\ttest: 0.0801242\tbest: 0.0801242 (2450)\ttotal: 55m 37s\tremaining: 2h 51m 18s\n",
      "2500:\tlearn: 0.0500412\ttest: 0.0799601\tbest: 0.0799601 (2500)\ttotal: 56m 45s\tremaining: 2h 50m 10s\n",
      "2550:\tlearn: 0.0496722\ttest: 0.0798436\tbest: 0.0798410 (2547)\ttotal: 57m 52s\tremaining: 2h 49m\n",
      "2600:\tlearn: 0.0493288\ttest: 0.0797204\tbest: 0.0797204 (2600)\ttotal: 58m 59s\tremaining: 2h 47m 49s\n",
      "2650:\tlearn: 0.0490185\ttest: 0.0795711\tbest: 0.0795711 (2650)\ttotal: 1h 7s\tremaining: 2h 46m 39s\n",
      "2700:\tlearn: 0.0487180\ttest: 0.0794515\tbest: 0.0794505 (2699)\ttotal: 1h 1m 14s\tremaining: 2h 45m 30s\n",
      "2750:\tlearn: 0.0483760\ttest: 0.0793365\tbest: 0.0793365 (2750)\ttotal: 1h 2m 22s\tremaining: 2h 44m 21s\n",
      "2800:\tlearn: 0.0480707\ttest: 0.0792176\tbest: 0.0792176 (2800)\ttotal: 1h 3m 29s\tremaining: 2h 43m 11s\n",
      "2850:\tlearn: 0.0477606\ttest: 0.0790961\tbest: 0.0790961 (2850)\ttotal: 1h 4m 36s\tremaining: 2h 42m 1s\n",
      "2900:\tlearn: 0.0474790\ttest: 0.0790029\tbest: 0.0790029 (2900)\ttotal: 1h 5m 44s\tremaining: 2h 40m 52s\n",
      "2950:\tlearn: 0.0471538\ttest: 0.0788741\tbest: 0.0788741 (2950)\ttotal: 1h 6m 52s\tremaining: 2h 39m 43s\n",
      "3000:\tlearn: 0.0468457\ttest: 0.0787557\tbest: 0.0787541 (2999)\ttotal: 1h 7m 59s\tremaining: 2h 38m 34s\n",
      "3050:\tlearn: 0.0465553\ttest: 0.0786668\tbest: 0.0786668 (3050)\ttotal: 1h 9m 6s\tremaining: 2h 37m 24s\n",
      "3100:\tlearn: 0.0462715\ttest: 0.0785554\tbest: 0.0785554 (3100)\ttotal: 1h 10m 14s\tremaining: 2h 36m 15s\n",
      "3150:\tlearn: 0.0459788\ttest: 0.0784740\tbest: 0.0784740 (3150)\ttotal: 1h 11m 21s\tremaining: 2h 35m 6s\n",
      "3200:\tlearn: 0.0456939\ttest: 0.0783475\tbest: 0.0783475 (3200)\ttotal: 1h 12m 29s\tremaining: 2h 33m 58s\n",
      "3250:\tlearn: 0.0454401\ttest: 0.0782622\tbest: 0.0782622 (3250)\ttotal: 1h 13m 36s\tremaining: 2h 32m 49s\n",
      "3300:\tlearn: 0.0451644\ttest: 0.0781251\tbest: 0.0781251 (3300)\ttotal: 1h 14m 44s\tremaining: 2h 31m 40s\n",
      "3350:\tlearn: 0.0448709\ttest: 0.0780258\tbest: 0.0780258 (3350)\ttotal: 1h 15m 51s\tremaining: 2h 30m 30s\n",
      "3400:\tlearn: 0.0446063\ttest: 0.0779192\tbest: 0.0779185 (3397)\ttotal: 1h 16m 58s\tremaining: 2h 29m 20s\n",
      "3450:\tlearn: 0.0443559\ttest: 0.0778159\tbest: 0.0778159 (3450)\ttotal: 1h 18m 5s\tremaining: 2h 28m 11s\n",
      "3500:\tlearn: 0.0441015\ttest: 0.0777303\tbest: 0.0777303 (3500)\ttotal: 1h 19m 12s\tremaining: 2h 27m 2s\n",
      "3550:\tlearn: 0.0438707\ttest: 0.0776428\tbest: 0.0776428 (3550)\ttotal: 1h 20m 19s\tremaining: 2h 25m 53s\n",
      "3600:\tlearn: 0.0436284\ttest: 0.0775568\tbest: 0.0775568 (3600)\ttotal: 1h 21m 27s\tremaining: 2h 24m 44s\n",
      "3650:\tlearn: 0.0433532\ttest: 0.0774676\tbest: 0.0774669 (3649)\ttotal: 1h 22m 34s\tremaining: 2h 23m 36s\n",
      "3700:\tlearn: 0.0430897\ttest: 0.0773938\tbest: 0.0773938 (3700)\ttotal: 1h 23m 41s\tremaining: 2h 22m 26s\n",
      "3750:\tlearn: 0.0428470\ttest: 0.0773246\tbest: 0.0773246 (3750)\ttotal: 1h 24m 48s\tremaining: 2h 21m 17s\n",
      "3800:\tlearn: 0.0425956\ttest: 0.0772454\tbest: 0.0772454 (3800)\ttotal: 1h 25m 56s\tremaining: 2h 20m 9s\n",
      "3850:\tlearn: 0.0423457\ttest: 0.0771623\tbest: 0.0771623 (3850)\ttotal: 1h 27m 3s\tremaining: 2h 19m\n",
      "3900:\tlearn: 0.0421090\ttest: 0.0770895\tbest: 0.0770895 (3900)\ttotal: 1h 28m 10s\tremaining: 2h 17m 51s\n",
      "3950:\tlearn: 0.0418630\ttest: 0.0770239\tbest: 0.0770239 (3950)\ttotal: 1h 29m 17s\tremaining: 2h 16m 42s\n",
      "4000:\tlearn: 0.0416114\ttest: 0.0769297\tbest: 0.0769297 (4000)\ttotal: 1h 30m 25s\tremaining: 2h 15m 34s\n",
      "4050:\tlearn: 0.0413951\ttest: 0.0768668\tbest: 0.0768668 (4050)\ttotal: 1h 31m 32s\tremaining: 2h 14m 26s\n",
      "4100:\tlearn: 0.0411805\ttest: 0.0767916\tbest: 0.0767916 (4100)\ttotal: 1h 32m 40s\tremaining: 2h 13m 17s\n",
      "4150:\tlearn: 0.0409553\ttest: 0.0767169\tbest: 0.0767169 (4150)\ttotal: 1h 33m 47s\tremaining: 2h 12m 9s\n",
      "4200:\tlearn: 0.0407368\ttest: 0.0766414\tbest: 0.0766414 (4200)\ttotal: 1h 34m 54s\tremaining: 2h 11m\n",
      "4250:\tlearn: 0.0405332\ttest: 0.0765850\tbest: 0.0765832 (4249)\ttotal: 1h 36m 1s\tremaining: 2h 9m 51s\n",
      "4300:\tlearn: 0.0403266\ttest: 0.0765171\tbest: 0.0765164 (4298)\ttotal: 1h 37m 8s\tremaining: 2h 8m 42s\n",
      "4350:\tlearn: 0.0401209\ttest: 0.0764258\tbest: 0.0764258 (4350)\ttotal: 1h 38m 15s\tremaining: 2h 7m 34s\n",
      "4400:\tlearn: 0.0399169\ttest: 0.0763537\tbest: 0.0763523 (4399)\ttotal: 1h 39m 23s\tremaining: 2h 6m 26s\n",
      "4450:\tlearn: 0.0397256\ttest: 0.0762984\tbest: 0.0762982 (4449)\ttotal: 1h 40m 30s\tremaining: 2h 5m 17s\n",
      "4500:\tlearn: 0.0395367\ttest: 0.0762129\tbest: 0.0762129 (4500)\ttotal: 1h 41m 37s\tremaining: 2h 4m 9s\n",
      "4550:\tlearn: 0.0393274\ttest: 0.0761491\tbest: 0.0761491 (4550)\ttotal: 1h 42m 44s\tremaining: 2h 3m\n",
      "4600:\tlearn: 0.0391422\ttest: 0.0760930\tbest: 0.0760926 (4599)\ttotal: 1h 43m 52s\tremaining: 2h 1m 53s\n",
      "4650:\tlearn: 0.0389603\ttest: 0.0760597\tbest: 0.0760597 (4650)\ttotal: 1h 44m 59s\tremaining: 2h 44s\n",
      "4700:\tlearn: 0.0387856\ttest: 0.0760040\tbest: 0.0760040 (4700)\ttotal: 1h 46m 6s\tremaining: 1h 59m 36s\n",
      "4750:\tlearn: 0.0385840\ttest: 0.0759333\tbest: 0.0759333 (4750)\ttotal: 1h 47m 14s\tremaining: 1h 58m 28s\n",
      "4800:\tlearn: 0.0383822\ttest: 0.0758781\tbest: 0.0758781 (4800)\ttotal: 1h 48m 22s\tremaining: 1h 57m 21s\n",
      "4850:\tlearn: 0.0381895\ttest: 0.0758117\tbest: 0.0758114 (4848)\ttotal: 1h 49m 28s\tremaining: 1h 56m 12s\n",
      "4900:\tlearn: 0.0379769\ttest: 0.0757630\tbest: 0.0757611 (4899)\ttotal: 1h 50m 36s\tremaining: 1h 55m 4s\n",
      "4950:\tlearn: 0.0377732\ttest: 0.0757041\tbest: 0.0757041 (4950)\ttotal: 1h 51m 44s\tremaining: 1h 53m 56s\n",
      "5000:\tlearn: 0.0375812\ttest: 0.0756451\tbest: 0.0756451 (5000)\ttotal: 1h 52m 51s\tremaining: 1h 52m 48s\n",
      "5050:\tlearn: 0.0374111\ttest: 0.0755880\tbest: 0.0755880 (5050)\ttotal: 1h 53m 58s\tremaining: 1h 51m 40s\n",
      "5100:\tlearn: 0.0372309\ttest: 0.0755371\tbest: 0.0755315 (5097)\ttotal: 1h 55m 6s\tremaining: 1h 50m 32s\n",
      "5150:\tlearn: 0.0370705\ttest: 0.0754864\tbest: 0.0754864 (5150)\ttotal: 1h 56m 13s\tremaining: 1h 49m 24s\n",
      "5200:\tlearn: 0.0369021\ttest: 0.0754317\tbest: 0.0754317 (5200)\ttotal: 1h 57m 20s\tremaining: 1h 48m 16s\n",
      "5250:\tlearn: 0.0367308\ttest: 0.0753654\tbest: 0.0753633 (5249)\ttotal: 1h 58m 28s\tremaining: 1h 47m 8s\n",
      "5300:\tlearn: 0.0365776\ttest: 0.0753384\tbest: 0.0753343 (5290)\ttotal: 1h 59m 35s\tremaining: 1h 46m\n",
      "5350:\tlearn: 0.0364099\ttest: 0.0753033\tbest: 0.0753026 (5345)\ttotal: 2h 42s\tremaining: 1h 44m 52s\n",
      "5400:\tlearn: 0.0362661\ttest: 0.0752665\tbest: 0.0752648 (5399)\ttotal: 2h 1m 49s\tremaining: 1h 43m 44s\n",
      "5450:\tlearn: 0.0361059\ttest: 0.0752179\tbest: 0.0752179 (5450)\ttotal: 2h 2m 56s\tremaining: 1h 42m 36s\n",
      "5500:\tlearn: 0.0359497\ttest: 0.0751649\tbest: 0.0751649 (5500)\ttotal: 2h 4m 4s\tremaining: 1h 41m 28s\n",
      "5550:\tlearn: 0.0357801\ttest: 0.0751268\tbest: 0.0751248 (5547)\ttotal: 2h 5m 11s\tremaining: 1h 40m 20s\n",
      "5600:\tlearn: 0.0355891\ttest: 0.0750727\tbest: 0.0750727 (5600)\ttotal: 2h 6m 18s\tremaining: 1h 39m 12s\n",
      "5650:\tlearn: 0.0354079\ttest: 0.0750218\tbest: 0.0750218 (5650)\ttotal: 2h 7m 25s\tremaining: 1h 38m 4s\n",
      "5700:\tlearn: 0.0352571\ttest: 0.0749691\tbest: 0.0749691 (5700)\ttotal: 2h 8m 32s\tremaining: 1h 36m 56s\n",
      "5750:\tlearn: 0.0351018\ttest: 0.0749161\tbest: 0.0749110 (5747)\ttotal: 2h 9m 40s\tremaining: 1h 35m 48s\n",
      "5800:\tlearn: 0.0349309\ttest: 0.0748501\tbest: 0.0748494 (5798)\ttotal: 2h 10m 47s\tremaining: 1h 34m 40s\n",
      "5850:\tlearn: 0.0347689\ttest: 0.0748038\tbest: 0.0748016 (5846)\ttotal: 2h 11m 55s\tremaining: 1h 33m 32s\n",
      "5900:\tlearn: 0.0346233\ttest: 0.0747679\tbest: 0.0747679 (5900)\ttotal: 2h 13m 2s\tremaining: 1h 32m 24s\n",
      "5950:\tlearn: 0.0344870\ttest: 0.0747227\tbest: 0.0747227 (5950)\ttotal: 2h 14m 9s\tremaining: 1h 31m 16s\n",
      "6000:\tlearn: 0.0343392\ttest: 0.0746860\tbest: 0.0746860 (6000)\ttotal: 2h 15m 16s\tremaining: 1h 30m 8s\n",
      "6050:\tlearn: 0.0341743\ttest: 0.0746191\tbest: 0.0746188 (6048)\ttotal: 2h 16m 23s\tremaining: 1h 29m\n",
      "6100:\tlearn: 0.0340088\ttest: 0.0745797\tbest: 0.0745797 (6100)\ttotal: 2h 17m 31s\tremaining: 1h 27m 53s\n",
      "6150:\tlearn: 0.0338692\ttest: 0.0745351\tbest: 0.0745351 (6150)\ttotal: 2h 18m 38s\tremaining: 1h 26m 45s\n",
      "6200:\tlearn: 0.0337141\ttest: 0.0744973\tbest: 0.0744973 (6200)\ttotal: 2h 19m 46s\tremaining: 1h 25m 37s\n",
      "6250:\tlearn: 0.0335756\ttest: 0.0744536\tbest: 0.0744536 (6250)\ttotal: 2h 20m 53s\tremaining: 1h 24m 29s\n",
      "6300:\tlearn: 0.0334348\ttest: 0.0744198\tbest: 0.0744198 (6300)\ttotal: 2h 22m\tremaining: 1h 23m 22s\n",
      "6350:\tlearn: 0.0332941\ttest: 0.0743899\tbest: 0.0743891 (6349)\ttotal: 2h 23m 7s\tremaining: 1h 22m 14s\n",
      "6400:\tlearn: 0.0331684\ttest: 0.0743562\tbest: 0.0743547 (6399)\ttotal: 2h 24m 14s\tremaining: 1h 21m 5s\n",
      "6450:\tlearn: 0.0330290\ttest: 0.0743362\tbest: 0.0743343 (6448)\ttotal: 2h 25m 21s\tremaining: 1h 19m 58s\n",
      "6500:\tlearn: 0.0328939\ttest: 0.0742773\tbest: 0.0742773 (6500)\ttotal: 2h 26m 28s\tremaining: 1h 18m 50s\n",
      "6550:\tlearn: 0.0327555\ttest: 0.0742401\tbest: 0.0742398 (6549)\ttotal: 2h 27m 36s\tremaining: 1h 17m 42s\n",
      "6600:\tlearn: 0.0326158\ttest: 0.0742206\tbest: 0.0742206 (6600)\ttotal: 2h 28m 43s\tremaining: 1h 16m 34s\n",
      "6650:\tlearn: 0.0324907\ttest: 0.0741941\tbest: 0.0741925 (6647)\ttotal: 2h 29m 50s\tremaining: 1h 15m 27s\n",
      "6700:\tlearn: 0.0323481\ttest: 0.0741490\tbest: 0.0741490 (6700)\ttotal: 2h 30m 57s\tremaining: 1h 14m 19s\n",
      "6750:\tlearn: 0.0322299\ttest: 0.0741158\tbest: 0.0741134 (6747)\ttotal: 2h 32m 5s\tremaining: 1h 13m 11s\n",
      "6800:\tlearn: 0.0320978\ttest: 0.0740869\tbest: 0.0740869 (6800)\ttotal: 2h 33m 12s\tremaining: 1h 12m 3s\n",
      "6850:\tlearn: 0.0319544\ttest: 0.0740513\tbest: 0.0740513 (6850)\ttotal: 2h 34m 19s\tremaining: 1h 10m 56s\n",
      "6900:\tlearn: 0.0318268\ttest: 0.0740322\tbest: 0.0740309 (6895)\ttotal: 2h 35m 27s\tremaining: 1h 9m 48s\n",
      "6950:\tlearn: 0.0316953\ttest: 0.0740053\tbest: 0.0740030 (6943)\ttotal: 2h 36m 34s\tremaining: 1h 8m 40s\n",
      "7000:\tlearn: 0.0315564\ttest: 0.0739615\tbest: 0.0739615 (7000)\ttotal: 2h 37m 41s\tremaining: 1h 7m 33s\n",
      "7050:\tlearn: 0.0314178\ttest: 0.0739201\tbest: 0.0739201 (7050)\ttotal: 2h 38m 49s\tremaining: 1h 6m 25s\n",
      "7100:\tlearn: 0.0312943\ttest: 0.0738813\tbest: 0.0738813 (7100)\ttotal: 2h 39m 56s\tremaining: 1h 5m 17s\n",
      "7150:\tlearn: 0.0311672\ttest: 0.0738564\tbest: 0.0738560 (7149)\ttotal: 2h 41m 3s\tremaining: 1h 4m 10s\n",
      "7200:\tlearn: 0.0310439\ttest: 0.0738180\tbest: 0.0738170 (7198)\ttotal: 2h 42m 10s\tremaining: 1h 3m 2s\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "model_type = \"cat\"\n",
    "params = {\n",
    "#     'n_jobs': 96,\n",
    "    'seed': 1208,\n",
    "#     'subsample': 0.9,\n",
    "#     'boosting_type':'Ordered',\n",
    "    'num_boost_round':10000,\n",
    "    'random_seed': 1208,\n",
    "#     'has_time': True,\n",
    "    'max_depth': 10,\n",
    "    'loss_function': 'Logloss',\n",
    "    'custom_loss':['AUC'],\n",
    "#     'logging_level':'Silent',\n",
    "    'task_type' : 'CPU',\n",
    "    'early_stopping_rounds' : 100,\n",
    "    'n_splits': n_splits,\n",
    "    'model_type': model_type,\n",
    "    'fold': ['stratified', 'group'][1],\n",
    "    'verbose': 50,\n",
    "}\n",
    "\n",
    "if is_submit:\n",
    "    pass\n",
    "    params['learning_rate'] = 0.01\n",
    "#     params['learning_rate'] = 0.07\n",
    "#     params['learning_rate'] = 0.1\n",
    "#     params[\"early_stopping_rounds\"] = 100\n",
    "    params[\"early_stopping_rounds\"] = 50\n",
    "#     params[\"early_stopping_rounds\"] = 10\n",
    "\n",
    "use_cols = [col for col in df_train.columns if col not in COLUMNS_IGNORE]\n",
    "logger.info(f\"* EXP: dataset {set_type} {tmp_train.shape} lr {params['learning_rate']} \")\n",
    "            \n",
    "if False:\n",
    "#     sample = tmp_train.sample(10000)\n",
    "#     sample[COLUMN_GROUP].value_counts()\n",
    "    use_cols = [col for col in df_train.columns if col not in COLUMNS_IGNORE][:10]\n",
    "    params['early_stopping_rounds'] = 1\n",
    "    params['num_boost_round'] = 1\n",
    "\n",
    "feim, _ = eval_train(\n",
    "    logger,\n",
    "    tmp_train,\n",
    "    Y,\n",
    "    tmp_test,\n",
    "#     sample,\n",
    "#     Y.head(10000),\n",
    "#     tmp_test.head(1000),\n",
    "    COLUMN_GROUP,\n",
    "    model_type,\n",
    "    params,\n",
    "    is_adv=[True, False][1],\n",
    "    is_viz=[True, False][1],\n",
    "#     cols_categorical=cols_categorical\n",
    ")\n",
    "feim = list_result_feim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
