{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_numeric_features, get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename\n",
    "from func.time_utils import date_add_days, date_add_times\n",
    "from func.ml_utils import save_feature, get_cnt_feature, get_dummie_feature, get_label_feature\n",
    "from func.parallel_utils import get_parallel_arg_list\n",
    "from joblib import delayed, Parallel\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_texts = read_pkl_gzip('../feature/eda_base/129__combi92_cnt_card-addr-domain-C-V-M_train.gz')\n",
    "# test_texts = read_pkl_gzip('../feature/eda_base/129__combi92_cnt_card-addr-domain-C-V-M_test.gz')\n",
    "\n",
    "def word_split(texts):\n",
    "    list_text = [text.split(' ') for text in texts]\n",
    "    return list_text\n",
    "\n",
    "# train_texts = word_split(train_texts)\n",
    "# test_texts = word_split(test_texts)\n",
    "all_texts = train_texts + test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語の出現回数を格納するfrequency変数を定義\n",
    "from collections import defaultdict\n",
    "\n",
    "def check_word_freq(list_text):\n",
    "    frequency = defaultdict(int)\n",
    "    \n",
    "    # 単語の出現回数をfrequency変数でカウント\n",
    "    for text in list_text:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "    \n",
    "    # frequency変数で1より上の単語のみを配列に構築\n",
    "    texts = [[token for token in text if frequency[token] > 1] for text in list_text]\n",
    "    return texts\n",
    "    \n",
    "texts = check_word_freq(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('../output/09151600_ieee_LDA_gensim.dict')\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_topics in range(5, 13, 2):\n",
    "num_topics = 5\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"f__cnt_V283_36001\" + 0.011*\"f__cnt_V307_1\" + 0.010*\"f__cnt_V62_38572\" + 0.010*\"f__cnt_V294_52137\" + 0.009*\"f__cnt_V281_31295\" + 0.008*\"f__cnt_V294_24611\" + 0.008*\"f__cnt_C12_185008\" + 0.008*\"f__cnt_V67_25167\" + 0.008*\"f__cnt_V282_22981\" + 0.008*\"f__cnt_V283_17209\"'),\n",
       " (1,\n",
       "  '0.014*\"f__cnt_V78_903415\" + 0.014*\"f__cnt_C7_961240\" + 0.014*\"f__cnt_addr2_956415\" + 0.013*\"f__cnt_V94_851784\" + 0.013*\"f__cnt_card3_956845\" + 0.013*\"f__cnt_V318_998337\" + 0.013*\"f__cnt_V317_972197\" + 0.013*\"f__cnt_V294_972197\" + 0.013*\"f__cnt_V306_910878\" + 0.012*\"f__cnt_V38_768706\"'),\n",
       " (2,\n",
       "  '0.096*\"f__cnt_C3_14643\" + 0.034*\"f__cnt_C6_10838\" + 0.033*\"f__cnt_C14_10797\" + 0.031*\"f__cnt_C1_10856\" + 0.031*\"f__cnt_C11_10769\" + 0.031*\"f__cnt_C2_10808\" + 0.019*\"f__cnt_C13_10929\" + 0.013*\"f__cnt_V265_2938\" + 0.013*\"f__cnt_V307_3613\" + 0.013*\"f__cnt_V127_3474\"'),\n",
       " (3,\n",
       "  '0.018*\"f__M2_#\" + 0.018*\"f__M3_#\" + 0.018*\"f__M1_#\" + 0.018*\"f__cnt_V2_455805\" + 0.018*\"f__cnt_V3_455805\" + 0.018*\"f__cnt_V4_455805\" + 0.018*\"f__cnt_V7_455805\" + 0.018*\"f__cnt_V6_455805\" + 0.018*\"f__cnt_V5_455805\" + 0.017*\"f__cnt_C9_341564\"'),\n",
       " (4,\n",
       "  '0.011*\"f__cnt_V307_1112\" + 0.010*\"f__cnt_V128_1207\" + 0.010*\"f__cnt_V127_1077\" + 0.010*\"f__cnt_V127_1371\" + 0.010*\"f__cnt_V265_853\" + 0.009*\"f__cnt_V308_1218\" + 0.009*\"f__cnt_V308_1074\" + 0.009*\"f__cnt_V128_1026\" + 0.009*\"f__cnt_V307_1438\" + 0.009*\"f__cnt_V306_1048\"')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 8\n",
    "lda8 = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "num_topics = 12\n",
    "lda12 = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "num_topics = 16\n",
    "lda16 = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "num_topics = 20\n",
    "lda20 = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 1/20 [00:09<03:00,  9.52s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 2/20 [00:17<02:45,  9.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 3/20 [00:25<02:30,  8.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 4/20 [00:34<02:19,  8.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 5/20 [00:38<01:51,  7.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 6/20 [00:43<01:31,  6.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 7/20 [00:47<01:16,  5.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 8/20 [00:52<01:05,  5.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 9/20 [00:56<00:56,  5.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 10/20 [01:03<00:55,  5.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 11/20 [01:12<01:01,  6.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 12/20 [01:22<01:01,  7.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 13/20 [01:31<00:57,  8.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 14/20 [01:40<00:50,  8.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 15/20 [01:46<00:38,  7.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 16/20 [01:52<00:28,  7.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 17/20 [01:59<00:21,  7.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 18/20 [02:09<00:15,  7.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 19/20 [02:18<00:08,  8.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 20/20 [02:27<00:00,  8.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "prefix = '608'\n",
    "trn_len = len(train_texts)\n",
    "for col_no in tqdm(range(20)):\n",
    "    train_feature = tmp_mx[:trn_len, col_no]\n",
    "    test_feature = tmp_mx[trn_len:, col_no]\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic20_no{col_no}_train', obj=train_feature)\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic20_no{col_no}_test', obj=test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 1/5 [00:04<00:18,  4.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 2/5 [00:08<00:13,  4.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 3/5 [00:13<00:08,  4.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 4/5 [00:18<00:04,  4.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 5/5 [00:28<00:00,  6.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "def get_lda_topic(topic_num, model, corpus):\n",
    "    tmp_mx = np.zeros((len(corpus), topic_num))\n",
    "    for idx, sample in tqdm(enumerate(corpus)):\n",
    "        topic = model[sample]\n",
    "        for t_no, val in topic:\n",
    "            tmp_mx[idx, t_no] = val\n",
    "        \n",
    "    return tmp_mx\n",
    "    \n",
    "topic_num = 5\n",
    "topic5_mx = get_lda_topic(topic_num, lda, corpus)\n",
    "\n",
    "prefix = '608'\n",
    "trn_len = len(train_texts)\n",
    "for col_no in tqdm(range(topic_num)):\n",
    "    train_feature = topic5_mx[:trn_len, col_no]\n",
    "    test_feature = topic5_mx[trn_len:, col_no]\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{topic_num}_no{col_no}_train', obj=train_feature)\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{topic_num}_no{col_no}_test', obj=test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num = 8\n",
    "topic_mx = get_lda_topic(topic_num, lda8, corpus)\n",
    "\n",
    "prefix = '608'\n",
    "trn_len = len(train_texts)\n",
    "for col_no in tqdm(range(topic_num)):\n",
    "    train_feature = topic_mx[:trn_len, col_no]\n",
    "    test_feature = topic_mx[trn_len:, col_no]\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{topic_num}_no{col_no}_train', obj=train_feature)\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{topic_num}_no{col_no}_test', obj=test_feature)\n",
    "    \n",
    "topic_num = 12\n",
    "topic_mx = get_lda_topic(topic_num, lda12, corpus)\n",
    "\n",
    "prefix = '608'\n",
    "trn_len = len(train_texts)\n",
    "for col_no in tqdm(range(topic_num)):\n",
    "    train_feature = topic_mx[:trn_len, col_no]\n",
    "    test_feature = topic_mx[trn_len:, col_no]\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{topic_num}_no{col_no}_train', obj=train_feature)\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{topic_num}_no{col_no}_test', obj=test_feature)\n",
    "    \n",
    "    \n",
    "topic_num = 16\n",
    "topic_mx = get_lda_topic(topic_num, lda16, corpus)\n",
    "\n",
    "prefix = '608'\n",
    "trn_len = len(train_texts)\n",
    "for col_no in tqdm(range(topic_num)):\n",
    "    train_feature = topic_mx[:trn_len, col_no]\n",
    "    test_feature = topic_mx[trn_len:, col_no]\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{topic_num}_no{col_no}_train', obj=train_feature)\n",
    "    to_pkl_gzip(path=f'../feature/create/{prefix}__lda_topic{topic_num}_no{col_no}_test', obj=test_feature)\n",
    "    \n",
    "del topic_mx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
