{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_numeric_features, get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename\n",
    "from func.time_utils import date_add_days\n",
    "from func.ml_utils import save_feature, get_cnt_feature, get_dummie_feature, get_label_feature\n",
    "from func.parallel_utils import get_parallel_arg_list\n",
    "from joblib import delayed, Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, 'ProductCD']\n",
    "\n",
    "train_paths = glob('../feature/eda_base/*_train.gz')\n",
    "test_paths = glob('../feature/eda_base/*_test.gz')\n",
    "\n",
    "train_paths = [path for path in train_paths \n",
    "               if (path.count(COLUMN_DT) \n",
    "               or path.count(COLUMN_ID)\n",
    "               or path.count(COLUMN_TARGET)\n",
    "               or path.count('V')\n",
    "               or path.count('C')\n",
    "               or path.count('D')\n",
    "               or path.count('card')\n",
    "               or path.count('addr')\n",
    "               or path.count('domain')\n",
    "               or path.count('TransactionAmt')\n",
    "               or path.count('Product')\n",
    "               )\n",
    "               and not path.count('new_uid')\n",
    "               and not path.count('fill')\n",
    "               and not path.count('bin')\n",
    "               and not path.count('129')\n",
    "              ]\n",
    "test_paths = [path for path in test_paths \n",
    "               if (path.count(COLUMN_DT) \n",
    "               or path.count(COLUMN_ID)\n",
    "               or path.count(COLUMN_TARGET)\n",
    "               or path.count('V')\n",
    "               or path.count('C')\n",
    "               or path.count('D')\n",
    "               or path.count('card')\n",
    "               or path.count('addr')\n",
    "               or path.count('domain')\n",
    "               or path.count('TransactionAmt')\n",
    "               or path.count('Product')\n",
    "               )\n",
    "               and not path.count('new_uid')\n",
    "               and not path.count('fill')\n",
    "               and not path.count('bin')\n",
    "               and not path.count('129')\n",
    "              ]\n",
    "\n",
    "df_train = parallel_load_data(train_paths)\n",
    "print(df_train.shape)\n",
    "df_test = parallel_load_data(test_paths)\n",
    "data = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "train_length = df_train.shape[0]\n",
    "\n",
    "df_user_id_ca = pd.read_csv('../output/same_user_pattern/0903__same_user_id__card_addr.csv').set_index(COLUMN_ID)\n",
    "df_user_id_cap = pd.read_csv('../output/same_user_pattern/0903__same_user_id__card_addr_pemail.csv').set_index(COLUMN_ID)\n",
    "df_user_id_capm = pd.read_csv('../output/same_user_pattern/0902__same_user_id__card_addr_pemail_M.csv').set_index(COLUMN_ID)\n",
    "df_user_id_bear = pd.read_csv('../output/same_user_pattern/20190901_user_ids_share.csv').set_index(COLUMN_ID)\n",
    "\n",
    "data.set_index(COLUMN_ID, inplace=True)\n",
    "data['user_id_bear'] = df_user_id_bear['predicted_user_id']\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# df_train['user_id_card_addr'] = df_user_id_ca['predicted_user_id']\n",
    "# df_train['user_id_card_addr_pemail'] = df_user_id_cap['predicted_user_id']\n",
    "# df_train['user_id_card_addr_pemail_M'] = df_user_id_capm['predicted_user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1097231/1097231 [00:04<00:00, 261451.42it/s]\n"
     ]
    }
   ],
   "source": [
    "START_DATE = '2017-12-01'\n",
    "# START_DATE = '2017-12-01'\n",
    "startdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "\n",
    "data['datetime'] = data['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x) - datetime.timedelta(seconds = 14400) ))\n",
    "data['datetime'].fillna(datetime.date(2020, 1, 1), inplace=True)\n",
    "data['date'] = data['datetime'].map(lambda x: x.date())\n",
    "\n",
    "# df_train['datetime'] = df_train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x) - datetime.timedelta(seconds = 14400) ))\n",
    "# df_train['datetime'].fillna(datetime.date(2020, 1, 1), inplace=True)\n",
    "# df_train['date'] = df_train['datetime'].map(lambda x: x.date())\n",
    "\n",
    "list_regist = []\n",
    "for d, diff in tqdm(data[['date', 'D1']].values):\n",
    "    if diff < 999999:\n",
    "        regist = date_add_days(d, -1*diff)\n",
    "    else:\n",
    "        regist = date_add_days(d, 0)\n",
    "    list_regist.append(str(regist))\n",
    "\n",
    "data['Regist_date'] = list_regist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = read_pkl_gzip(path='../output/0919_ieee__eight_residual_50000over.gz')\n",
    "df_check = df_check.merge(df_train, how='inner', on=COLUMN_ID)\n",
    "\n",
    "cols_uid = [col for col in df_check.columns if col.count('130_')]\n",
    "\n",
    "col_bear  = 'user_id_bear'\n",
    "col_uid_1 = 'user_id_card_addr'\n",
    "col_uid_2 = 'user_id_card_addr_pemail'\n",
    "col_uid_3 = 'user_id_card_addr_pemail_M'\n",
    "\n",
    "list_uid = [\n",
    "    col_bear ,\n",
    "    col_uid_1,\n",
    "    col_uid_2,\n",
    "    col_uid_3,\n",
    "] + cols_uid\n",
    "\n",
    "# for uid in list_uid:\n",
    "#     cnt_map = df_check[uid].value_counts()\n",
    "#     df_check[f'cnt__{uid}'] = df_check[uid].map(cnt_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_sort = ['datetime', 'user_id_bear', 'isFraud', 'residual', '_eight_rank', '_pred_rank', 'C1', 'C11', 'C13', 'P_emaildomain', 'ProductCD', 'R_emaildomain', 'Regist_date', 'D1', 'D3', 'addr1', 'card1', 'card2', 'card3', 'V95', 'V97', 'V127', 'V128', 'TransactionAmt', 'C10', 'C12', 'C14', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'D2', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'V101', 'V102', 'V103', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V123', 'V124', 'V125', 'V130', 'V131', 'V133', 'V156', 'V165', 'V187', 'V2', 'V201', 'V243', 'V258', 'V259', 'V265', 'V267', 'V281', 'V282', 'V283', 'V29', 'V294', 'V3', 'V306', 'V307', 'V308', 'V310', 'V312', 'V313', 'V314', 'V315', 'V317', 'V318', 'V320', 'V37', 'V38', 'V4', 'V44', 'V45', 'V48', 'V49', 'V5', 'V53', 'V54', 'V6', 'V61', 'V62', 'V67', 'V7', 'V70', 'V76', 'V78', 'V83', 'V87', 'V90', 'V91', 'V94', '__DT-M', '__DT-W', 'addr2', 'card4', 'card5', 'card6']\n",
    "cols_all = df_check.columns\n",
    "cols_remain = sorted(list(set(cols_all) - set(cols_sort)))\n",
    "df_check = df_check[cols_sort + cols_remain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "col_amt = 'TransactionAmt'\n",
    "cols_V = [col for col in tmp.columns if col.startswith('V')]\n",
    "cols_C = [col for col in tmp.columns if col.startswith('C')]\n",
    "cols_D = [col for col in tmp.columns if col.startswith('D')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['C1_C14_ratio'] = data['C1'] / data['C14']\n",
    "data['ratio_id'] = data['C1_C14_ratio'].map(lambda x: np.round(x, 3)).astype('str').fillna('#')  + '_' + data['addr1'].astype('str')\n",
    "# + '_' + data['card1'].astype('str') \\\n",
    "\n",
    "check_ids = data['ratio_id'].value_counts().head(20).index\n",
    "\n",
    "\n",
    "# df_check['C1_C14_ratio'] = df_check['C1'] / df_check['C14']\n",
    "# # df_check[df_check[col_bear]==200780.0][['pred', 'C1', 'C14', 'C1_C14_ratio']].sort_values(by='pred')\n",
    "# # df_check[(df_check['C1_C14_ratio']==1) & (df_check['card1'])]\n",
    "# df_check['ratio_id'] = df_check['C1_C14_ratio'].map(lambda x: np.round(x, 3)).astype('str') + '_' + df_check['card1'].astype('str')\n",
    "# df_check['ratio_id'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21809,)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for uid in check_ids:\n",
    "    tmp = data[data['ratio_id']==uid]\n",
    "    cnt = tmp[col_bear].value_counts()\n",
    "    ids = cnt[cnt==1].index\n",
    "    print(ids.shape)\n",
    "    sys.exit()\n",
    "    \n",
    "#     df_train[df_train[col_bear].isin(ids)][[col_bear, 'Regist_date', 'datetime'] + cols_D].sort_values(by='Regist_date')\n",
    "# print(ids.shape)\n",
    "# tmp.sort_values(by='datetime', inplace=True)\n",
    "# tmp[[col_bear] + cols_C + cols_D].sort_values(by=col_bear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filter = data[data[col_bear].isin(ids)]\n",
    "# cnt = df_filter[col_bear].value_counts()\n",
    "# cnt = data[col_bear].value_counts()\n",
    "# ids = cnt[cnt==1].index\n",
    "tmp = data[data[col_bear].isin(ids)]\n",
    "# save = tmp[['ProductCD', 'isFraud', 'Regist_date', 'datetime', 'D1', 'D2', 'D3', 'C1', 'C14', 'V95', 'V97', col_amt, 'V130', 'V131', 'V307', 'V308']].sort_values(by='datetime').sort_values(by=['Regist_date'])\n",
    "save = tmp[[COLUMN_ID, 'ProductCD', 'isFraud', 'Regist_date', 'datetime', 'card1', 'card2', 'card3', 'D1', 'D2', 'D3', 'D6', 'D7', 'D8', 'D13', 'D14', 'D15', 'C1', 'C14', 'V95', 'V97', col_amt, 'V130', 'V131', 'V307', 'V308', col_bear]].sort_values(by='datetime').sort_values(by=['Regist_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_r = save[save['ProductCD']=='R']\n",
    "# save_r.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_r[~save_r['D8'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']]\n",
    "list_user_r = []\n",
    "already = []\n",
    "\n",
    "for uid, d, d8, t in tqdm(tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']].values):\n",
    "    if uid in set(already):\n",
    "        continue\n",
    "    tmp['diff'] = (tmp['D8'] - d8).astype('int')\n",
    "    candidates = tmp[(tmp['datetime'] - d).map(lambda x: x.total_seconds()/60/60).astype('int') == tmp['diff']]\n",
    "    if candidates.shape[0]>1:\n",
    "#     if candidates['isFraud'].isnull().sum()>1:\n",
    "#     if candidates['isFraud'].sum()>1:\n",
    "#         display(candidates)\n",
    "        list_user_r.append(candidates[COLUMN_ID].values)\n",
    "        already += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_r = save[save['ProductCD']=='R']\n",
    "# save_r.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_r[~saver['D3'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']]\n",
    "list_user_R_D3 = []\n",
    "already_R_D3 = []\n",
    "\n",
    "for uid, d, rd, d1,d3, d8, t in tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_R_D3):\n",
    "        continue\n",
    "    diff = d1 - d3\n",
    "    candidates = tmp[((tmp['D1'] == diff) | (tmp[COLUMN_ID]==uid)) & (tmp['Regist_date']==rd) & (tmp['D3']!=0)]\n",
    "    if candidates.shape[0]>1:\n",
    "#         display(candidates.sort_values(by='datetime'))\n",
    "        list_user_R_D3.append(candidates[COLUMN_ID].values)\n",
    "        already_R_D3 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_s = save[save['ProductCD']=='S']\n",
    "# save_s.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_s[~save_s['D8'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']]\n",
    "list_user_S_D8 = []\n",
    "already_S_D8 = []\n",
    "\n",
    "for uid, d, d8, t in tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_S_D8):\n",
    "        continue\n",
    "    tmp['diff'] = (tmp['D8'] - d8).astype('int')\n",
    "    candidates = tmp[(tmp['datetime'] - d).map(lambda x: x.total_seconds()/60/60).astype('int') == tmp['diff']]\n",
    "    if candidates.shape[0]>1:\n",
    "#     if candidates['isFraud'].isnull().sum()>1:\n",
    "#     if candidates['isFraud'].sum()>1:\n",
    "#         display(candidates)\n",
    "        list_user_S_D8.append(candidates[COLUMN_ID].values)\n",
    "        already_S_D8 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_s = save[save['ProductCD']=='S']\n",
    "# save_s.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_s[~save_s['D3'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']]\n",
    "list_user_S_D3 = []\n",
    "already_S_D3 = []\n",
    "\n",
    "for uid, d, rd, d1,d3, d8, t in tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_S_D3):\n",
    "        continue\n",
    "    diff = d1 - d3\n",
    "    candidates = tmp[((tmp['D1'] == diff) | (tmp[COLUMN_ID]==uid)) & (tmp['Regist_date']==rd) & (tmp['D3']!=0)]\n",
    "    if candidates.shape[0]>1:\n",
    "#         display(candidates.sort_values(by='datetime'))\n",
    "        list_user_S_D3.append(candidates[COLUMN_ID].values)\n",
    "        already_S_D3 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_w = save[save['ProductCD']=='W']\n",
    "# save_w.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_w[~save_w['D8'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']]\n",
    "list_user_W_D8 = []\n",
    "already_W_D8 = []\n",
    "\n",
    "for uid, d, d8, t in tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_W_D8):\n",
    "        continue\n",
    "    tmp['diff'] = (tmp['D8'] - d8).astype('int')\n",
    "    candidates = tmp[(tmp['datetime'] - d).map(lambda x: x.total_seconds()/60/60).astype('int') == tmp['diff']]\n",
    "    if candidates.shape[0]>1:\n",
    "#     if candidates['isFraud'].isnull().sum()>1:\n",
    "#     if candidates['isFraud'].sum()>1:\n",
    "#         display(candidates)\n",
    "        list_user_W_D8.append(candidates[COLUMN_ID].values)\n",
    "        already_W_D8 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_w = save[save['ProductCD']=='W']\n",
    "# save_w.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_w[~save_w['D3'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']]\n",
    "list_user_W_D3 = []\n",
    "already_W_D3 = []\n",
    "\n",
    "for uid, d, rd, d1,d3, d8, t in tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_W_D3):\n",
    "        continue\n",
    "    diff = d1 - d3\n",
    "    candidates = tmp[((tmp['D1'] == diff) | (tmp[COLUMN_ID]==uid)) & (tmp['Regist_date']==rd) & (tmp['D3']!=0)]\n",
    "    if candidates.shape[0]>1:\n",
    "#         display(candidates.sort_values(by='datetime'))\n",
    "        list_user_W_D3.append(candidates[COLUMN_ID].values)\n",
    "        already_W_D3 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_c = save[save['ProductCD']=='C']\n",
    "# save_c.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_c[~save_c['D8'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']]\n",
    "list_user_C_D8 = []\n",
    "already_C_D8 = []\n",
    "\n",
    "for uid, d, d8, t in tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_C_D8):\n",
    "        continue\n",
    "    tmp['diff'] = (tmp['D8'] - d8).astype('int')\n",
    "    candidates = tmp[(tmp['datetime'] - d).map(lambda x: x.total_seconds()/60/60).astype('int') == tmp['diff']]\n",
    "    if candidates.shape[0]>1:\n",
    "#     if candidates['isFraud'].isnull().sum()>1:\n",
    "#     if candidates['isFraud'].sum()>1:\n",
    "#         display(candidates)\n",
    "        list_user_C_D8.append(candidates[COLUMN_ID].values)\n",
    "        already_C_D8 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_c = save[save['ProductCD']=='C']\n",
    "# save_c.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_c[~save_c['D3'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']]\n",
    "list_user_C_D3 = []\n",
    "already_C_D3 = []\n",
    "\n",
    "for uid, d, rd, d1,d3, d8, t in tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_C_D3):\n",
    "        continue\n",
    "    diff = d1 - d3\n",
    "    candidates = tmp[((tmp['D1'] == diff) | (tmp[COLUMN_ID]==uid)) & (tmp['Regist_date']==rd) & (tmp['D3']!=0)]\n",
    "    if candidates.shape[0]>1:\n",
    "#         display(candidates.sort_values(by='datetime'))\n",
    "        list_user_C_D3.append(candidates[COLUMN_ID].values)\n",
    "        already_C_D3 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_h = save[save['ProductCD']=='H']\n",
    "# save_h.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_h[~save_h['D8'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']]\n",
    "list_user_H_D8 = []\n",
    "already_H_D8 = []\n",
    "\n",
    "for uid, d, d8, t in tmp[[COLUMN_ID, 'datetime', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_H_D8):\n",
    "        continue\n",
    "    tmp['diff'] = (tmp['D8'] - d8).astype('int')\n",
    "    candidates = tmp[(tmp['datetime'] - d).map(lambda x: x.total_seconds()/60/60).astype('int') == tmp['diff']]\n",
    "    if candidates.shape[0]>1:\n",
    "#     if candidates['isFraud'].isnull().sum()>1:\n",
    "#     if candidates['isFraud'].sum()>1:\n",
    "#         display(candidates)\n",
    "        list_user_H_D8.append(candidates[COLUMN_ID].values)\n",
    "        already_H_D8 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_h = save[save['ProductCD']=='H']\n",
    "# save_h.to_csv('../output/0919_probing_R_addr1_C1_C14_ratio.csv')\n",
    "\n",
    "tmp = save_h[~save_h['D3'].isnull()]\n",
    "tmp = tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']]\n",
    "list_user_H_D3 = []\n",
    "already_H_D3 = []\n",
    "\n",
    "for uid, d, rd, d1,d3, d8, t in tmp[[COLUMN_ID, 'datetime', 'Regist_date', 'D1', 'D3', 'D8', 'isFraud']].values:\n",
    "    if uid in set(already_H_D3):\n",
    "        continue\n",
    "    diff = d1 - d3\n",
    "    candidates = tmp[((tmp['D1'] == diff) | (tmp[COLUMN_ID]==uid)) & (tmp['Regist_date']==rd) & (tmp['D3']!=0)]\n",
    "    if candidates.shape[0]>1:\n",
    "#         display(candidates.sort_values(by='datetime'))\n",
    "        list_user_H_D3.append(candidates[COLUMN_ID].values)\n",
    "        already_H_D3 += candidates[COLUMN_ID].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "save['d8_progress'] = np.nan\n",
    "\n",
    "for users in tqdm(list_user_R_D3):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd8_progress'] = cnt\n",
    "    cnt += 1\n",
    "    \n",
    "for users in tqdm(list_user_S_D8):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd8_progress'] = cnt\n",
    "    cnt += 1\n",
    "    \n",
    "    \n",
    "for users in tqdm(list_user_W_D8):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd8_progress'] = cnt\n",
    "    cnt += 1\n",
    "    \n",
    "    \n",
    "for users in tqdm(list_user_C_D8):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd8_progress'] = cnt\n",
    "    cnt += 1\n",
    "    \n",
    "    \n",
    "for users in tqdm(list_user_H_D8):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd8_progress'] = cnt\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "save['d3_progress'] = np.nan\n",
    "\n",
    "for users in tqdm(list_user_R_D3):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd3_progress'] = cnt\n",
    "    cnt += 1\n",
    "    \n",
    "for users in tqdm(list_user_S_D3):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd3_progress'] = cnt\n",
    "    cnt += 1\n",
    "    \n",
    "    \n",
    "for users in tqdm(list_user_W_D3):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd3_progress'] = cnt\n",
    "    cnt += 1\n",
    "    \n",
    "    \n",
    "for users in tqdm(list_user_C_D3):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd3_progress'] = cnt\n",
    "    cnt += 1\n",
    "    \n",
    "    \n",
    "for users in tqdm(list_user_H_D3):\n",
    "# tmp = np.hstack(list_user_r)\n",
    "    save.loc[save[COLUMN_ID].isin(users), 'd3_progress'] = cnt\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pkl_gzip(obj=save[[COLUMN_ID, 'd3_progress', 'd8_progress']], path='../output/0920_ieee__d3_d8_progress_ProductCD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
