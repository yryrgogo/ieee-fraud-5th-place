{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-23 23:45:57,198 func.utils 347 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_numeric_features, get_categorical_features,\\\n",
    "read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename, logger_func, timer\n",
    "from ieee_train import eval_train, eval_check_feature\n",
    "from kaggle_utils import reduce_mem_usage, move_feature\n",
    "logger = logger_func()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from torch.optim import Adam\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import random\n",
    "import  warnings\n",
    "pd.set_option('display.max_columns', 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1208):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e513b88ffe493cfff3302697e49ce9e2b8e5941f"
   },
   "outputs": [],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "COLUMN_DT = 'TransactionDT'\n",
    "COLUMN_TARGET = 'isFraud'\n",
    "COLUMN_GROUP = 'DT-M'\n",
    "COLUMNS_IGNORE = [COLUMN_ID, COLUMN_DT, COLUMN_TARGET, COLUMN_GROUP, 'is_train', 'date']\n",
    "\n",
    "def filter_feature(path):\n",
    "    if path.count(''):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "paths_train = glob('../feature/raw_use/*_train.gz')\n",
    "paths_test  = glob('../feature/raw_use/*_test.gz')\n",
    "\n",
    "# paths_train = glob('../submit/re_sub/*_train.gz')\n",
    "# paths_test  = glob('../submit/re_sub/*_test.gz')\n",
    "# paths_train += glob('../submit/add_feature/*_train.gz')\n",
    "# paths_test  += glob('../submit/add_feature/*_test.gz')\n",
    "# paths_train += glob('../feature/valid_use/531*_train.gz')\n",
    "# paths_test  += glob('../feature/valid_use/531*_test.gz')\n",
    "# paths_train += glob('../feature/valid_use/532*_train.gz')\n",
    "# paths_test  += glob('../feature/valid_use/532*_test.gz')\n",
    "\n",
    "\n",
    "paths_train_feature = []\n",
    "paths_test_feature  = []\n",
    "\n",
    "# df_train = reduce_mem_usage( parallel_load_data(paths_train) )\n",
    "# df_test  = reduce_mem_usage( parallel_load_data(paths_test) )\n",
    "df_train = parallel_load_data(paths_train).iloc[:10000]\n",
    "df_test  = parallel_load_data(paths_test).iloc[:10000]\n",
    "Y = df_train[COLUMN_TARGET]\n",
    "df_train.drop(COLUMN_TARGET, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "1f2ce481199cf0bf823b29aa68abef31255aa628"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = df_train[COLUMN_ID]\n",
    "test_ids = df_test[COLUMN_ID]\n",
    "\n",
    "df_all = pd.concat((df_train, df_test),axis=0)\n",
    "\n",
    "del df_train, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c4a52ef1dd84a6f73d93087ed80d79ad3ae13690"
   },
   "outputs": [],
   "source": [
    "# In practice, among the numerical variables, many corresponds to identifiers. *In the current dataset, the truly numerical variables are in fact rare*. Below, I make a list of the variables which are truly numerical, according the the description of the data.\n",
    "cols_all_num = get_numeric_features(df_all, COLUMNS_IGNORE)\n",
    "\n",
    "cols_binary = [col for col in cols_all_num if df_all[col].nunique() == 2]\n",
    "\n",
    "cols_cat = [col for col in df_all.columns if (col.count('uid')) & (col not in cols_binary)]\n",
    "cols_num = list(set(cols_all_num) - set(cols_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bcc09ccb8d7b41c0fb5c857e11b6b4e30ebde9b"
   },
   "source": [
    "## Frequency Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c4a52ef1dd84a6f73d93087ed80d79ad3ae13690"
   },
   "outputs": [],
   "source": [
    "# def frequency_encoding(variable):\n",
    "#     # t = pd.concat([train[variable], test[variable]]).value_counts().reset_index()\n",
    "#     t = df_all[variable].value_counts().reset_index()\n",
    "#     t = t.reset_index()\n",
    "#     t.loc[t[variable] == 1, 'level_0'] = np.nan\n",
    "#     t.set_index('index', inplace=True)\n",
    "#     max_label = t['level_0'].max() + 1\n",
    "#     t.fillna(max_label, inplace=True)\n",
    "#     return t.to_dict()['level_0']\n",
    "\n",
    "# frequency_encoded_variables = [\n",
    "#     'Census_OEMModelIdentifier',\n",
    "#     'CityIdentifier',\n",
    "#     'Census_FirmwareVersionIdentifier',\n",
    "#     'AvSigVersion',\n",
    "#     'Census_ProcessorModelIdentifier',\n",
    "#     'Census_OEMNameIdentifier',\n",
    "#     'DefaultBrowsersIdentifier',\n",
    "#     'AVProductStatesIdentifier',\n",
    "#     'OsBuildLab',\n",
    "# ]\n",
    "\n",
    "# for variable in tqdm(frequency_encoded_variables):\n",
    "#     freq_enc_dict = frequency_encoding(variable)\n",
    "#     df_all[variable] = df_all[variable].map(lambda x: freq_enc_dict.get(x, np.nan))\n",
    "#     categorical_columns.remove(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4a52ef1dd84a6f73d93087ed80d79ad3ae13690"
   },
   "source": [
    "## Prepare Embedding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c4a52ef1dd84a6f73d93087ed80d79ad3ae13690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of embed features : 19\n"
     ]
    }
   ],
   "source": [
    "embed_cols = []\n",
    "len_embed_cols = []\n",
    "for col in cols_cat:\n",
    "    embed_cols.append(col)\n",
    "    len_embed_cols.append(df_all[col].nunique())\n",
    "print('\\n Number of embed features :', len(embed_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89e8ad026348315a30e496cc73455762843ff0dd"
   },
   "source": [
    "## Preprocess Other Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c4a52ef1dd84a6f73d93087ed80d79ad3ae13690"
   },
   "outputs": [],
   "source": [
    "# set index to unique identifier\n",
    "df_all = df_all.set_index(COLUMN_ID)\n",
    "\n",
    "# Select the numeric features\n",
    "other_cols = [x for x in df_all.columns if x not in embed_cols]\n",
    "\n",
    "# Impute missing values in order to scale\n",
    "df_all[other_cols] = df_all[other_cols].fillna(value=0)\n",
    "\n",
    "\n",
    "# Fit the scaler only on df_all data\n",
    "scaler = MinMaxScaler().fit(df_all[other_cols])\n",
    "df_all.loc[:, other_cols] = scaler.transform(df_all[other_cols])\n",
    "\n",
    "# other_cols = [c for c in df_all.columns if (not c in embed_cols)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6955728ede711080f20ea6b9b99bf48bf67f51fd"
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "083bf20005ccc9c50c36ed87e8447b7ce799e13f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 63) (10000, 63)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_all.loc[train_ids, embed_cols+other_cols]\n",
    "test = df_all.loc[test_ids, embed_cols+other_cols]\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "del df_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "083bf20005ccc9c50c36ed87e8447b7ce799e13f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 1208\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, Y , test_size=0.20, random_state=seed)\n",
    "\n",
    "torch_X_train = torch.FloatTensor(X_train.values)\n",
    "torch_X_valid = torch.FloatTensor(X_valid.values)\n",
    "torch_y_train = torch.FloatTensor(y_train.values.astype(np.int32))\n",
    "torch_y_valid = torch.FloatTensor(y_valid.values.astype(np.int32))\n",
    "torch_test  = torch.FloatTensor(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0463,  0.7180,  0.3123,  ..., -0.0706,  2.3758, -0.4642],\n",
       "        [-0.3286, -0.1409,  0.8102,  ...,  0.6836,  0.6042,  1.0068],\n",
       "        [-1.1372, -0.1712, -1.2252,  ..., -0.0583,  0.0772,  0.0157]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0,1,2])\n",
    "model.emb_layers[0](a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "12a4251dc137499af5cd4f7acdc3b2ba54864511"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb_layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(.20)\n",
    "        self.num_categorical = len(len_embed_cols)\n",
    "        self.num_numeric = len(other_cols)\n",
    "        \n",
    "        for embed_col, len_embed_col in zip(embed_cols, len_embed_cols):\n",
    "            self.emb_layers.append(nn.Embedding(len_embed_col, len_embed_col // 2))\n",
    "\n",
    "        ff_inp_dim = sum(e.embedding_dim for e in self.emb_layers) + self.num_numeric\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(ff_inp_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=.20),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=.15),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "        emb_indices = x_batch[:, :self.num_categorical].long()\n",
    "        emb_outs = []\n",
    "        for i, emb_layer in enumerate(self.emb_layers):\n",
    "            tmp = emb_indices[:, i]\n",
    "            print(tmp.shape)\n",
    "            print(emb_layer)\n",
    "            emb_out = emb_layer(emb_indices[:, i])\n",
    "            emb_out = self.dropout(emb_out)\n",
    "            emb_outs.append(emb_out)\n",
    "        \n",
    "        embs = torch.cat(emb_outs, dim=1)\n",
    "\n",
    "        x_numerical = x_batch[:, self.num_categorical:]\n",
    "        embs_num = torch.cat([embs, x_numerical], dim=1)\n",
    "        out = self.ff(embs_num)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# always call this before training for deterministic results\n",
    "seed_everything(seed)\n",
    "\n",
    "batch_size = 512\n",
    "n_epochs = 6\n",
    "\n",
    "# init model\n",
    "model = NeuralNet()\n",
    "\n",
    "# init Binary Cross Entropy loss\n",
    "loss_fn = torch.nn.BCELoss(reduction='mean')\n",
    "\n",
    "# init optimizer\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3c0504bcc508c9dc2815ec7d039cf7f7e91204f5"
   },
   "outputs": [],
   "source": [
    "#prepare iterators for training\n",
    "torch_train = torch.utils.data.TensorDataset(torch_X_train, torch_y_train)\n",
    "train_loader = torch.utils.data.DataLoader(torch_train, batch_size=batch_size, shuffle=True)\n",
    "torch_valid = torch.utils.data.TensorDataset(torch_X_valid, torch_y_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(torch_valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# init predictions\n",
    "train_preds = np.zeros((torch_X_train.size(0)))\n",
    "valid_preds = np.zeros((torch_X_valid.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "3c0504bcc508c9dc2815ec7d039cf7f7e91204f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "Embedding(3007, 1503)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range: Tried to access index 1414356048 out of table with 3006 rows. at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:237",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-bca11a3ceb81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;31m# Forward pass: compute predicted y by passing x to the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0;31m# Compute and print loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch-1.2.0-py3.7-linux-x86_64.egg/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-e7aebea05083>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_batch)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0memb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0memb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0memb_outs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch-1.2.0-py3.7-linux-x86_64.egg/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch-1.2.0-py3.7-linux-x86_64.egg/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch-1.2.0-py3.7-linux-x86_64.egg/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range: Tried to access index 1414356048 out of table with 3006 rows. at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:237"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs)): \n",
    "    \n",
    "    with timer(f\"  * Epoch{epoch}\"):\n",
    "        avg_loss = 0.  \n",
    "        # set the module in training mode.\n",
    "        model.train()\n",
    "        \n",
    "        with timer(f\"  * Train\"):\n",
    "    \n",
    "            for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "                # Forward pass: compute predicted y by passing x to the model.\n",
    "                y_pred = model(x_batch)\n",
    "                # Compute and print loss.\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # Before the backward pass, use the optimizer object to zero all of the\n",
    "                # gradients for the Tensors it will update (which are the learnable weights\n",
    "                # of the model)\n",
    "                optimizer.zero_grad()\n",
    "                # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # Calling the step function on an Optimizer makes an update to its parameters\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)\n",
    "    \n",
    "        with timer(f\"  * Valid\"):\n",
    "            \n",
    "            # set evaluation mode of the model. This disabled operations which are only applied during training like dropout\n",
    "            model.eval()\n",
    "        \n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "                # detach returns a new Tensor, detached from the current graph whose result will never require gradient\n",
    "                y_val_pred = model(x_batch).detach()\n",
    "                avg_val_loss += loss_fn(y_val_pred, y_batch).item() / len(valid_loader)\n",
    "        \n",
    "                valid_preds[i * batch_size:(i+1) * batch_size] = y_val_pred.cpu().numpy()[:, 0]\n",
    "            elapsed_time = time.time() - start_time \n",
    "            print('\\nEpoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
    "            print('AUC_VAL{} '.format(roc_auc_score(torch_y_val.cpu(),valid_preds).round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35759d3baf9079d7cfe591b9a45e8abb63e63e57",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch_test = torch.utils.data.TensorDataset(torch_test)\n",
    "test_loader = torch.utils.data.DataLoader(torch_test, batch_size=batch_size, shuffle=False)\n",
    "test_preds = np.zeros((len(torch_test)))\n",
    "\n",
    "\n",
    "for i, (x_batch,) in enumerate(test_loader):\n",
    "    y_pred = model(x_batch).detach()\n",
    "    test_preds[i * batch_size:(i+1) * batch_size] = y_pred.cpu().numpy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3fdc363d69ab95db26709c1cb287c62fbc2fdf23"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(torch_y_val.cpu(),valid_preds)\n",
    "\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9d5e663c68849029b7354483b45525edf15c583"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "359bc5f1d6dcd311a3899b32d67fb8aeb98758cf"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'MachineIdentifier':test_ids,'HasDetections':test_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f95afb2ee7c75211b1380369db6775fc2a6a5b9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63f0f8b9d679f8b30cd90ee88ba55af95473f447",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submission.to_csv('nn_embeddings.csv.gz', index=False, ,compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
