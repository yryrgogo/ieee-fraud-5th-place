{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from func.utils import get_categorical_features, read_pkl_gzip, to_pkl_gzip, parallel_load_data, get_filename\n",
    "from kaggle_utils import move_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths_feim = glob('../output/feature_importances/20190925_1450__CV0-9581588018233685__feature2114.gz') \\\n",
    "# paths_feim = glob('../output/feature_importances/20190925_1633__CV0-9582357322305678__feature2763.gz') \\\n",
    "paths_feim = glob('../output/feature_importances/20190927_0221__CV0-9594791704263358__feature1844.gz')\n",
    "# paths_feim = glob('../output/feature_importances/20190921_2310__CV0-9554268637512479__feature1142.gz')\n",
    "paths_feim = glob('../output/feature_importances/20191003_0728__CV0-9564154607798349__feature943.gz')\n",
    "# + glob('../output/feature_importances/20190909*.gz') \\\n",
    "# + glob('../output/feature_importances/20190908*.gz') \n",
    "# + glob('../output/feature_importances/20190907*.gz') \\\n",
    "# + glob('../output/feature_importances/20190906*.gz')\n",
    "# paths_feim = glob('../output/selection_feature/*.gz')\n",
    "list_good_feature = []\n",
    "list_feim = []\n",
    "\n",
    "for path in paths_feim:\n",
    "    try:\n",
    "        lb_score = re.search(rf'CV([^/.]*)__', path).group(1)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    if float(lb_score.replace('-', '.'))<0.9167:\n",
    "        continue\n",
    "\n",
    "    feim = read_pkl_gzip(path)\n",
    "#     feim = feim[feim['is_valid']==1].head(1).tail(1)\n",
    "#     feim['score'] = lb_score\n",
    "#     list_feim.append(feim)\n",
    "# df_feim = pd.concat(list_feim, axis=0)\n",
    "# df_feim.sort_values(by='importance', ascending=False, inplace=True)\n",
    "# display(df_feim)\n",
    "#     tmp_list = feim.head(1).feature.tolist()\n",
    "#     for feature in tmp_list:\n",
    "#         if feature not in set(list_good_feature):\n",
    "#             list_good_feature.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n"
     ]
    }
   ],
   "source": [
    "from_dir = '../submit/add_feature/'\n",
    "# from_dir = '../submit/escape/'\n",
    "# from_dir = '../submit/re_sub/'\n",
    "# from_dir = 'valid_use'\n",
    "# from_dir = 'valid_trush'\n",
    "# from_dir = 'useless'\n",
    "# from_dir = 'add_feature'\n",
    "# to_dir = 'valid_use'\n",
    "# to_dir = 'valid_trush'\n",
    "to_dir = '../submit/re_sub/'\n",
    "# to_dir = '../submit/add_feature/'\n",
    "# for feature in df_feim['feature'].values:\n",
    "# for feature in feim[feim['is_valid']==1]['feature'].values:\n",
    "# feim = feim.loc[moves]\n",
    "# feim = feim[feim['imp_avg']<500]\n",
    "cnt = 0\n",
    "for feature in feim.index:\n",
    "    move_feature([feature], from_dir, to_dir)\n",
    "    cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703__user_id_bear_agg_D2_max\n",
      "703__user_id_bear_agg_D3_mean\n",
      "703__user_id_bear_agg_C13_skew\n",
      "703__user_id_bear_agg_C1_max\n",
      "703__user_id_bear_agg_C14_mean\n",
      "703__user_id_bear_agg_TransactionAmt_mean\n",
      "703__user_id_bear_agg_D1_skew\n"
     ]
    }
   ],
   "source": [
    "for feature in feim.index:\n",
    "    if feature.count('703'):\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821 821\n"
     ]
    }
   ],
   "source": [
    "COLUMN_ID = 'TransactionID'\n",
    "probing = pd.read_csv('../input/20190929_probing.csv')\n",
    "ids = probing[probing['Probing_isFraud']==1][COLUMN_ID].values\n",
    "print(len(ids), len(set(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "list_from_dir = ['raw_use' , 'org_use']\n",
    "list_from_dir += ['raw_trush' , 'org_trush', 'valid_trush']\n",
    "to_dir = 'valid'\n",
    "list_not_found = []\n",
    "\n",
    "for feature in list_good_feature:\n",
    "    for from_dir in list_from_dir:\n",
    "        \n",
    "        path_train_feature = f\"../feature/{from_dir}/{feature}_train.gz\"\n",
    "        path_test_feature = f\"../feature/{from_dir}/{feature}_test.gz\"\n",
    "        \n",
    "        if os.path.exists(path_train_feature) and os.path.exists(path_test_feature):\n",
    "#         if os.path.exists(path_train_feature):\n",
    "#         if os.path.exists(path_test_feature):\n",
    "            try:\n",
    "                shutil.move(path_train_feature, f'../feature/{to_dir}')\n",
    "                shutil.move(path_test_feature, f'../feature/{to_dir}')\n",
    "            except FileNotFoundError:\n",
    "                print(feature)\n",
    "                list_not_found.append(feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
